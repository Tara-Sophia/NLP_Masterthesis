{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import imblearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE    \n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "      <th>transcription_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>{'pulmonary', 'ventricular', 'left', 'valve', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>{'pulmonary', 'lipomatous', 'leaflet', 'ventri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>{'pulmonary', 'arch', 'coronary', 'inflow', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>{'ventricular', 'left', 'valve', 'cardiac', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>{'ventricular', 'left', 'heart', 'ventricle', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "1  1.  The left ventricular cavity size and wall ...   \n",
       "2  2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "3  DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "4  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "0   Cardiovascular / Pulmonary   \n",
       "1   Cardiovascular / Pulmonary   \n",
       "2   Cardiovascular / Pulmonary   \n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \\\n",
       "0  2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "1  1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "2  2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "3  description1,normal,cardiac,chamber,size2,norm...   \n",
       "4  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "                                     transcription_f  \n",
       "0  {'pulmonary', 'ventricular', 'left', 'valve', ...  \n",
       "1  {'pulmonary', 'lipomatous', 'leaflet', 'ventri...  \n",
       "2  {'pulmonary', 'arch', 'coronary', 'inflow', 'a...  \n",
       "3  {'ventricular', 'left', 'valve', 'cardiac', 'm...  \n",
       "4  {'ventricular', 'left', 'heart', 'ventricle', ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_test = pd.read_csv('../data/processed/mtsamples_nlp.csv')\n",
    "df_test.transcription=df_test.transcription.astype(str)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Cardiovascular / Pulmonary',\n",
       " ' Cardiovascular / Pulmonary',\n",
       " ' Cardiovascular / Pulmonary',\n",
       " ' Cardiovascular / Pulmonary',\n",
       " ' Cardiovascular / Pulmonary',\n",
       " ' Cardiovascular / Pulmonary',\n",
       " ' Urology',\n",
       " ' General Medicine',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Surgery',\n",
       " ' Urology',\n",
       " ' Urology',\n",
       " ' Surgery',\n",
       " ' Urology',\n",
       " ' Surgery',\n",
       " ' Urology',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ' Surgery',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve labels as function\n",
    "def get_labels(data):\n",
    "    return data['medical_specialty'].tolist()\n",
    "\n",
    "df_test_label = get_labels(df_test)\n",
    "\n",
    "df_test_X = df_test['transcription_f'].astype(str)\n",
    "\n",
    "df_test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test set (first split data into train and test set to only transform the train set)\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_test_X, df_test_label)\n",
    "\n",
    "tuple = X_train, X_test, y_train, y_test \n",
    "\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = imbPipeline([\n",
    "        ('preprocessing',CountVectorizer()),\n",
    "        #('svd', TruncatedSVD(n_components=100)),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', LogisticRegression(random_state=42, multi_class='multinomial')), # remainder=\"passthrough\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.23      0.25      0.24        52\n",
      "                       Urology       0.16      0.15      0.15        40\n",
      "              General Medicine       0.25      0.33      0.29        42\n",
      "                       Surgery       0.05      0.08      0.06        25\n",
      " SOAP / Chart / Progress Notes       0.04      0.04      0.04        23\n",
      "                     Radiology       0.23      0.33      0.27        30\n",
      "                    Orthopedic       0.12      0.16      0.14        57\n",
      "       Obstetrics / Gynecology       0.07      0.06      0.06        51\n",
      "                     Neurology       0.15      0.14      0.14        35\n",
      "              Gastroenterology       0.35      0.26      0.30       212\n",
      "    Consult - History and Phy.       0.21      0.24      0.23        29\n",
      "\n",
      "                      accuracy                           0.21       596\n",
      "                     macro avg       0.17      0.19      0.18       596\n",
      "                  weighted avg       0.23      0.21      0.21       596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# poor preformance without fine tuning\n",
    "lr = model_pipeline.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "category_list = df_test.medical_specialty.unique()\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "245 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1149, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 97, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.22731092 0.21386555        nan 0.07478992        nan        nan\n",
      " 0.41344538 0.41176471        nan        nan        nan        nan\n",
      " 0.22731092 0.21386555        nan 0.33991597        nan        nan\n",
      " 0.4092437  0.40546218        nan        nan        nan        nan\n",
      " 0.22731092 0.21386555        nan 0.39831933        nan        nan\n",
      " 0.34957983 0.35084034        nan        nan        nan        nan\n",
      " 0.22731092 0.21386555        nan 0.30966387        nan        nan\n",
      " 0.25840336 0.2592437         nan        nan        nan        nan\n",
      " 0.22731092 0.21386555        nan 0.23109244        nan        nan\n",
      " 0.23067227 0.21806723        nan        nan        nan        nan\n",
      " 0.22731092 0.21386555        nan 0.2289916         nan        nan\n",
      " 0.22815126 0.21428571        nan        nan        nan        nan\n",
      " 0.22731092 0.21386555        nan 0.22731092        nan        nan\n",
      " 0.22731092 0.21428571        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter {'classifier': LogisticRegression(C=0.001, multi_class='multinomial', random_state=42,\n",
      "                   solver='saga'), 'classifier__C': 0.001, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.45      0.56      0.50        52\n",
      "                       Urology       0.40      0.20      0.27        40\n",
      "              General Medicine       0.42      0.45      0.44        42\n",
      "                       Surgery       0.17      0.16      0.17        25\n",
      " SOAP / Chart / Progress Notes       0.17      0.13      0.15        23\n",
      "                     Radiology       0.33      0.60      0.42        30\n",
      "                    Orthopedic       0.32      0.40      0.35        57\n",
      "       Obstetrics / Gynecology       0.16      0.10      0.12        51\n",
      "                     Neurology       0.16      0.23      0.19        35\n",
      "              Gastroenterology       0.53      0.47      0.50       212\n",
      "    Consult - History and Phy.       0.33      0.31      0.32        29\n",
      "\n",
      "                      accuracy                           0.38       596\n",
      "                     macro avg       0.31      0.33      0.31       596\n",
      "                  weighted avg       0.38      0.38      0.37       596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# take best model from grid search and perform evaluation\n",
    "\n",
    "param_grid = [\n",
    "    { 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "      'classifier': [LogisticRegression(multi_class='multinomial', random_state=42)],\n",
    "      'classifier__solver': ['saga', 'lbfgs', 'liblinear'],\n",
    "      'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    }\n",
    "]\n",
    "\n",
    "def grid_search(X_train, y_train, model_pipeline, param_grid):\n",
    "    search = GridSearchCV(model_pipeline, param_grid, cv=5)\n",
    "    search.fit(X_train, y_train)\n",
    "    print(\"Best parameter\", search.best_params_)\n",
    "    return search.best_estimator_\n",
    "    \n",
    "best_model = grid_search(X_train, y_train, model_pipeline, param_grid)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "category_list = df_test.medical_specialty.unique()\n",
    "# predict and evaluate\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [' Obstetrics / Gynecology']\n",
      "Actual:  Obstetrics / Gynecology\n"
     ]
    }
   ],
   "source": [
    "# Prediction for sample from test set\n",
    "sample = X_test.iloc[13]\n",
    "print(\"Prediction:\", best_model.predict([sample]))\n",
    "# Actual category of first sample from test set\n",
    "print(\"Actual:\", y_test[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of predict() and predict_proba(), highest probability not equal to prediction:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.257612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.167588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.082872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.076178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.070553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.062319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.057917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.057241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.056038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.051755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " Radiology                         0.257612\n",
       " Gastroenterology                  0.167588\n",
       " Cardiovascular / Pulmonary        0.082872\n",
       " General Medicine                  0.076178\n",
       " Orthopedic                        0.070553\n",
       " Obstetrics / Gynecology           0.062319\n",
       " Consult - History and Phy.        0.059928\n",
       " SOAP / Chart / Progress Notes     0.057917\n",
       " Urology                           0.057241\n",
       " Neurology                         0.056038\n",
       " Surgery                           0.051755"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities for a sample from test set\n",
    "print(\"Difference of predict() and predict_proba(), highest probability not equal to prediction:\")\n",
    "prob_array = best_model.predict_proba(X_test)[13,:]\n",
    "prob_df = pd.DataFrame(prob_array, index=category_list, columns=['Probability']).sort_values(by='Probability', ascending=False)\n",
    "prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0007',\n",
       " '005',\n",
       " '01',\n",
       " '0125',\n",
       " '020',\n",
       " '025',\n",
       " '03',\n",
       " '0395',\n",
       " '05',\n",
       " '050',\n",
       " '075',\n",
       " '092assessment1',\n",
       " '10',\n",
       " '100',\n",
       " '1001',\n",
       " '1007',\n",
       " '100complications',\n",
       " '102',\n",
       " '103',\n",
       " '1032',\n",
       " '104',\n",
       " '107',\n",
       " '108',\n",
       " '10872',\n",
       " '109',\n",
       " '10drains',\n",
       " '11',\n",
       " '11000',\n",
       " '1100000',\n",
       " '11070',\n",
       " '12',\n",
       " '120',\n",
       " '1200000',\n",
       " '12161',\n",
       " '122',\n",
       " '126000',\n",
       " '129',\n",
       " '12959',\n",
       " '12yearold',\n",
       " '13',\n",
       " '131',\n",
       " '13172',\n",
       " '136',\n",
       " '137',\n",
       " '13878',\n",
       " '13975',\n",
       " '13gauge',\n",
       " '14',\n",
       " '14078',\n",
       " '14080',\n",
       " '143',\n",
       " '14383',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '155',\n",
       " '158',\n",
       " '16',\n",
       " '16080',\n",
       " '168',\n",
       " '16870',\n",
       " '17',\n",
       " '17291',\n",
       " '18',\n",
       " '180110',\n",
       " '1937',\n",
       " '19373',\n",
       " '1cc',\n",
       " '1well',\n",
       " '20',\n",
       " '200',\n",
       " '2004',\n",
       " '2008',\n",
       " '2020',\n",
       " '2030',\n",
       " '204',\n",
       " '20meql',\n",
       " '21',\n",
       " '22',\n",
       " '223',\n",
       " '22591',\n",
       " '23',\n",
       " '24',\n",
       " '24hour',\n",
       " '25',\n",
       " '250',\n",
       " '25mg',\n",
       " '26',\n",
       " '269000',\n",
       " '27',\n",
       " '290',\n",
       " '297',\n",
       " '298',\n",
       " '2hypercholesterolemia',\n",
       " '30',\n",
       " '300',\n",
       " '313',\n",
       " '31493',\n",
       " '32',\n",
       " '32095',\n",
       " '32593',\n",
       " '32mm',\n",
       " '32yearold',\n",
       " '3431anesthesia',\n",
       " '35',\n",
       " '35000',\n",
       " '355c',\n",
       " '358fmsa',\n",
       " '36',\n",
       " '3695',\n",
       " '37',\n",
       " '372cms',\n",
       " '378',\n",
       " '37yearold',\n",
       " '3bipolar',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '40mg',\n",
       " '41',\n",
       " '412',\n",
       " '42',\n",
       " '425',\n",
       " '43',\n",
       " '45',\n",
       " '48',\n",
       " '484',\n",
       " '4r',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5050',\n",
       " '51yearold',\n",
       " '54',\n",
       " '56',\n",
       " '563',\n",
       " '5french',\n",
       " '60',\n",
       " '602',\n",
       " '6300',\n",
       " '64',\n",
       " '64yearold',\n",
       " '65',\n",
       " '66',\n",
       " '665',\n",
       " '6french',\n",
       " '6mm',\n",
       " '70',\n",
       " '704',\n",
       " '71',\n",
       " '713',\n",
       " '72',\n",
       " '74',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '81695in',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '84general',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '90',\n",
       " '91',\n",
       " '9163',\n",
       " '94',\n",
       " '95',\n",
       " '965',\n",
       " '975mr',\n",
       " '9th',\n",
       " 'a1c',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abdominalpelvic',\n",
       " 'abdominis',\n",
       " 'abdominus',\n",
       " 'abductor',\n",
       " 'abf',\n",
       " 'accutane',\n",
       " 'ace',\n",
       " 'acetabular',\n",
       " 'acetaminophen',\n",
       " 'acetazolamide',\n",
       " 'acetowhite',\n",
       " 'acetylcholine',\n",
       " 'achieved',\n",
       " 'acl',\n",
       " 'acromial',\n",
       " 'activase',\n",
       " 'acular',\n",
       " 'adenocarcinoma',\n",
       " 'adenoid',\n",
       " 'adenoidal',\n",
       " 'adenoma',\n",
       " 'adenosine',\n",
       " 'adhesed',\n",
       " 'adipose',\n",
       " 'adnexa',\n",
       " 'adrenal',\n",
       " 'adrenaline',\n",
       " 'adriamycin',\n",
       " 'adventitial',\n",
       " 'afb',\n",
       " 'agarose',\n",
       " 'airspace',\n",
       " 'airway',\n",
       " 'alar',\n",
       " 'albuginea',\n",
       " 'albumin',\n",
       " 'albuminanesthesia',\n",
       " 'albuterol',\n",
       " 'alcohol',\n",
       " 'aldosterone',\n",
       " 'alfentanil',\n",
       " 'alkaline',\n",
       " 'alloderm',\n",
       " 'allograft',\n",
       " 'alpha1antitrypsin',\n",
       " 'alphablocker',\n",
       " 'alphablockers',\n",
       " 'alphafetoprotein',\n",
       " 'alprazolam',\n",
       " 'alt',\n",
       " 'alta',\n",
       " 'alupent',\n",
       " 'alveolar',\n",
       " 'amiodarone',\n",
       " 'amitriptyline',\n",
       " 'amniotic',\n",
       " 'amoxacillin',\n",
       " 'amoxicillin',\n",
       " 'amoxil',\n",
       " 'amphetamine',\n",
       " 'amphotericin',\n",
       " 'ampicillin',\n",
       " 'ampulla',\n",
       " 'amylase',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'andor',\n",
       " 'anesthesia',\n",
       " 'anesthetic',\n",
       " 'aneurysm',\n",
       " 'angelica',\n",
       " 'ani',\n",
       " 'annular',\n",
       " 'anorectal',\n",
       " 'anorectum',\n",
       " 'anserine',\n",
       " 'anserinus',\n",
       " 'antacid',\n",
       " 'antebrachial',\n",
       " 'antecubital',\n",
       " 'anterior',\n",
       " 'anteroapical',\n",
       " 'anterolateral',\n",
       " 'anteromedial',\n",
       " 'anteroseptal',\n",
       " 'anterosuperior',\n",
       " 'anthracotic',\n",
       " 'antigen',\n",
       " 'antihistamine',\n",
       " 'antineuronal',\n",
       " 'antiplatelet',\n",
       " 'antral',\n",
       " 'antrostomies',\n",
       " 'antrum',\n",
       " 'anus',\n",
       " 'anxiety2',\n",
       " 'aorta',\n",
       " 'apc',\n",
       " 'apical',\n",
       " 'apl',\n",
       " 'apolipoprotein',\n",
       " 'appendiceal',\n",
       " 'approximately',\n",
       " 'aqueous',\n",
       " 'arachnoid',\n",
       " 'arch',\n",
       " 'area',\n",
       " 'areolar',\n",
       " 'aricept',\n",
       " 'aromasin',\n",
       " 'arterial',\n",
       " 'arteriosus',\n",
       " 'arteriovenous',\n",
       " 'artery',\n",
       " 'articular',\n",
       " 'asacol',\n",
       " 'ascus',\n",
       " 'aseptically',\n",
       " 'aspirin',\n",
       " 'ast',\n",
       " 'astrocyte',\n",
       " 'astrocytoma',\n",
       " 'asv',\n",
       " 'atenolol',\n",
       " 'ativan',\n",
       " 'atlantis',\n",
       " 'atresia',\n",
       " 'atrial',\n",
       " 'atrioventricular',\n",
       " 'atrium',\n",
       " 'atropine',\n",
       " 'atrovent',\n",
       " 'augmentin',\n",
       " 'auricle',\n",
       " 'auricular',\n",
       " 'autoimmune',\n",
       " 'avascular',\n",
       " 'avastin',\n",
       " 'avelox',\n",
       " 'avf',\n",
       " 'axilla',\n",
       " 'axillary',\n",
       " 'axonal',\n",
       " 'azathioprine',\n",
       " 'azithromycin',\n",
       " 'azulfidine',\n",
       " 'azygos',\n",
       " 'b12',\n",
       " 'babcock',\n",
       " 'bacitracin',\n",
       " 'back',\n",
       " 'bald',\n",
       " 'balloon',\n",
       " 'barbotage',\n",
       " 'barium',\n",
       " 'barrett',\n",
       " 'barretts',\n",
       " 'bartholin',\n",
       " 'basal',\n",
       " 'basalganglia',\n",
       " 'basil',\n",
       " 'basilar',\n",
       " 'basilic',\n",
       " 'basket',\n",
       " 'basophilic',\n",
       " 'bay',\n",
       " 'bayer',\n",
       " 'bcell',\n",
       " 'bcnu',\n",
       " 'bed',\n",
       " 'beginning',\n",
       " 'belly',\n",
       " 'benzocaine',\n",
       " 'benzoin',\n",
       " 'benzoyl',\n",
       " 'berry',\n",
       " 'beta',\n",
       " 'betablockers',\n",
       " 'betadine',\n",
       " 'betamethasone',\n",
       " 'bibasilar',\n",
       " 'bicarbonate',\n",
       " 'bicep',\n",
       " 'biceps',\n",
       " 'bicipital',\n",
       " 'bicuspid',\n",
       " 'bid3',\n",
       " 'bilateral',\n",
       " 'bilaterally',\n",
       " 'bilaterallyneuro',\n",
       " 'bilaterallyskin',\n",
       " 'bile',\n",
       " 'bileaflet',\n",
       " 'biliary',\n",
       " 'bilirubin',\n",
       " 'billroth',\n",
       " 'bilobular',\n",
       " 'biomet',\n",
       " 'biopsy',\n",
       " 'biopsysamples',\n",
       " 'birads',\n",
       " 'birthdate',\n",
       " 'bitch',\n",
       " 'biventricular',\n",
       " 'bladder',\n",
       " 'blade',\n",
       " 'blake',\n",
       " 'bleeding2',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blowout',\n",
       " 'bmp',\n",
       " 'body',\n",
       " 'body2',\n",
       " 'body3',\n",
       " 'boggy',\n",
       " 'bone',\n",
       " 'boot',\n",
       " 'bos',\n",
       " 'botox',\n",
       " 'botulinum',\n",
       " 'bovie',\n",
       " 'bowed',\n",
       " 'bowel',\n",
       " 'bowman',\n",
       " 'bp',\n",
       " 'bp12157mmhg',\n",
       " 'bp12670',\n",
       " 'bp15786',\n",
       " 'bp16090',\n",
       " 'brachial',\n",
       " 'brachialis',\n",
       " 'brachiobasilic',\n",
       " 'brachiocephalic',\n",
       " 'brachioradialis',\n",
       " 'brachium',\n",
       " 'brain',\n",
       " 'brainstem',\n",
       " 'branchial',\n",
       " 'branchii',\n",
       " 'brat',\n",
       " 'breast',\n",
       " 'brenner',\n",
       " 'bretylium',\n",
       " 'brevis',\n",
       " 'brevital',\n",
       " 'briefly',\n",
       " 'bronchioalveolar',\n",
       " 'bronchiole',\n",
       " 'bronchioloalveolar',\n",
       " 'bronchoalveolar',\n",
       " 'bronchogenic',\n",
       " 'bronchomalacia',\n",
       " 'bronchoscope',\n",
       " 'bronchus',\n",
       " 'broviac',\n",
       " 'brow',\n",
       " 'brown',\n",
       " 'brownish',\n",
       " 'brush',\n",
       " 'buccal',\n",
       " 'buck',\n",
       " 'bulb',\n",
       " 'bulbocavernosus',\n",
       " 'bulbous',\n",
       " 'bullet',\n",
       " 'bun',\n",
       " 'bupivacaine',\n",
       " 'bursa',\n",
       " 'bursal',\n",
       " 'butter',\n",
       " 'buttock',\n",
       " 'buttonholed',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'c3',\n",
       " 'c3c4',\n",
       " 'c4c5',\n",
       " 'c5',\n",
       " 'c54',\n",
       " 'c5c64',\n",
       " 'c5c7',\n",
       " 'c7t1',\n",
       " 'cad',\n",
       " 'caffeine',\n",
       " 'calcaneus',\n",
       " 'calcium',\n",
       " 'calf',\n",
       " 'caliber',\n",
       " 'caliceal',\n",
       " 'california',\n",
       " 'callosum',\n",
       " 'callus',\n",
       " 'calvarial',\n",
       " 'calvarium',\n",
       " 'calyceal',\n",
       " 'calyx',\n",
       " 'came',\n",
       " 'canal',\n",
       " 'canalicular',\n",
       " 'canaliculus',\n",
       " 'cancellous',\n",
       " 'cancer',\n",
       " 'cancerous',\n",
       " 'cane',\n",
       " 'canthal',\n",
       " 'capillary',\n",
       " 'capoten',\n",
       " 'capsular',\n",
       " 'capsule',\n",
       " 'carbohydrate',\n",
       " 'carbondioxide',\n",
       " 'carboplatin',\n",
       " 'carcinoma',\n",
       " 'carcinomaprocedures1',\n",
       " 'carcinomatumor',\n",
       " 'cardia',\n",
       " 'cardiac',\n",
       " 'cardioesophageal',\n",
       " 'cardioplegia',\n",
       " 'care',\n",
       " 'carina',\n",
       " 'carious',\n",
       " 'carmine',\n",
       " 'carnitine',\n",
       " 'carotid',\n",
       " 'carotids',\n",
       " 'carrell',\n",
       " 'cartilage',\n",
       " 'carvedilol',\n",
       " 'catheter',\n",
       " 'catheteranesthesia',\n",
       " 'catheterization4',\n",
       " 'caucasian',\n",
       " 'cauda',\n",
       " 'caudal',\n",
       " 'caudate',\n",
       " 'cauteryanesthetic',\n",
       " 'cava',\n",
       " 'cavernosum',\n",
       " 'cavitary',\n",
       " 'cavum',\n",
       " 'cbc',\n",
       " 'cc',\n",
       " 'cccomplications',\n",
       " 'ccfluids',\n",
       " 'cchistory',\n",
       " 'ccollar',\n",
       " 'ccspecimens',\n",
       " 'ccurine',\n",
       " 'cd4',\n",
       " 'cecal',\n",
       " 'cecum',\n",
       " 'cefazolin',\n",
       " 'cefotaxime',\n",
       " 'ceftriaxone',\n",
       " 'celebrex',\n",
       " 'celestone',\n",
       " 'cell',\n",
       " 'cellular',\n",
       " 'centerin',\n",
       " 'centimeter',\n",
       " 'central',\n",
       " 'centrum',\n",
       " 'cephalad',\n",
       " 'cephalic',\n",
       " 'cephazolin',\n",
       " 'cerebellar',\n",
       " 'cerebelli',\n",
       " 'cerebellum',\n",
       " 'cerebrospinal',\n",
       " 'cerebrovascular',\n",
       " 'cerumen',\n",
       " 'cervical',\n",
       " 'cervicalis',\n",
       " 'cervicovaginal',\n",
       " 'cervix',\n",
       " 'cetacaine',\n",
       " 'chang',\n",
       " 'cheek',\n",
       " 'cheese',\n",
       " 'chiasm',\n",
       " 'chlorambucil',\n",
       " 'chlorhexidine',\n",
       " 'chloride',\n",
       " 'choana',\n",
       " 'cholangiogram',\n",
       " 'cholecystic',\n",
       " 'cholecystitis',\n",
       " 'cholecystogram',\n",
       " 'cholesteatoma',\n",
       " 'cholesterol',\n",
       " 'chondral',\n",
       " 'chondroitin',\n",
       " 'chondromalacia4',\n",
       " 'chondrosarcoma',\n",
       " 'chorda',\n",
       " 'chordae',\n",
       " 'chorioretinal',\n",
       " 'choroid',\n",
       " 'choroidal',\n",
       " 'chromogranin',\n",
       " 'chyle',\n",
       " 'cialis',\n",
       " 'cicatrix',\n",
       " 'ciliary',\n",
       " 'cin',\n",
       " 'cineangiography3',\n",
       " 'cipro',\n",
       " 'ciprofloxacin',\n",
       " 'circ',\n",
       " 'circumferential',\n",
       " 'circumflex',\n",
       " 'cisplatin',\n",
       " 'cisterna',\n",
       " 'citalopram',\n",
       " 'cl',\n",
       " 'claustrum',\n",
       " 'clavicular',\n",
       " 'clearcardiovascular',\n",
       " 'cleft',\n",
       " 'cleocin',\n",
       " 'clindamycin',\n",
       " 'clinic',\n",
       " 'clinoid',\n",
       " 'clip',\n",
       " 'clitoromegaly',\n",
       " 'clivus',\n",
       " 'cll2',\n",
       " 'clobazam',\n",
       " 'clonazepam',\n",
       " 'clonidine',\n",
       " 'closed',\n",
       " 'closure',\n",
       " 'clot',\n",
       " 'clozaril',\n",
       " 'cm',\n",
       " 'cm2',\n",
       " 'cmv',\n",
       " 'cmvisceral',\n",
       " 'cns',\n",
       " 'co2',\n",
       " 'cobalt',\n",
       " 'cocaine',\n",
       " 'cocci',\n",
       " 'coccygeal',\n",
       " 'codeine',\n",
       " 'codman',\n",
       " 'colestid',\n",
       " 'collage',\n",
       " 'collagen',\n",
       " 'collarbone',\n",
       " 'collateral',\n",
       " 'collection2',\n",
       " 'colon',\n",
       " 'colonic',\n",
       " 'colorectal',\n",
       " 'columella',\n",
       " 'columellar',\n",
       " 'commissural',\n",
       " 'commissure',\n",
       " 'communis',\n",
       " 'compazine',\n",
       " 'completed',\n",
       " 'completeimpression1',\n",
       " 'concha',\n",
       " 'condyle',\n",
       " 'condylomatous',\n",
       " 'cone',\n",
       " 'conjunctiva',\n",
       " 'conray',\n",
       " 'consisting',\n",
       " 'containing',\n",
       " 'contin',\n",
       " 'conus',\n",
       " 'cookie',\n",
       " 'copaxone',\n",
       " 'copdexam',\n",
       " 'coracoacromial',\n",
       " 'coracoclavicular',\n",
       " 'coracoid',\n",
       " 'cord',\n",
       " 'cornea',\n",
       " 'corneal',\n",
       " 'corneoscleral',\n",
       " 'cornu',\n",
       " 'corona',\n",
       " 'coronary',\n",
       " 'corporal',\n",
       " 'corpus',\n",
       " 'corpuscular',\n",
       " 'cortex',\n",
       " 'cortical',\n",
       " 'corticosteroid',\n",
       " 'cortisone',\n",
       " 'cortisporin',\n",
       " 'cortrosyn',\n",
       " 'costovertebral',\n",
       " 'coumadin',\n",
       " 'count',\n",
       " 'cranial',\n",
       " 'craniopharyngioma',\n",
       " 'cream',\n",
       " 'crease',\n",
       " 'creatinine',\n",
       " 'cremasteric',\n",
       " 'cricoid',\n",
       " 'cricopharyngeus',\n",
       " 'cricothyroid',\n",
       " 'crossclamped',\n",
       " 'crp',\n",
       " 'cruciate',\n",
       " 'crural',\n",
       " 'cryoprocedure',\n",
       " 'crypt',\n",
       " 'crystalloid',\n",
       " 'crystalloidurine',\n",
       " 'csf11993',\n",
       " 'ctap',\n",
       " 'cubital',\n",
       " 'culture',\n",
       " 'curetted',\n",
       " 'curettings',\n",
       " 'cuspid',\n",
       " 'cyclogyl',\n",
       " 'cyclophosphamide',\n",
       " 'cyclosporin',\n",
       " 'cymbalta',\n",
       " 'cystic',\n",
       " 'cysto',\n",
       " 'cystoid',\n",
       " 'cytobrush',\n",
       " 'cytokeratin',\n",
       " 'cytomolecular',\n",
       " 'cytoplasmic',\n",
       " 'cytoxan',\n",
       " 'day',\n",
       " 'days2',\n",
       " 'decadron',\n",
       " 'decidual',\n",
       " 'decline',\n",
       " 'decreased',\n",
       " 'decubitus',\n",
       " 'deferens',\n",
       " 'deltoid',\n",
       " 'demerol',\n",
       " 'denies',\n",
       " 'dentin',\n",
       " 'depakene',\n",
       " 'depakote',\n",
       " 'depomedrol',\n",
       " 'dermal',\n",
       " 'desire',\n",
       " 'dexamethasone',\n",
       " 'diaphragm',\n",
       " 'diastase',\n",
       " 'diazepam',\n",
       " 'digastric',\n",
       " 'digitorum',\n",
       " 'digoxin',\n",
       " 'dilantin',\n",
       " 'dilaudid',\n",
       " 'diltiazem',\n",
       " 'dioxide',\n",
       " 'diploic',\n",
       " 'disc',\n",
       " 'diverticular',\n",
       " 'dobutamine',\n",
       " 'dolichoectasia',\n",
       " 'dolichoectatic',\n",
       " 'dopamine',\n",
       " 'dorsal',\n",
       " 'dorsi',\n",
       " 'dorsiflexors',\n",
       " 'dose',\n",
       " 'doxorubicin',\n",
       " 'doxycycline',\n",
       " 'droplet',\n",
       " 'duct',\n",
       " 'duodenal',\n",
       " 'duodenum',\n",
       " 'dura',\n",
       " 'dural',\n",
       " 'dyspepsia',\n",
       " 'dyssynergia',\n",
       " 'ear',\n",
       " 'eardrum',\n",
       " 'ebu',\n",
       " 'ecchymotic',\n",
       " 'ecstasy',\n",
       " 'edema',\n",
       " 'edematous',\n",
       " 'effaces',\n",
       " 'efferent',\n",
       " 'egg',\n",
       " 'ejaculatory',\n",
       " 'electrolyte',\n",
       " 'elevated',\n",
       " 'elixir',\n",
       " 'eminence',\n",
       " 'emissary',\n",
       " 'emphysema',\n",
       " 'enalapril',\n",
       " 'end',\n",
       " 'enddiastolic',\n",
       " 'endobronchial',\n",
       " 'endocervical',\n",
       " 'endocrine',\n",
       " 'endometrial',\n",
       " 'endometrium',\n",
       " 'endopelvic',\n",
       " 'endothoracic',\n",
       " 'endotracheal',\n",
       " 'endovascular',\n",
       " 'endplate',\n",
       " 'enema',\n",
       " 'enteral',\n",
       " 'envelope',\n",
       " 'eom',\n",
       " 'epicardial',\n",
       " 'epicardium',\n",
       " 'epicondylar',\n",
       " 'epicondyle',\n",
       " 'epicortex',\n",
       " 'epidermal',\n",
       " 'epidermis',\n",
       " 'epididymal',\n",
       " 'epididymidis',\n",
       " 'epididymis',\n",
       " 'epidural',\n",
       " 'epigastric',\n",
       " 'epigastrium',\n",
       " 'epiglottic',\n",
       " 'epinephrine',\n",
       " 'epineurium',\n",
       " 'epinuclear',\n",
       " 'epiretinal',\n",
       " 'episcleral',\n",
       " 'epithelial',\n",
       " 'epithelium',\n",
       " 'epitrochlear',\n",
       " 'epl',\n",
       " 'equina',\n",
       " 'erector',\n",
       " 'erythematous',\n",
       " 'erythromycin',\n",
       " 'eserine',\n",
       " 'esmolol',\n",
       " 'esophageal',\n",
       " 'esophagitis',\n",
       " 'esophagus',\n",
       " 'estrace',\n",
       " 'estradiol',\n",
       " 'estrogen',\n",
       " 'ethanol',\n",
       " 'ethmoid',\n",
       " 'ethmoidal',\n",
       " 'eugenol',\n",
       " 'eustachian',\n",
       " 'evaluation',\n",
       " 'event',\n",
       " 'examneurovascular',\n",
       " 'excised',\n",
       " 'exophytic',\n",
       " 'expander',\n",
       " 'expanders',\n",
       " 'extensor',\n",
       " 'extraarticular',\n",
       " 'extrahepatic',\n",
       " 'extranodal',\n",
       " 'extraocular',\n",
       " 'extraoral',\n",
       " 'extrapulmonary',\n",
       " 'exudate',\n",
       " 'eye',\n",
       " 'eyeball',\n",
       " 'eyedrop',\n",
       " 'eyelid',\n",
       " 'fallopian',\n",
       " 'fascia',\n",
       " 'fascial',\n",
       " 'fascicular',\n",
       " 'fashion',\n",
       " 'fat',\n",
       " 'fatigue3',\n",
       " 'fatty',\n",
       " 'faucial',\n",
       " 'fdp',\n",
       " 'feed',\n",
       " 'feeder',\n",
       " 'femoral',\n",
       " 'femorals',\n",
       " 'femoris',\n",
       " 'femorosaphenous',\n",
       " 'femorotibial',\n",
       " 'femur',\n",
       " 'fenofibrate',\n",
       " 'fenoldopam',\n",
       " 'fentanyl',\n",
       " 'ferric',\n",
       " 'ferritin',\n",
       " 'ferrous',\n",
       " 'fetal',\n",
       " 'fhx',\n",
       " 'fiber',\n",
       " 'fibrin',\n",
       " 'fibrinous',\n",
       " 'fibroadenoma',\n",
       " 'fibroglandular',\n",
       " 'fibroid',\n",
       " 'fibromucosa',\n",
       " 'fibromuscular',\n",
       " 'fibula',\n",
       " 'fibular',\n",
       " 'filamentous',\n",
       " 'filled',\n",
       " 'fimbria',\n",
       " 'fimbriated',\n",
       " 'fineneedle',\n",
       " 'fingerbreadth',\n",
       " 'fingernail',\n",
       " 'fingertip',\n",
       " 'fishbone',\n",
       " 'fistulous',\n",
       " 'fixed',\n",
       " 'flabby',\n",
       " 'flagyl',\n",
       " 'flail',\n",
       " 'flaky',\n",
       " 'flank',\n",
       " 'flaxseed',\n",
       " 'flexeril',\n",
       " 'flexure',\n",
       " 'flooded',\n",
       " 'floor',\n",
       " 'florinef',\n",
       " 'floxin',\n",
       " 'fludrocortisone',\n",
       " 'fluid',\n",
       " 'fluids2lurine',\n",
       " 'fluorescein',\n",
       " 'fluoride',\n",
       " 'fluoxetine',\n",
       " 'flushed',\n",
       " 'focal',\n",
       " 'fogarty',\n",
       " 'folate',\n",
       " 'folic',\n",
       " 'follicle',\n",
       " 'follicular',\n",
       " 'followed',\n",
       " 'fontanelle',\n",
       " 'foot',\n",
       " 'footanesthesia',\n",
       " 'foramen',\n",
       " 'forearm',\n",
       " 'forefoot',\n",
       " 'forehead',\n",
       " 'foreskin',\n",
       " 'fork',\n",
       " 'fornix',\n",
       " 'fosphenytoin',\n",
       " 'foveal',\n",
       " 'fraction',\n",
       " 'frayed',\n",
       " 'fremitus',\n",
       " 'french',\n",
       " 'frenulum',\n",
       " 'fresh',\n",
       " 'friable',\n",
       " 'frontal',\n",
       " 'frontoorbital',\n",
       " 'frontoparietal',\n",
       " 'frontotemporal',\n",
       " 'frontotemporoparietal',\n",
       " 'ft4',\n",
       " 'fundal',\n",
       " 'fundic',\n",
       " 'fundus',\n",
       " 'furosemide',\n",
       " 'fusiform',\n",
       " 'gabapentin',\n",
       " 'gadolinium',\n",
       " 'gag',\n",
       " 'galea',\n",
       " 'gallbladder',\n",
       " 'ganciclovir',\n",
       " 'ganglion',\n",
       " 'gangrenous',\n",
       " 'gastric',\n",
       " 'gastroc',\n",
       " 'gastrocnemius',\n",
       " 'gastrocsoleus',\n",
       " 'gastroepiploic',\n",
       " 'gastroesophageal',\n",
       " 'gastrohepatic',\n",
       " 'gastrointestinal',\n",
       " 'gastrojejunal',\n",
       " 'gbq',\n",
       " 'gemelli',\n",
       " 'gemfibrozil',\n",
       " 'general',\n",
       " 'genital',\n",
       " 'genitourinary',\n",
       " 'gentamicin',\n",
       " 'gentamycin',\n",
       " 'gentleman',\n",
       " 'gerd',\n",
       " 'gfap',\n",
       " 'gfr',\n",
       " 'gia',\n",
       " 'gingiva',\n",
       " 'given',\n",
       " 'glabella',\n",
       " 'glabellar',\n",
       " 'gland',\n",
       " 'glandular',\n",
       " 'glans',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for exploration of features, not needed for further code\n",
    "X_train_df = X_train.to_frame()\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(X_train_df[\"transcription_f\"])\n",
    "feat_df = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "feat = list(feat_df.columns)\n",
    "print(len(feat))\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\n",
      "difference of X_train split before or after pipeline\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlime_tabular\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mdifference of X_train split before or after pipeline\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m explainer \u001b[39m=\u001b[39m lime\u001b[39m.\u001b[39mlime_tabular\u001b[39m.\u001b[39mLimeTabularExplainer(X_train, feature_names\u001b[39m=\u001b[39mvectorizer\u001b[39m.\u001b[39mget_feature_names_out(), class_names\u001b[39m=\u001b[39mcategory_list)\n\u001b[1;32m      6\u001b[0m \u001b[39m# num features is the number of features to be shown\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# top lables is the number of labels with the highest probability to be shown\u001b[39;00m\n\u001b[1;32m      8\u001b[0m exp \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mexplain_instance(X_test[\u001b[39m4\u001b[39m], lr\u001b[39m.\u001b[39mpredict_proba, num_features\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, top_labels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/lime/lime_tabular.py:215\u001b[0m, in \u001b[0;36mLimeTabularExplainer.__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    209\u001b[0m     discretizer \u001b[39m=\u001b[39m StatsDiscretizer(training_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategorical_features,\n\u001b[1;32m    210\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names, labels\u001b[39m=\u001b[39mtraining_labels,\n\u001b[1;32m    211\u001b[0m                                    data_stats\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_data_stats,\n\u001b[1;32m    212\u001b[0m                                    random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m discretizer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mquartile\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretizer \u001b[39m=\u001b[39m QuartileDiscretizer(\n\u001b[1;32m    216\u001b[0m             training_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_features,\n\u001b[1;32m    217\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_names, labels\u001b[39m=\u001b[39;49mtraining_labels,\n\u001b[1;32m    218\u001b[0m             random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state)\n\u001b[1;32m    219\u001b[0m \u001b[39melif\u001b[39;00m discretizer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdecile\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretizer \u001b[39m=\u001b[39m DecileDiscretizer(\n\u001b[1;32m    221\u001b[0m             training_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategorical_features,\n\u001b[1;32m    222\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names, labels\u001b[39m=\u001b[39mtraining_labels,\n\u001b[1;32m    223\u001b[0m             random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/lime/discretize.py:178\u001b[0m, in \u001b[0;36mQuartileDiscretizer.__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, categorical_features, feature_names, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 178\u001b[0m     BaseDiscretizer\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, data, categorical_features,\n\u001b[1;32m    179\u001b[0m                              feature_names, labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m    180\u001b[0m                              random_state\u001b[39m=\u001b[39;49mrandom_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/lime/discretize.py:39\u001b[0m, in \u001b[0;36mBaseDiscretizer.__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, categorical_features, feature_names, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m              data_stats\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     24\u001b[0m     \u001b[39m\"\"\"Initializer\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m        data: numpy 2d array\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m            if you don't want these values to be computed from data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_discretize \u001b[39m=\u001b[39m ([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     40\u001b[0m                            \u001b[39mif\u001b[39;00m x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m categorical_features])\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_stats \u001b[39m=\u001b[39m data_stats\n\u001b[1;32m     42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "print(\"lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\\ndifference of X_train split before or after pipeline\")\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=vectorizer.get_feature_names_out(), class_names=category_list)\n",
    "# num features is the number of features to be shown\n",
    "# top lables is the number of labels with the highest probability to be shown\n",
    "exp = explainer.explain_instance(X_test[4], lr.predict_proba, num_features=5, top_labels=2)\n",
    "exp.show_in_notebook(show_table=True, show_all=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\n",
      "difference of X_train split before or after pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The option feature_dependence has been renamed to feature_perturbation!\n",
      "The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, or maskers.Impute)\n"
     ]
    },
    {
     "ename": "InvalidModelError",
     "evalue": "An unknown model type was passed: <class 'imblearn.pipeline.Pipeline'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidModelError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydoc\u001b[39;00m \u001b[39mimport\u001b[39;00m classname\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mdifference of X_train split before or after pipeline\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mLinearExplainer(best_model, X_train, feature_dependence\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minterventional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m shap_values \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mshap_values(X_test)\n\u001b[1;32m      6\u001b[0m shap\u001b[39m.\u001b[39msummary_plot(shap_values, X_test, class_names\u001b[39m=\u001b[39m category_list, feature_names\u001b[39m=\u001b[39mvectorizer\u001b[39m.\u001b[39mget_feature_names_out())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/shap/explainers/_linear.py:88\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, model, masker, link, nsamples, feature_perturbation, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsamples \u001b[39m=\u001b[39m nsamples\n\u001b[1;32m     87\u001b[0m \u001b[39m# extract what we need from the given model object\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept \u001b[39m=\u001b[39m Linear\u001b[39m.\u001b[39;49m_parse_model(model)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extract the data\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasker), (maskers\u001b[39m.\u001b[39mIndependent, maskers\u001b[39m.\u001b[39mPartition)):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/shap/explainers/_linear.py:265\u001b[0m, in \u001b[0;36mLinear._parse_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    263\u001b[0m         intercept \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidModelError(\u001b[39m\"\u001b[39m\u001b[39mAn unknown model type was passed: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(model)))\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m coef,intercept\n",
      "\u001b[0;31mInvalidModelError\u001b[0m: An unknown model type was passed: <class 'imblearn.pipeline.Pipeline'>"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from pydoc import classname\n",
    "print(\"lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\\ndifference of X_train split before or after pipeline\")\n",
    "explainer = shap.LinearExplainer(best_model, X_train, feature_dependence=\"interventional\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, class_names= category_list, feature_names=vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
