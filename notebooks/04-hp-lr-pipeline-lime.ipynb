{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import imblearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE    \n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "      <th>transcription_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>{'pulmonary', 'ventricular', 'left', 'valve', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>{'pulmonary', 'lipomatous', 'leaflet', 'ventri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>{'pulmonary', 'arch', 'coronary', 'inflow', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>{'ventricular', 'left', 'valve', 'cardiac', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>{'ventricular', 'left', 'heart', 'ventricle', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "1  1.  The left ventricular cavity size and wall ...   \n",
       "2  2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "3  DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "4  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "0   Cardiovascular / Pulmonary   \n",
       "1   Cardiovascular / Pulmonary   \n",
       "2   Cardiovascular / Pulmonary   \n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \\\n",
       "0  2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "1  1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "2  2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "3  description1,normal,cardiac,chamber,size2,norm...   \n",
       "4  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "                                     transcription_f  \n",
       "0  {'pulmonary', 'ventricular', 'left', 'valve', ...  \n",
       "1  {'pulmonary', 'lipomatous', 'leaflet', 'ventri...  \n",
       "2  {'pulmonary', 'arch', 'coronary', 'inflow', 'a...  \n",
       "3  {'ventricular', 'left', 'valve', 'cardiac', 'm...  \n",
       "4  {'ventricular', 'left', 'heart', 'ventricle', ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_test = pd.read_csv('../data/processed/mtsamples_nlp.csv')\n",
    "df_test.transcription=df_test.transcription.astype(str)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve labels as function\n",
    "def get_labels(data):\n",
    "    return data['medical_specialty'].tolist()\n",
    "\n",
    "df_test_label = get_labels(df_test)\n",
    "\n",
    "df_test_X = df_test['transcription_f'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set (first split data into train and test set to only transform the train set)\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_test_X, df_test_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2976, 2702)\n"
     ]
    }
   ],
   "source": [
    "# vectorize df_test_X for correlation matrix between features\n",
    "vectorizer = CountVectorizer()\n",
    "df_test_X_vec = vectorizer.fit_transform(df_test_X)\n",
    "df_test_X_vec = df_test_X_vec.toarray()\n",
    "print(df_test_X_vec.shape)\n",
    "\n",
    "df_test_X_vec = pd.DataFrame(df_test_X_vec, columns=vectorizer.get_feature_names_out ())\n",
    "df_test_X_vec.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong negative correlations:\n",
      "patient         set        -0.294474\n",
      "intervertebral  patient    -0.165295\n",
      "heart           tissue     -0.136525\n",
      "wound           heart      -0.127911\n",
      "patient         pancreas   -0.122850\n",
      "set             left       -0.119657\n",
      "adrenal         patient    -0.117364\n",
      "patient         hilar      -0.113338\n",
      "joint           tube       -0.109961\n",
      "coronary        tissue     -0.109453\n",
      "dtype: float64\n",
      "\n",
      "Strong positive correlations:\n",
      "elevated      290                   0.953302\n",
      "mmhg          290                   0.912563\n",
      "homograft     hydroxychloroquine    0.894367\n",
      "carboplatin   taxol                 0.894277\n",
      "mmhg          elevated              0.869889\n",
      "phosphorus    126000                0.865880\n",
      "qam           phosphorus            0.865880\n",
      "bicuspid      qam                   0.865880\n",
      "hypodense     intramural            0.865880\n",
      "semicircular  intermuscular         0.865880\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_unstack = df_test_X_vec.corr().unstack()\n",
    "corr_unstack = corr_unstack[corr_unstack != 1.0]\n",
    "corr_unstack = corr_unstack.sort_values().drop_duplicates()\n",
    "print(\"Strong negative correlations:\")\n",
    "print(corr_unstack.nsmallest(10))\n",
    "print()\n",
    "print(\"Strong positive correlations:\")\n",
    "print(corr_unstack.nlargest(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = imbPipeline([\n",
    "        ('preprocessing',CountVectorizer()),\n",
    "        #('svd', TruncatedSVD(n_components=100)),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', LogisticRegression(random_state=42, multi_class='multinomial')), # remainder=\"passthrough\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.23      0.25      0.24        52\n",
      "                       Urology       0.16      0.15      0.15        40\n",
      "              General Medicine       0.25      0.33      0.29        42\n",
      "                       Surgery       0.05      0.08      0.06        25\n",
      " SOAP / Chart / Progress Notes       0.04      0.04      0.04        23\n",
      "                     Radiology       0.23      0.33      0.27        30\n",
      "                    Orthopedic       0.12      0.16      0.14        57\n",
      "       Obstetrics / Gynecology       0.07      0.06      0.06        51\n",
      "                     Neurology       0.15      0.14      0.14        35\n",
      "              Gastroenterology       0.35      0.26      0.30       212\n",
      "    Consult - History and Phy.       0.21      0.24      0.23        29\n",
      "\n",
      "                      accuracy                           0.21       596\n",
      "                     macro avg       0.17      0.19      0.18       596\n",
      "                  weighted avg       0.23      0.21      0.21       596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# poor preformance without fine tuning\n",
    "lr = model_pipeline.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "category_list = df_test.medical_specialty.unique()\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameter\u001b[39m\u001b[39m\"\u001b[39m, search\u001b[39m.\u001b[39mbest_params_)\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m search\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m---> 17\u001b[0m best_model \u001b[39m=\u001b[39m grid_search(X_train, y_train, model_pipeline, param_grid)\n\u001b[1;32m     18\u001b[0m y_pred \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     20\u001b[0m category_list \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mmedical_specialty\u001b[39m.\u001b[39munique()\n",
      "Cell \u001b[0;32mIn [8], line 13\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(X_train, y_train, model_pipeline, param_grid)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrid_search\u001b[39m(X_train, y_train, model_pipeline, param_grid):\n\u001b[1;32m     12\u001b[0m     search \u001b[39m=\u001b[39m GridSearchCV(model_pipeline, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameter\u001b[39m\u001b[39m\"\u001b[39m, search\u001b[39m.\u001b[39mbest_params_)\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py:272\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    271\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 272\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, yt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1233\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1231\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1233\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[1;32m   1234\u001b[0m     path_func(\n\u001b[1;32m   1235\u001b[0m         X,\n\u001b[1;32m   1236\u001b[0m         y,\n\u001b[1;32m   1237\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1238\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1239\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1240\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1241\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1242\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1243\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1244\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1245\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1246\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1247\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1248\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1249\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1250\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1251\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1252\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1253\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m   1254\u001b[0m     )\n\u001b[1;32m   1255\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1256\u001b[0m )\n\u001b[1;32m   1258\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:436\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    432\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C\n\u001b[1;32m    433\u001b[0m iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    434\u001b[0m     np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[1;32m    435\u001b[0m ]\n\u001b[0;32m--> 436\u001b[0m opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    437\u001b[0m     func,\n\u001b[1;32m    438\u001b[0m     w0,\n\u001b[1;32m    439\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    440\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    441\u001b[0m     args\u001b[39m=\u001b[39;49m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    442\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter},\n\u001b[1;32m    443\u001b[0m )\n\u001b[1;32m    444\u001b[0m n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    445\u001b[0m     solver,\n\u001b[1;32m    446\u001b[0m     opt_res,\n\u001b[1;32m    447\u001b[0m     max_iter,\n\u001b[1;32m    448\u001b[0m     extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    450\u001b[0m w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_minimize.py:699\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    697\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    698\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 699\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    700\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    701\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    702\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    703\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_linear_loss.py:189\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads)\u001b[0m\n\u001b[1;32m    186\u001b[0m n_dof \u001b[39m=\u001b[39m n_features \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept)\n\u001b[1;32m    187\u001b[0m weights, intercept, raw_prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_w_intercept_raw(coef, X)\n\u001b[0;32m--> 189\u001b[0m loss, grad_per_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_loss\u001b[39m.\u001b[39;49mloss_gradient(\n\u001b[1;32m    190\u001b[0m     y_true\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    191\u001b[0m     raw_prediction\u001b[39m=\u001b[39;49mraw_prediction,\n\u001b[1;32m    192\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    193\u001b[0m     n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m    194\u001b[0m )\n\u001b[1;32m    195\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39msum()\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_loss\u001b[39m.\u001b[39mis_multiclass:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/_loss/loss.py:257\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     sample_weight \u001b[39m=\u001b[39m ReadonlyArrayWrapper(sample_weight)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcloss\u001b[39m.\u001b[39;49mloss_gradient(\n\u001b[1;32m    258\u001b[0m     y_true\u001b[39m=\u001b[39;49my_true,\n\u001b[1;32m    259\u001b[0m     raw_prediction\u001b[39m=\u001b[39;49mraw_prediction,\n\u001b[1;32m    260\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    261\u001b[0m     loss_out\u001b[39m=\u001b[39;49mloss_out,\n\u001b[1;32m    262\u001b[0m     gradient_out\u001b[39m=\u001b[39;49mgradient_out,\n\u001b[1;32m    263\u001b[0m     n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m    264\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# take best model from grid search and perform evaluation\n",
    "\n",
    "param_grid = [\n",
    "    { 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "      'classifier': [LogisticRegression(multi_class='multinomial', random_state=42)],\n",
    "      'classifier__solver': ['saga', 'lbfgs', 'liblinear'],\n",
    "      'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    }\n",
    "]\n",
    "\n",
    "def grid_search(X_train, y_train, model_pipeline, param_grid):\n",
    "    search = GridSearchCV(model_pipeline, param_grid, cv=5)\n",
    "    search.fit(X_train, y_train)\n",
    "    print(\"Best parameter\", search.best_params_)\n",
    "    return search.best_estimator_\n",
    "    \n",
    "best_model = grid_search(X_train, y_train, model_pipeline, param_grid)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "category_list = df_test.medical_specialty.unique()\n",
    "# predict and evaluate\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [' General Medicine']\n",
      "Actual:  SOAP / Chart / Progress Notes\n"
     ]
    }
   ],
   "source": [
    "# Prediction for sample from test set\n",
    "sample = X_test.iloc[10]\n",
    "print(\"Prediction:\", lr.predict([sample]))\n",
    "# Actual category of first sample from test set\n",
    "print(\"Actual:\", y_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'lip', 'abdomen', 'needle', 'endometrial', 'wall', 'anterior', 'cervix', 'tissue', 'fallopian', 'decidual', 'patient', 'tube', 'unclotted', 'liver', 'umbilicus', 'mesosalpinx', 'saline', 'vulsellum', 'vagina', 'left', 'midline', 'curettings', 'clot', 'fundus', 'peritoneum', 'omental', 'vesicouterine', 'uterus', 'uterine', 'blood'}\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = X_test.iloc[13]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Cardiovascular / Pulmonary', ' Consult - History and Phy.',\n",
       "       ' Gastroenterology', ' General Medicine', ' Neurology',\n",
       "       ' Obstetrics / Gynecology', ' Orthopedic', ' Radiology',\n",
       "       ' SOAP / Chart / Progress Notes', ' Surgery', ' Urology'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [' Radiology']\n",
      "                                Probability\n",
      " Radiology                            0.611\n",
      " Cardiovascular / Pulmonary           0.338\n",
      " Consult - History and Phy.           0.035\n",
      " General Medicine                     0.008\n",
      " SOAP / Chart / Progress Notes        0.004\n",
      " Gastroenterology                     0.002\n",
      " Obstetrics / Gynecology              0.001\n",
      " Orthopedic                           0.001\n",
      " Surgery                              0.000\n",
      " Urology                              0.000\n",
      " Neurology                            0.000\n"
     ]
    }
   ],
   "source": [
    "# Prediction for sample from test set\n",
    "sample = X_test.iloc[30]\n",
    "print(\"Prediction:\", lr.predict([sample]))\n",
    "# Predict probabilities for a sample from test set\n",
    "prob_array = lr.predict_proba(X_test)[30,:]\n",
    "prob_df = pd.DataFrame(prob_array, index=lr.classes_, columns=['Probability']).sort_values(by='Probability', ascending=False)\n",
    "prob_df.Probability = prob_df.Probability.round(3)\n",
    "print(prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.272830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.241453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.193900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.144196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.036220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.035474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.026937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.020467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.017649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.007424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " General Medicine                  0.272830\n",
       " Cardiovascular / Pulmonary        0.241453\n",
       " Radiology                         0.193900\n",
       " Consult - History and Phy.        0.144196\n",
       " SOAP / Chart / Progress Notes     0.036220\n",
       " Obstetrics / Gynecology           0.035474\n",
       " Gastroenterology                  0.026937\n",
       " Orthopedic                        0.020467\n",
       " Neurology                         0.017649\n",
       " Urology                           0.007424\n",
       " Surgery                           0.003452"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred = \"heart racing chest pain\"\n",
    "def predict_probability(model: imblearn.pipeline.Pipeline, value) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get probabilities for sample\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : imblearn.pipeline.Pipeline\n",
    "        best model from train.py\n",
    "    value : str\n",
    "        sample\n",
    "    category_list: list[str]\n",
    "        list of unique labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Probabilities for labels\n",
    "    \"\"\"\n",
    "\n",
    "    prob_array = model.predict_proba(value)\n",
    "    prob_df = pd.DataFrame(\n",
    "        prob_array, index=[\"Probability\"], columns=model.classes_\n",
    "    ).transpose().sort_values(by=\"Probability\", ascending=False)\n",
    "    return prob_df\n",
    "\n",
    "res_df = predict_probability(lr, [to_pred])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0007',\n",
       " '005',\n",
       " '01',\n",
       " '0125',\n",
       " '020',\n",
       " '025',\n",
       " '03',\n",
       " '0395',\n",
       " '05',\n",
       " '050',\n",
       " '075',\n",
       " '092assessment1',\n",
       " '10',\n",
       " '100',\n",
       " '1001',\n",
       " '1007',\n",
       " '100complications',\n",
       " '102',\n",
       " '103',\n",
       " '1032',\n",
       " '104',\n",
       " '107',\n",
       " '108',\n",
       " '10872',\n",
       " '109',\n",
       " '10drains',\n",
       " '11',\n",
       " '11000',\n",
       " '1100000',\n",
       " '11070',\n",
       " '12',\n",
       " '120',\n",
       " '1200000',\n",
       " '12161',\n",
       " '122',\n",
       " '126000',\n",
       " '129',\n",
       " '12959',\n",
       " '12yearold',\n",
       " '13',\n",
       " '131',\n",
       " '13172',\n",
       " '136',\n",
       " '137',\n",
       " '13878',\n",
       " '13975',\n",
       " '13gauge',\n",
       " '14',\n",
       " '14078',\n",
       " '14080',\n",
       " '143',\n",
       " '14383',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '155',\n",
       " '158',\n",
       " '16',\n",
       " '16080',\n",
       " '168',\n",
       " '16870',\n",
       " '17',\n",
       " '17291',\n",
       " '18',\n",
       " '180110',\n",
       " '1937',\n",
       " '19373',\n",
       " '1cc',\n",
       " '1well',\n",
       " '20',\n",
       " '200',\n",
       " '2004',\n",
       " '2008',\n",
       " '2020',\n",
       " '2030',\n",
       " '204',\n",
       " '20meql',\n",
       " '21',\n",
       " '22',\n",
       " '223',\n",
       " '22591',\n",
       " '23',\n",
       " '24',\n",
       " '24hour',\n",
       " '25',\n",
       " '250',\n",
       " '25mg',\n",
       " '26',\n",
       " '269000',\n",
       " '27',\n",
       " '290',\n",
       " '297',\n",
       " '298',\n",
       " '2hypercholesterolemia',\n",
       " '30',\n",
       " '300',\n",
       " '313',\n",
       " '31493',\n",
       " '32',\n",
       " '32095',\n",
       " '32593',\n",
       " '32mm',\n",
       " '32yearold',\n",
       " '3431anesthesia',\n",
       " '35',\n",
       " '35000',\n",
       " '355c',\n",
       " '358fmsa',\n",
       " '36',\n",
       " '3695',\n",
       " '37',\n",
       " '372cms',\n",
       " '378',\n",
       " '37yearold',\n",
       " '3bipolar',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '40mg',\n",
       " '41',\n",
       " '412',\n",
       " '42',\n",
       " '425',\n",
       " '43',\n",
       " '45',\n",
       " '48',\n",
       " '484',\n",
       " '4r',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5050',\n",
       " '51yearold',\n",
       " '54',\n",
       " '56',\n",
       " '563',\n",
       " '5french',\n",
       " '60',\n",
       " '602',\n",
       " '6300',\n",
       " '64',\n",
       " '64yearold',\n",
       " '65',\n",
       " '66',\n",
       " '665',\n",
       " '6french',\n",
       " '6mm',\n",
       " '70',\n",
       " '704',\n",
       " '71',\n",
       " '713',\n",
       " '72',\n",
       " '74',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '81695in',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '84general',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '90',\n",
       " '91',\n",
       " '9163',\n",
       " '94',\n",
       " '95',\n",
       " '965',\n",
       " '975mr',\n",
       " '9th',\n",
       " 'a1c',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abdominalpelvic',\n",
       " 'abdominis',\n",
       " 'abdominus',\n",
       " 'abductor',\n",
       " 'abf',\n",
       " 'accutane',\n",
       " 'ace',\n",
       " 'acetabular',\n",
       " 'acetaminophen',\n",
       " 'acetazolamide',\n",
       " 'acetowhite',\n",
       " 'acetylcholine',\n",
       " 'achieved',\n",
       " 'acl',\n",
       " 'acromial',\n",
       " 'activase',\n",
       " 'acular',\n",
       " 'adenocarcinoma',\n",
       " 'adenoid',\n",
       " 'adenoidal',\n",
       " 'adenoma',\n",
       " 'adenosine',\n",
       " 'adhesed',\n",
       " 'adipose',\n",
       " 'adnexa',\n",
       " 'adrenal',\n",
       " 'adrenaline',\n",
       " 'adriamycin',\n",
       " 'adventitial',\n",
       " 'afb',\n",
       " 'agarose',\n",
       " 'airspace',\n",
       " 'airway',\n",
       " 'alar',\n",
       " 'albuginea',\n",
       " 'albumin',\n",
       " 'albuminanesthesia',\n",
       " 'albuterol',\n",
       " 'alcohol',\n",
       " 'aldosterone',\n",
       " 'alfentanil',\n",
       " 'alkaline',\n",
       " 'alloderm',\n",
       " 'allograft',\n",
       " 'alpha1antitrypsin',\n",
       " 'alphablocker',\n",
       " 'alphablockers',\n",
       " 'alphafetoprotein',\n",
       " 'alprazolam',\n",
       " 'alt',\n",
       " 'alta',\n",
       " 'alupent',\n",
       " 'alveolar',\n",
       " 'amiodarone',\n",
       " 'amitriptyline',\n",
       " 'amniotic',\n",
       " 'amoxacillin',\n",
       " 'amoxicillin',\n",
       " 'amoxil',\n",
       " 'amphetamine',\n",
       " 'amphotericin',\n",
       " 'ampicillin',\n",
       " 'ampulla',\n",
       " 'amylase',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'andor',\n",
       " 'anesthesia',\n",
       " 'anesthetic',\n",
       " 'aneurysm',\n",
       " 'angelica',\n",
       " 'ani',\n",
       " 'annular',\n",
       " 'anorectal',\n",
       " 'anorectum',\n",
       " 'anserine',\n",
       " 'anserinus',\n",
       " 'antacid',\n",
       " 'antebrachial',\n",
       " 'antecubital',\n",
       " 'anterior',\n",
       " 'anteroapical',\n",
       " 'anterolateral',\n",
       " 'anteromedial',\n",
       " 'anteroseptal',\n",
       " 'anterosuperior',\n",
       " 'anthracotic',\n",
       " 'antigen',\n",
       " 'antihistamine',\n",
       " 'antineuronal',\n",
       " 'antiplatelet',\n",
       " 'antral',\n",
       " 'antrostomies',\n",
       " 'antrum',\n",
       " 'anus',\n",
       " 'anxiety2',\n",
       " 'aorta',\n",
       " 'apc',\n",
       " 'apical',\n",
       " 'apl',\n",
       " 'apolipoprotein',\n",
       " 'appendiceal',\n",
       " 'approximately',\n",
       " 'aqueous',\n",
       " 'arachnoid',\n",
       " 'arch',\n",
       " 'area',\n",
       " 'areolar',\n",
       " 'aricept',\n",
       " 'aromasin',\n",
       " 'arterial',\n",
       " 'arteriosus',\n",
       " 'arteriovenous',\n",
       " 'artery',\n",
       " 'articular',\n",
       " 'asacol',\n",
       " 'ascus',\n",
       " 'aseptically',\n",
       " 'aspirin',\n",
       " 'ast',\n",
       " 'astrocyte',\n",
       " 'astrocytoma',\n",
       " 'asv',\n",
       " 'atenolol',\n",
       " 'ativan',\n",
       " 'atlantis',\n",
       " 'atresia',\n",
       " 'atrial',\n",
       " 'atrioventricular',\n",
       " 'atrium',\n",
       " 'atropine',\n",
       " 'atrovent',\n",
       " 'augmentin',\n",
       " 'auricle',\n",
       " 'auricular',\n",
       " 'autoimmune',\n",
       " 'avascular',\n",
       " 'avastin',\n",
       " 'avelox',\n",
       " 'avf',\n",
       " 'axilla',\n",
       " 'axillary',\n",
       " 'axonal',\n",
       " 'azathioprine',\n",
       " 'azithromycin',\n",
       " 'azulfidine',\n",
       " 'azygos',\n",
       " 'b12',\n",
       " 'babcock',\n",
       " 'bacitracin',\n",
       " 'back',\n",
       " 'bald',\n",
       " 'balloon',\n",
       " 'barbotage',\n",
       " 'barium',\n",
       " 'barrett',\n",
       " 'barretts',\n",
       " 'bartholin',\n",
       " 'basal',\n",
       " 'basalganglia',\n",
       " 'basil',\n",
       " 'basilar',\n",
       " 'basilic',\n",
       " 'basket',\n",
       " 'basophilic',\n",
       " 'bay',\n",
       " 'bayer',\n",
       " 'bcell',\n",
       " 'bcnu',\n",
       " 'bed',\n",
       " 'beginning',\n",
       " 'belly',\n",
       " 'benzocaine',\n",
       " 'benzoin',\n",
       " 'benzoyl',\n",
       " 'berry',\n",
       " 'beta',\n",
       " 'betablockers',\n",
       " 'betadine',\n",
       " 'betamethasone',\n",
       " 'bibasilar',\n",
       " 'bicarbonate',\n",
       " 'bicep',\n",
       " 'biceps',\n",
       " 'bicipital',\n",
       " 'bicuspid',\n",
       " 'bid3',\n",
       " 'bilateral',\n",
       " 'bilaterally',\n",
       " 'bilaterallyneuro',\n",
       " 'bilaterallyskin',\n",
       " 'bile',\n",
       " 'bileaflet',\n",
       " 'biliary',\n",
       " 'bilirubin',\n",
       " 'billroth',\n",
       " 'bilobular',\n",
       " 'biomet',\n",
       " 'biopsy',\n",
       " 'biopsysamples',\n",
       " 'birads',\n",
       " 'birthdate',\n",
       " 'bitch',\n",
       " 'biventricular',\n",
       " 'bladder',\n",
       " 'blade',\n",
       " 'blake',\n",
       " 'bleeding2',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blowout',\n",
       " 'bmp',\n",
       " 'body',\n",
       " 'body2',\n",
       " 'body3',\n",
       " 'boggy',\n",
       " 'bone',\n",
       " 'boot',\n",
       " 'bos',\n",
       " 'botox',\n",
       " 'botulinum',\n",
       " 'bovie',\n",
       " 'bowed',\n",
       " 'bowel',\n",
       " 'bowman',\n",
       " 'bp',\n",
       " 'bp12157mmhg',\n",
       " 'bp12670',\n",
       " 'bp15786',\n",
       " 'bp16090',\n",
       " 'brachial',\n",
       " 'brachialis',\n",
       " 'brachiobasilic',\n",
       " 'brachiocephalic',\n",
       " 'brachioradialis',\n",
       " 'brachium',\n",
       " 'brain',\n",
       " 'brainstem',\n",
       " 'branchial',\n",
       " 'branchii',\n",
       " 'brat',\n",
       " 'breast',\n",
       " 'brenner',\n",
       " 'bretylium',\n",
       " 'brevis',\n",
       " 'brevital',\n",
       " 'briefly',\n",
       " 'bronchioalveolar',\n",
       " 'bronchiole',\n",
       " 'bronchioloalveolar',\n",
       " 'bronchoalveolar',\n",
       " 'bronchogenic',\n",
       " 'bronchomalacia',\n",
       " 'bronchoscope',\n",
       " 'bronchus',\n",
       " 'broviac',\n",
       " 'brow',\n",
       " 'brown',\n",
       " 'brownish',\n",
       " 'brush',\n",
       " 'buccal',\n",
       " 'buck',\n",
       " 'bulb',\n",
       " 'bulbocavernosus',\n",
       " 'bulbous',\n",
       " 'bullet',\n",
       " 'bun',\n",
       " 'bupivacaine',\n",
       " 'bursa',\n",
       " 'bursal',\n",
       " 'butter',\n",
       " 'buttock',\n",
       " 'buttonholed',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'c3',\n",
       " 'c3c4',\n",
       " 'c4c5',\n",
       " 'c5',\n",
       " 'c54',\n",
       " 'c5c64',\n",
       " 'c5c7',\n",
       " 'c7t1',\n",
       " 'cad',\n",
       " 'caffeine',\n",
       " 'calcaneus',\n",
       " 'calcium',\n",
       " 'calf',\n",
       " 'caliber',\n",
       " 'caliceal',\n",
       " 'california',\n",
       " 'callosum',\n",
       " 'callus',\n",
       " 'calvarial',\n",
       " 'calvarium',\n",
       " 'calyceal',\n",
       " 'calyx',\n",
       " 'came',\n",
       " 'canal',\n",
       " 'canalicular',\n",
       " 'canaliculus',\n",
       " 'cancellous',\n",
       " 'cancer',\n",
       " 'cancerous',\n",
       " 'cane',\n",
       " 'canthal',\n",
       " 'capillary',\n",
       " 'capoten',\n",
       " 'capsular',\n",
       " 'capsule',\n",
       " 'carbohydrate',\n",
       " 'carbondioxide',\n",
       " 'carboplatin',\n",
       " 'carcinoma',\n",
       " 'carcinomaprocedures1',\n",
       " 'carcinomatumor',\n",
       " 'cardia',\n",
       " 'cardiac',\n",
       " 'cardioesophageal',\n",
       " 'cardioplegia',\n",
       " 'care',\n",
       " 'carina',\n",
       " 'carious',\n",
       " 'carmine',\n",
       " 'carnitine',\n",
       " 'carotid',\n",
       " 'carotids',\n",
       " 'carrell',\n",
       " 'cartilage',\n",
       " 'carvedilol',\n",
       " 'catheter',\n",
       " 'catheteranesthesia',\n",
       " 'catheterization4',\n",
       " 'caucasian',\n",
       " 'cauda',\n",
       " 'caudal',\n",
       " 'caudate',\n",
       " 'cauteryanesthetic',\n",
       " 'cava',\n",
       " 'cavernosum',\n",
       " 'cavitary',\n",
       " 'cavum',\n",
       " 'cbc',\n",
       " 'cc',\n",
       " 'cccomplications',\n",
       " 'ccfluids',\n",
       " 'cchistory',\n",
       " 'ccollar',\n",
       " 'ccspecimens',\n",
       " 'ccurine',\n",
       " 'cd4',\n",
       " 'cecal',\n",
       " 'cecum',\n",
       " 'cefazolin',\n",
       " 'cefotaxime',\n",
       " 'ceftriaxone',\n",
       " 'celebrex',\n",
       " 'celestone',\n",
       " 'cell',\n",
       " 'cellular',\n",
       " 'centerin',\n",
       " 'centimeter',\n",
       " 'central',\n",
       " 'centrum',\n",
       " 'cephalad',\n",
       " 'cephalic',\n",
       " 'cephazolin',\n",
       " 'cerebellar',\n",
       " 'cerebelli',\n",
       " 'cerebellum',\n",
       " 'cerebrospinal',\n",
       " 'cerebrovascular',\n",
       " 'cerumen',\n",
       " 'cervical',\n",
       " 'cervicalis',\n",
       " 'cervicovaginal',\n",
       " 'cervix',\n",
       " 'cetacaine',\n",
       " 'chang',\n",
       " 'cheek',\n",
       " 'cheese',\n",
       " 'chiasm',\n",
       " 'chlorambucil',\n",
       " 'chlorhexidine',\n",
       " 'chloride',\n",
       " 'choana',\n",
       " 'cholangiogram',\n",
       " 'cholecystic',\n",
       " 'cholecystitis',\n",
       " 'cholecystogram',\n",
       " 'cholesteatoma',\n",
       " 'cholesterol',\n",
       " 'chondral',\n",
       " 'chondroitin',\n",
       " 'chondromalacia4',\n",
       " 'chondrosarcoma',\n",
       " 'chorda',\n",
       " 'chordae',\n",
       " 'chorioretinal',\n",
       " 'choroid',\n",
       " 'choroidal',\n",
       " 'chromogranin',\n",
       " 'chyle',\n",
       " 'cialis',\n",
       " 'cicatrix',\n",
       " 'ciliary',\n",
       " 'cin',\n",
       " 'cineangiography3',\n",
       " 'cipro',\n",
       " 'ciprofloxacin',\n",
       " 'circ',\n",
       " 'circumferential',\n",
       " 'circumflex',\n",
       " 'cisplatin',\n",
       " 'cisterna',\n",
       " 'citalopram',\n",
       " 'cl',\n",
       " 'claustrum',\n",
       " 'clavicular',\n",
       " 'clearcardiovascular',\n",
       " 'cleft',\n",
       " 'cleocin',\n",
       " 'clindamycin',\n",
       " 'clinic',\n",
       " 'clinoid',\n",
       " 'clip',\n",
       " 'clitoromegaly',\n",
       " 'clivus',\n",
       " 'cll2',\n",
       " 'clobazam',\n",
       " 'clonazepam',\n",
       " 'clonidine',\n",
       " 'closed',\n",
       " 'closure',\n",
       " 'clot',\n",
       " 'clozaril',\n",
       " 'cm',\n",
       " 'cm2',\n",
       " 'cmv',\n",
       " 'cmvisceral',\n",
       " 'cns',\n",
       " 'co2',\n",
       " 'cobalt',\n",
       " 'cocaine',\n",
       " 'cocci',\n",
       " 'coccygeal',\n",
       " 'codeine',\n",
       " 'codman',\n",
       " 'colestid',\n",
       " 'collage',\n",
       " 'collagen',\n",
       " 'collarbone',\n",
       " 'collateral',\n",
       " 'collection2',\n",
       " 'colon',\n",
       " 'colonic',\n",
       " 'colorectal',\n",
       " 'columella',\n",
       " 'columellar',\n",
       " 'commissural',\n",
       " 'commissure',\n",
       " 'communis',\n",
       " 'compazine',\n",
       " 'completed',\n",
       " 'completeimpression1',\n",
       " 'concha',\n",
       " 'condyle',\n",
       " 'condylomatous',\n",
       " 'cone',\n",
       " 'conjunctiva',\n",
       " 'conray',\n",
       " 'consisting',\n",
       " 'containing',\n",
       " 'contin',\n",
       " 'conus',\n",
       " 'cookie',\n",
       " 'copaxone',\n",
       " 'copdexam',\n",
       " 'coracoacromial',\n",
       " 'coracoclavicular',\n",
       " 'coracoid',\n",
       " 'cord',\n",
       " 'cornea',\n",
       " 'corneal',\n",
       " 'corneoscleral',\n",
       " 'cornu',\n",
       " 'corona',\n",
       " 'coronary',\n",
       " 'corporal',\n",
       " 'corpus',\n",
       " 'corpuscular',\n",
       " 'cortex',\n",
       " 'cortical',\n",
       " 'corticosteroid',\n",
       " 'cortisone',\n",
       " 'cortisporin',\n",
       " 'cortrosyn',\n",
       " 'costovertebral',\n",
       " 'coumadin',\n",
       " 'count',\n",
       " 'cranial',\n",
       " 'craniopharyngioma',\n",
       " 'cream',\n",
       " 'crease',\n",
       " 'creatinine',\n",
       " 'cremasteric',\n",
       " 'cricoid',\n",
       " 'cricopharyngeus',\n",
       " 'cricothyroid',\n",
       " 'crossclamped',\n",
       " 'crp',\n",
       " 'cruciate',\n",
       " 'crural',\n",
       " 'cryoprocedure',\n",
       " 'crypt',\n",
       " 'crystalloid',\n",
       " 'crystalloidurine',\n",
       " 'csf11993',\n",
       " 'ctap',\n",
       " 'cubital',\n",
       " 'culture',\n",
       " 'curetted',\n",
       " 'curettings',\n",
       " 'cuspid',\n",
       " 'cyclogyl',\n",
       " 'cyclophosphamide',\n",
       " 'cyclosporin',\n",
       " 'cymbalta',\n",
       " 'cystic',\n",
       " 'cysto',\n",
       " 'cystoid',\n",
       " 'cytobrush',\n",
       " 'cytokeratin',\n",
       " 'cytomolecular',\n",
       " 'cytoplasmic',\n",
       " 'cytoxan',\n",
       " 'day',\n",
       " 'days2',\n",
       " 'decadron',\n",
       " 'decidual',\n",
       " 'decline',\n",
       " 'decreased',\n",
       " 'decubitus',\n",
       " 'deferens',\n",
       " 'deltoid',\n",
       " 'demerol',\n",
       " 'denies',\n",
       " 'dentin',\n",
       " 'depakene',\n",
       " 'depakote',\n",
       " 'depomedrol',\n",
       " 'dermal',\n",
       " 'desire',\n",
       " 'dexamethasone',\n",
       " 'diaphragm',\n",
       " 'diastase',\n",
       " 'diazepam',\n",
       " 'digastric',\n",
       " 'digitorum',\n",
       " 'digoxin',\n",
       " 'dilantin',\n",
       " 'dilaudid',\n",
       " 'diltiazem',\n",
       " 'dioxide',\n",
       " 'diploic',\n",
       " 'disc',\n",
       " 'diverticular',\n",
       " 'dobutamine',\n",
       " 'dolichoectasia',\n",
       " 'dolichoectatic',\n",
       " 'dopamine',\n",
       " 'dorsal',\n",
       " 'dorsi',\n",
       " 'dorsiflexors',\n",
       " 'dose',\n",
       " 'doxorubicin',\n",
       " 'doxycycline',\n",
       " 'droplet',\n",
       " 'duct',\n",
       " 'duodenal',\n",
       " 'duodenum',\n",
       " 'dura',\n",
       " 'dural',\n",
       " 'dyspepsia',\n",
       " 'dyssynergia',\n",
       " 'ear',\n",
       " 'eardrum',\n",
       " 'ebu',\n",
       " 'ecchymotic',\n",
       " 'ecstasy',\n",
       " 'edema',\n",
       " 'edematous',\n",
       " 'effaces',\n",
       " 'efferent',\n",
       " 'egg',\n",
       " 'ejaculatory',\n",
       " 'electrolyte',\n",
       " 'elevated',\n",
       " 'elixir',\n",
       " 'eminence',\n",
       " 'emissary',\n",
       " 'emphysema',\n",
       " 'enalapril',\n",
       " 'end',\n",
       " 'enddiastolic',\n",
       " 'endobronchial',\n",
       " 'endocervical',\n",
       " 'endocrine',\n",
       " 'endometrial',\n",
       " 'endometrium',\n",
       " 'endopelvic',\n",
       " 'endothoracic',\n",
       " 'endotracheal',\n",
       " 'endovascular',\n",
       " 'endplate',\n",
       " 'enema',\n",
       " 'enteral',\n",
       " 'envelope',\n",
       " 'eom',\n",
       " 'epicardial',\n",
       " 'epicardium',\n",
       " 'epicondylar',\n",
       " 'epicondyle',\n",
       " 'epicortex',\n",
       " 'epidermal',\n",
       " 'epidermis',\n",
       " 'epididymal',\n",
       " 'epididymidis',\n",
       " 'epididymis',\n",
       " 'epidural',\n",
       " 'epigastric',\n",
       " 'epigastrium',\n",
       " 'epiglottic',\n",
       " 'epinephrine',\n",
       " 'epineurium',\n",
       " 'epinuclear',\n",
       " 'epiretinal',\n",
       " 'episcleral',\n",
       " 'epithelial',\n",
       " 'epithelium',\n",
       " 'epitrochlear',\n",
       " 'epl',\n",
       " 'equina',\n",
       " 'erector',\n",
       " 'erythematous',\n",
       " 'erythromycin',\n",
       " 'eserine',\n",
       " 'esmolol',\n",
       " 'esophageal',\n",
       " 'esophagitis',\n",
       " 'esophagus',\n",
       " 'estrace',\n",
       " 'estradiol',\n",
       " 'estrogen',\n",
       " 'ethanol',\n",
       " 'ethmoid',\n",
       " 'ethmoidal',\n",
       " 'eugenol',\n",
       " 'eustachian',\n",
       " 'evaluation',\n",
       " 'event',\n",
       " 'examneurovascular',\n",
       " 'excised',\n",
       " 'exophytic',\n",
       " 'expander',\n",
       " 'expanders',\n",
       " 'extensor',\n",
       " 'extraarticular',\n",
       " 'extrahepatic',\n",
       " 'extranodal',\n",
       " 'extraocular',\n",
       " 'extraoral',\n",
       " 'extrapulmonary',\n",
       " 'exudate',\n",
       " 'eye',\n",
       " 'eyeball',\n",
       " 'eyedrop',\n",
       " 'eyelid',\n",
       " 'fallopian',\n",
       " 'fascia',\n",
       " 'fascial',\n",
       " 'fascicular',\n",
       " 'fashion',\n",
       " 'fat',\n",
       " 'fatigue3',\n",
       " 'fatty',\n",
       " 'faucial',\n",
       " 'fdp',\n",
       " 'feed',\n",
       " 'feeder',\n",
       " 'femoral',\n",
       " 'femorals',\n",
       " 'femoris',\n",
       " 'femorosaphenous',\n",
       " 'femorotibial',\n",
       " 'femur',\n",
       " 'fenofibrate',\n",
       " 'fenoldopam',\n",
       " 'fentanyl',\n",
       " 'ferric',\n",
       " 'ferritin',\n",
       " 'ferrous',\n",
       " 'fetal',\n",
       " 'fhx',\n",
       " 'fiber',\n",
       " 'fibrin',\n",
       " 'fibrinous',\n",
       " 'fibroadenoma',\n",
       " 'fibroglandular',\n",
       " 'fibroid',\n",
       " 'fibromucosa',\n",
       " 'fibromuscular',\n",
       " 'fibula',\n",
       " 'fibular',\n",
       " 'filamentous',\n",
       " 'filled',\n",
       " 'fimbria',\n",
       " 'fimbriated',\n",
       " 'fineneedle',\n",
       " 'fingerbreadth',\n",
       " 'fingernail',\n",
       " 'fingertip',\n",
       " 'fishbone',\n",
       " 'fistulous',\n",
       " 'fixed',\n",
       " 'flabby',\n",
       " 'flagyl',\n",
       " 'flail',\n",
       " 'flaky',\n",
       " 'flank',\n",
       " 'flaxseed',\n",
       " 'flexeril',\n",
       " 'flexure',\n",
       " 'flooded',\n",
       " 'floor',\n",
       " 'florinef',\n",
       " 'floxin',\n",
       " 'fludrocortisone',\n",
       " 'fluid',\n",
       " 'fluids2lurine',\n",
       " 'fluorescein',\n",
       " 'fluoride',\n",
       " 'fluoxetine',\n",
       " 'flushed',\n",
       " 'focal',\n",
       " 'fogarty',\n",
       " 'folate',\n",
       " 'folic',\n",
       " 'follicle',\n",
       " 'follicular',\n",
       " 'followed',\n",
       " 'fontanelle',\n",
       " 'foot',\n",
       " 'footanesthesia',\n",
       " 'foramen',\n",
       " 'forearm',\n",
       " 'forefoot',\n",
       " 'forehead',\n",
       " 'foreskin',\n",
       " 'fork',\n",
       " 'fornix',\n",
       " 'fosphenytoin',\n",
       " 'foveal',\n",
       " 'fraction',\n",
       " 'frayed',\n",
       " 'fremitus',\n",
       " 'french',\n",
       " 'frenulum',\n",
       " 'fresh',\n",
       " 'friable',\n",
       " 'frontal',\n",
       " 'frontoorbital',\n",
       " 'frontoparietal',\n",
       " 'frontotemporal',\n",
       " 'frontotemporoparietal',\n",
       " 'ft4',\n",
       " 'fundal',\n",
       " 'fundic',\n",
       " 'fundus',\n",
       " 'furosemide',\n",
       " 'fusiform',\n",
       " 'gabapentin',\n",
       " 'gadolinium',\n",
       " 'gag',\n",
       " 'galea',\n",
       " 'gallbladder',\n",
       " 'ganciclovir',\n",
       " 'ganglion',\n",
       " 'gangrenous',\n",
       " 'gastric',\n",
       " 'gastroc',\n",
       " 'gastrocnemius',\n",
       " 'gastrocsoleus',\n",
       " 'gastroepiploic',\n",
       " 'gastroesophageal',\n",
       " 'gastrohepatic',\n",
       " 'gastrointestinal',\n",
       " 'gastrojejunal',\n",
       " 'gbq',\n",
       " 'gemelli',\n",
       " 'gemfibrozil',\n",
       " 'general',\n",
       " 'genital',\n",
       " 'genitourinary',\n",
       " 'gentamicin',\n",
       " 'gentamycin',\n",
       " 'gentleman',\n",
       " 'gerd',\n",
       " 'gfap',\n",
       " 'gfr',\n",
       " 'gia',\n",
       " 'gingiva',\n",
       " 'given',\n",
       " 'glabella',\n",
       " 'glabellar',\n",
       " 'gland',\n",
       " 'glandular',\n",
       " 'glans',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for exploration of features, not needed for further code\n",
    "X_train_df = X_train.to_frame()\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(X_train_df[\"transcription_f\"])\n",
    "feat_df = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "feat = list(feat_df.columns)\n",
    "print(len(feat))\n",
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\n",
      "difference of X_train split before or after pipeline\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlime_tabular\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mdifference of X_train split before or after pipeline\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m explainer \u001b[39m=\u001b[39m lime\u001b[39m.\u001b[39mlime_tabular\u001b[39m.\u001b[39mLimeTabularExplainer(X_train, feature_names\u001b[39m=\u001b[39mvectorizer\u001b[39m.\u001b[39mget_feature_names_out(), class_names\u001b[39m=\u001b[39mcategory_list)\n\u001b[1;32m      6\u001b[0m \u001b[39m# num features is the number of features to be shown\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# top lables is the number of labels with the highest probability to be shown\u001b[39;00m\n\u001b[1;32m      8\u001b[0m exp \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mexplain_instance(X_test[\u001b[39m4\u001b[39m], lr\u001b[39m.\u001b[39mpredict_proba, num_features\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, top_labels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/lime/lime_tabular.py:215\u001b[0m, in \u001b[0;36mLimeTabularExplainer.__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    209\u001b[0m     discretizer \u001b[39m=\u001b[39m StatsDiscretizer(training_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategorical_features,\n\u001b[1;32m    210\u001b[0m                                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names, labels\u001b[39m=\u001b[39mtraining_labels,\n\u001b[1;32m    211\u001b[0m                                    data_stats\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_data_stats,\n\u001b[1;32m    212\u001b[0m                                    random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    214\u001b[0m \u001b[39mif\u001b[39;00m discretizer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mquartile\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretizer \u001b[39m=\u001b[39m QuartileDiscretizer(\n\u001b[1;32m    216\u001b[0m             training_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_features,\n\u001b[1;32m    217\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_names, labels\u001b[39m=\u001b[39;49mtraining_labels,\n\u001b[1;32m    218\u001b[0m             random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state)\n\u001b[1;32m    219\u001b[0m \u001b[39melif\u001b[39;00m discretizer \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdecile\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscretizer \u001b[39m=\u001b[39m DecileDiscretizer(\n\u001b[1;32m    221\u001b[0m             training_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategorical_features,\n\u001b[1;32m    222\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names, labels\u001b[39m=\u001b[39mtraining_labels,\n\u001b[1;32m    223\u001b[0m             random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/lime/discretize.py:178\u001b[0m, in \u001b[0;36mQuartileDiscretizer.__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, categorical_features, feature_names, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 178\u001b[0m     BaseDiscretizer\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, data, categorical_features,\n\u001b[1;32m    179\u001b[0m                              feature_names, labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m    180\u001b[0m                              random_state\u001b[39m=\u001b[39;49mrandom_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/lime/discretize.py:39\u001b[0m, in \u001b[0;36mBaseDiscretizer.__init__\u001b[0;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, categorical_features, feature_names, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m              data_stats\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     24\u001b[0m     \u001b[39m\"\"\"Initializer\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m        data: numpy 2d array\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m            if you don't want these values to be computed from data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_discretize \u001b[39m=\u001b[39m ([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     40\u001b[0m                            \u001b[39mif\u001b[39;00m x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m categorical_features])\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_stats \u001b[39m=\u001b[39m data_stats\n\u001b[1;32m     42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "print(\"lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\\ndifference of X_train split before or after pipeline\")\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=vectorizer.get_feature_names_out(), class_names=category_list)\n",
    "# num features is the number of features to be shown\n",
    "# top lables is the number of labels with the highest probability to be shown\n",
    "exp = explainer.explain_instance(X_test[4], lr.predict_proba, num_features=5, top_labels=2)\n",
    "exp.show_in_notebook(show_table=True, show_all=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\n",
      "difference of X_train split before or after pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The option feature_dependence has been renamed to feature_perturbation!\n",
      "The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, or maskers.Impute)\n"
     ]
    },
    {
     "ename": "InvalidModelError",
     "evalue": "An unknown model type was passed: <class 'imblearn.pipeline.Pipeline'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidModelError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydoc\u001b[39;00m \u001b[39mimport\u001b[39;00m classname\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mdifference of X_train split before or after pipeline\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mLinearExplainer(best_model, X_train, feature_dependence\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minterventional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m shap_values \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mshap_values(X_test)\n\u001b[1;32m      6\u001b[0m shap\u001b[39m.\u001b[39msummary_plot(shap_values, X_test, class_names\u001b[39m=\u001b[39m category_list, feature_names\u001b[39m=\u001b[39mvectorizer\u001b[39m.\u001b[39mget_feature_names_out())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/shap/explainers/_linear.py:88\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, model, masker, link, nsamples, feature_perturbation, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsamples \u001b[39m=\u001b[39m nsamples\n\u001b[1;32m     87\u001b[0m \u001b[39m# extract what we need from the given model object\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept \u001b[39m=\u001b[39m Linear\u001b[39m.\u001b[39;49m_parse_model(model)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extract the data\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasker), (maskers\u001b[39m.\u001b[39mIndependent, maskers\u001b[39m.\u001b[39mPartition)):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/shap/explainers/_linear.py:265\u001b[0m, in \u001b[0;36mLinear._parse_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    263\u001b[0m         intercept \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidModelError(\u001b[39m\"\u001b[39m\u001b[39mAn unknown model type was passed: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(model)))\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m coef,intercept\n",
      "\u001b[0;31mInvalidModelError\u001b[0m: An unknown model type was passed: <class 'imblearn.pipeline.Pipeline'>"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "from pydoc import classname\n",
    "print(\"lime does not work here but works in notebook 02-hp-lrmodel-nlpinput.ipynb\\ndifference of X_train split before or after pipeline\")\n",
    "explainer = shap.LinearExplainer(best_model, X_train, feature_dependence=\"interventional\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, class_names= category_list, feature_names=vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
