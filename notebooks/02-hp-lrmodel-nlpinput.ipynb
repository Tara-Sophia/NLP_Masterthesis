{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE    \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/raw/mtsamples.csv')\n",
    "df.transcription=df.transcription.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 2976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, mmode, 1, left, atrial, enlargement, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[1, left, ventricular, cavity, size, wall, thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \n",
       "3  [2d, mmode, 1, left, atrial, enlargement, left...  \n",
       "4  [1, left, ventricular, cavity, size, wall, thi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 100 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription_c\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    data[\"transcription_c\"] = data[\"transcription_c\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "\n",
    "\n",
    "#apply on dataset\n",
    "df_m = clean_df(df)\n",
    "df_test = remove_punct_lower(df_m)\n",
    "df_test = lemmatize_words(df_test)\n",
    "\n",
    "\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/hannahpetry/Desktop/Work Project/NLP_Masterthesis/data/en_ner_bionlp13cg_md-0.5.1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.1 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from en-ner-bionlp13cg-md==0.5.1) (3.4.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2.4.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (65.4.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (1.0.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (8.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (0.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (3.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (3.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (1.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (1.23.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (0.7.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (0.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages (from jinja2->spacy<3.5.0,>=3.4.1->en-ner-bionlp13cg-md==0.5.1) (2.1.1)\n",
      "Building wheels for collected packages: en-ner-bionlp13cg-md\n",
      "  Building wheel for en-ner-bionlp13cg-md (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-ner-bionlp13cg-md: filename=en_ner_bionlp13cg_md-0.5.1-py3-none-any.whl size=120241147 sha256=a129e3af6632c973998a4e4c1ed6847eefa021aa97916119d25140e0c1a8d344\n",
      "  Stored in directory: /Users/hannahpetry/Library/Caches/pip/wheels/ba/dc/7b/d8d45322e45cc36e3226aef67695c2eaa65d737e0def574ef2\n",
      "Successfully built en-ner-bionlp13cg-md\n",
      "Installing collected packages: en-ner-bionlp13cg-md\n",
      "Successfully installed en-ner-bionlp13cg-md-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ../data/en_ner_bionlp13cg_md-0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "      <th>transcription_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>{valve, left, pulmonary, ventricular, mitral}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>{leaflet, ventricle, valve, left, atrium, lipo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>{aorta, valve, vessel, left, atrium, pulmonary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>{valve, left, ventricular, cardiac, mitral}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>{ventricle, left, ventricular, heart, mitral}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                      transcription_c  \\\n",
       "3   2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "4   1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "7   2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "9   description1,normal,cardiac,chamber,size2,norm...   \n",
       "11  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "                                      transcription_f  \n",
       "3       {valve, left, pulmonary, ventricular, mitral}  \n",
       "4   {leaflet, ventricle, valve, left, atrium, lipo...  \n",
       "7   {aorta, valve, vessel, left, atrium, pulmonary...  \n",
       "9         {valve, left, ventricular, cardiac, mitral}  \n",
       "11      {ventricle, left, ventricular, heart, mitral}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP with Spacy\n",
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "def medical_entities( text):\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "df_test['transcription_c'] = [','.join(map(str, l)) for l in df_test['transcription_c']]\n",
    "df_test['transcription_f'] = df_test['transcription_c'].apply(medical_entities)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       {'valve', 'left', 'pulmonary', 'ventricular', ...\n",
       "4       {'leaflet', 'ventricle', 'valve', 'left', 'atr...\n",
       "7       {'aorta', 'valve', 'vessel', 'left', 'atrium',...\n",
       "9       {'valve', 'left', 'ventricular', 'cardiac', 'm...\n",
       "11      {'ventricle', 'left', 'ventricular', 'heart', ...\n",
       "                              ...                        \n",
       "4967    {'circumflex', 'aorta', 'renal', 'pda', 'pci',...\n",
       "4968    {'aspirin', 'vessel', 'myocardial', 'femoral',...\n",
       "4971    {'blood', 'ear', 'valve', 'fat', 'muscle', 'an...\n",
       "4972    {'adenosine', 'nuclear', 'myocardial', 'patien...\n",
       "4975    {'circumflex', 'pci', 'lipid', 'gerd', 'left',...\n",
       "Name: transcription_f, Length: 2976, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.transcription_f = df_test.transcription_f.astype(str)\n",
    "df_test.transcription_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2976, 2702)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sparse matrix from transcription_f\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df_test.transcription_f)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y and apply PCA to reduce dimensionality of features\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X.toarray())\n",
    "labels = df_test['medical_specialty'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance out dataset with SMOTE, creates synthetic samples of the minority classes\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_reduced, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build model with finetuned hyperparameters\n",
    "clf = LogisticRegression(random_state=42, penalty= 'l1', solver= 'saga', multi_class='multinomial', C=1)\n",
    "lr = Pipeline(steps=[('classifier', clf)]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.71      0.75      0.73       208\n",
      "                       Urology       0.71      0.55      0.62       218\n",
      "              General Medicine       0.75      0.82      0.79       191\n",
      "                       Surgery       0.77      0.83      0.80       213\n",
      " SOAP / Chart / Progress Notes       0.72      0.81      0.77       193\n",
      "                     Radiology       0.76      0.89      0.82       202\n",
      "                    Orthopedic       0.66      0.72      0.69       202\n",
      "       Obstetrics / Gynecology       0.54      0.50      0.52       191\n",
      "                     Neurology       0.68      0.82      0.74       225\n",
      "              Gastroenterology       0.53      0.23      0.32       203\n",
      "    Consult - History and Phy.       0.87      0.92      0.89       205\n",
      "\n",
      "                      accuracy                           0.71      2251\n",
      "                     macro avg       0.70      0.71      0.70      2251\n",
      "                  weighted avg       0.70      0.71      0.70      2251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_list = df_test.medical_specialty.unique()\n",
    "# predict and evaluate\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUROC score of 0.9517\n"
     ]
    }
   ],
   "source": [
    "# ROC curve\n",
    "# Generate class membership probabilities\n",
    "y_preb_probs = lr.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_preb_probs, average=\"weighted\", multi_class=\"ovr\")\n",
    "print('Average AUROC score of', round(score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6847131496502603"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version of accuracy that also integrates measurements of chance and class imbalance\n",
    "# Generally, a score above 0.8 is considered excellent\n",
    "cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.684487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.107089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.093361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.037043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.020825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.018470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.014036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.005452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.003385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.002925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " Radiology                         0.684487\n",
       " Gastroenterology                  0.107089\n",
       " Obstetrics / Gynecology           0.093361\n",
       " Consult - History and Phy.        0.037043\n",
       " General Medicine                  0.020825\n",
       " Urology                           0.018470\n",
       " Neurology                         0.014036\n",
       " Cardiovascular / Pulmonary        0.012928\n",
       " Orthopedic                        0.005452\n",
       " SOAP / Chart / Progress Notes     0.003385\n",
       " Surgery                           0.002925"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities for a sample from test set\n",
    "prob_array = lr.predict_proba(X_test)[0,:]\n",
    "prob_df = pd.DataFrame(prob_array, index=category_list, columns=['Probability']).sort_values(by='Probability', ascending=False)\n",
    "prob_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
