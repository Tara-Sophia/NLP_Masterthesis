{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample(url, output_directory):\n",
    "    \"\"\"\n",
    "    Extracts the html from the webpage, finds the div tag with the id = 'sampletext' and performs text splitting to remove any other html elements.\n",
    "    It then writes the reamining text to a new txt file in a directory specified by output_directory.\n",
    "    \"\"\"\n",
    "    raw_html =  simple_get(url)  \n",
    "    try:\n",
    "        html = BeautifulSoup(raw_html, 'html.parser')  \n",
    "    except TypeError:\n",
    "        print('THE ERROR OCCURED AT THIS URL: '+ str(url))\n",
    "        print('RAW HTML: ')\n",
    "        print('\\n')\n",
    "        print(raw_html)\n",
    "        \n",
    "\n",
    "    for p in html.select('div'):\n",
    "        try:\n",
    "            if p['id'] == 'sampletext':\n",
    "                text = p.get_text()\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    #https://stackoverflow.com/questions/904746/how-to-remove-all-characters-after-a-specific-character-in-python\n",
    "\n",
    "    text = text.split('Sample Type', 1)[-1]\n",
    "    text = text.split('Keywords', 1)[0]\n",
    "    text = text.replace('(adsbygoogle = window.adsbygoogle || []).push({});', '')\n",
    "    text = text.replace('(Medical Transcription Sample Report)', '')\n",
    "    text = text.rstrip()\n",
    "    \n",
    "\n",
    "    title = text.split('Sample Name: ')[-1]\n",
    "    title = title.split('Description: ')[0]\n",
    "    text = text.split(title)[-1]\n",
    "    title = title.replace ('\\n', '')\n",
    "    title = title.replace(' ', '_')\n",
    "    title = title.replace('-','')\n",
    "    title = title.replace('/','_')\n",
    "    \n",
    "\n",
    "    \n",
    "    file_name = output_directory + '/' +  title + '.txt'\n",
    "\n",
    "    \n",
    "\n",
    "    text_file = open(file_name, \"w+\")\n",
    "    text_file.write(text)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.crummy.com/software/BeautifulSoup/bs4/doc/#get-text\n",
    "def retrieve_top_layer_urls(url):\n",
    "    \"\"\"\n",
    "    Retrieves the url of the subsections without the MTSamples website.\n",
    "    \"\"\"\n",
    "    links =[]\n",
    "    raw_html =  simple_get(url)  \n",
    "    html = BeautifulSoup(raw_html, 'html.parser')  \n",
    "    for link in html.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    links = [x for x in links if x is not None] \n",
    "    links =  [x for x in links if x.startswith('/site/pages/browse')]\n",
    "    del links[:40]  \n",
    "    \n",
    "    links =  [ ('http://mtsamples.com' + x) for x in links ]\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_bottom_layer_urls(url):\n",
    "    \"\"\"\n",
    "    Retrieves the url of the inidividual sample pages from the subsection pages. This has some redudancy as a url may appear multiple times on page. In the end it \n",
    "    doesn't matter because the extract_sample() function will overwrite any already existing documents with the same name. \n",
    "    \"\"\"\n",
    "    links =[]\n",
    "    raw_html =  simple_get(url)  \n",
    "    html = BeautifulSoup(raw_html, 'html.parser')  \n",
    "    for link in html.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    links = [x for x in links if x is not None]\n",
    "\n",
    "   \n",
    "    links =  [x for x in links if x.startswith('/site/pages/sample.asp')]\n",
    "    \n",
    "    links =  [ ('http://mtsamples.com' + x) for x in links ]\n",
    "\n",
    "   \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mt_samples_extractor():\n",
    "    \"\"\"\n",
    "    This function loops through all the available url links that link to inidividual samples and then calls the extract_sample() function to extract the text from the sample pages.\n",
    "    \"\"\"\n",
    "    top_level_links = retrieve_top_layer_urls('http://mtsamples.com/')\n",
    "    for i, link in enumerate(top_level_links):\n",
    "        print(i, \" : \", link)\n",
    "\n",
    "    # for x in top_level_links:\n",
    "    #     bottom_level_links = retrieve_bottom_layer_urls(x)\n",
    "    #     for y in bottom_level_links:\n",
    "    #         extract_sample(y, sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### To launch the code, in the command line write:  python web_extract.py text_folder_name\n",
    "##### Where text_folder_name is the folder into which you want the text to be written to\n",
    "mt_samples_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up code with checks and correct functions and move to other branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://mtsamples.com/site/pages/sitemap.asp\"\n",
    "base = \"https://mtsamples.com\"\n",
    "res = get(link)\n",
    "# if res.status_code == 200:\n",
    "#     print(\"Success\")\n",
    "html = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_dict = {}\n",
    "\n",
    "for section in html.find(\"ul\", {\"class\": \"list-unstyled\"}).findChildren(\"a\" , recursive=True):\n",
    "    if section.find(\"img\") is not None:\n",
    "        current_section = section.text.strip()\n",
    "        section_dict[current_section] = []\n",
    "    else:\n",
    "        section_dict[current_section].append(f\"{base}{section.get('href')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(html):\n",
    "    section_words = []\n",
    "    new_html = str(html).split('<hr/>')[1]\n",
    "    for item in html.find_all(\"b\"):\n",
    "        text = item.text.strip(\" :\")\n",
    "        if text.isupper():\n",
    "            section_words.append(text)\n",
    "                \n",
    "    return section_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergy / Immunology\n",
      "Autopsy\n",
      "Bariatrics\n",
      "Cardiovascular / Pulmonary\n",
      "Chiropractic\n",
      "Consult - History and Phy.\n",
      "Cosmetic / Plastic Surgery\n",
      "Dentistry\n",
      "Dermatology\n",
      "Diets and Nutritions\n",
      "Discharge Summary\n",
      "Emergency Room Reports\n",
      "Endocrinology\n",
      "ENT - Otolaryngology\n",
      "Gastroenterology\n",
      "General Medicine\n",
      "Hematology - Oncology\n",
      "Hospice - Palliative Care\n",
      "IME-QME-Work Comp etc.\n",
      "Lab Medicine - Pathology\n",
      "Letters\n",
      "Nephrology\n",
      "Neurology\n",
      "Neurosurgery\n",
      "Obstetrics / Gynecology\n",
      "Office Notes\n",
      "Ophthalmology\n",
      "Orthopedic\n",
      "Pain Management\n",
      "Pediatrics - Neonatal\n",
      "Physical Medicine - Rehab\n",
      "Podiatry\n",
      "Psychiatry / Psychology\n",
      "Radiology\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [599], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m res \u001b[38;5;241m=\u001b[39m get(link)\n\u001b[0;32m      6\u001b[0m html \u001b[38;5;241m=\u001b[39m BeautifulSoup(res\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m final_dict[link] \u001b[38;5;241m=\u001b[39m [\u001b[43mget_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m)\u001b[49m]\n",
      "Cell \u001b[1;32mIn [568], line 3\u001b[0m, in \u001b[0;36mget_values\u001b[1;34m(html)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values\u001b[39m(html):\n\u001b[0;32m      2\u001b[0m     section_words \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     new_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<hr/>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m html\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      5\u001b[0m         text \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "final_dict = {}\n",
    "for key, value in section_dict.items():\n",
    "    print(key)\n",
    "    for link in section_dict[key]:\n",
    "        res = get(link)\n",
    "        html = BeautifulSoup(res.content, 'html.parser')\n",
    "        final_dict[link] = [get_values(html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[SUBJECTIVE, MEDICATIONS, ALLERGIES, OBJECTIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[HISTORY, PAST MEDICAL HISTORY, PAST SURGICAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[CHIEF COMPLAINT, PAST MEDICAL HISTORY, IMMUNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[HISTORY, PAST MEDICAL HISTORY, PAST SURGICAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[HISTORY, IMPRESSION, RECOMMENDATIONS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[SUBJECTIVE, REVIEW OF SYSTEMS, PAST MEDICAL H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://mtsamples.com/site/pages/sample.asp?ty...</td>\n",
       "      <td>[ADMITTING DIAGNOSIS, DISCHARGE DIAGNOSIS, HOS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "1  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "2  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "3  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "4  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "5  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "6  https://mtsamples.com/site/pages/sample.asp?ty...   \n",
       "\n",
       "                                               words  \n",
       "0  [SUBJECTIVE, MEDICATIONS, ALLERGIES, OBJECTIVE...  \n",
       "1  [HISTORY, PAST MEDICAL HISTORY, PAST SURGICAL ...  \n",
       "2  [CHIEF COMPLAINT, PAST MEDICAL HISTORY, IMMUNI...  \n",
       "3  [HISTORY, PAST MEDICAL HISTORY, PAST SURGICAL ...  \n",
       "4             [HISTORY, IMPRESSION, RECOMMENDATIONS]  \n",
       "5  [SUBJECTIVE, REVIEW OF SYSTEMS, PAST MEDICAL H...  \n",
       "6  [ADMITTING DIAGNOSIS, DISCHARGE DIAGNOSIS, HOS...  "
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(final_dict, orient=\"columns\").melt(var_name=\"link\", value_name=\"words\")#, columns=[\"Link\", \"Words\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need sample name\n",
    "# I need url\n",
    "# I need everything between \"Description\" and \"Keywords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40268d9a6ead8a84520c08d0b901e046bd2176336d854cc732bdbdbf7245879e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
