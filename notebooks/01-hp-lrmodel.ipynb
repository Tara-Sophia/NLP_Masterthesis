{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE    \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "mtsamples_df = pd.read_csv(\"../data/raw/mtsamples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Data Cleaning\n",
    "mtsamples_df = mtsamples_df.dropna()\n",
    "mtsamples_df = mtsamples_df.drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing\n",
    "data_categories  = mtsamples_df.groupby(mtsamples_df['medical_specialty'])\n",
    "# Only use medical specialties with more than 100 samples\n",
    "filtered_data_categories = data_categories.filter(lambda x:x.shape[0] > 100)\n",
    "final_data_categories = filtered_data_categories.groupby(filtered_data_categories['medical_specialty'])\n",
    "data = filtered_data_categories[['transcription', 'medical_specialty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering functions for text (taken from Kaggle)\n",
    "def clean_text(text ): \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text1 = ''.join([w for w in text if not w.isdigit()]) \n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    #BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    \n",
    "    text2 = text1.lower()\n",
    "    text2 = REPLACE_BY_SPACE_RE.sub('', text2) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    #text2 = BAD_SYMBOLS_RE.sub('', text2)\n",
    "    return text2\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    wordlist=[]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    sentences=sent_tokenize(text)\n",
    "    \n",
    "    intial_sentences= sentences[0:1]\n",
    "    final_sentences = sentences[len(sentences)-2: len(sentences)-1]\n",
    "    \n",
    "    for sentence in intial_sentences:\n",
    "        words=word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            wordlist.append(lemmatizer.lemmatize(word))\n",
    "    for sentence in final_sentences:\n",
    "        words=word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            wordlist.append(lemmatizer.lemmatize(word))       \n",
    "    return ' '.join(wordlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Feature Engineering (taken from Kaggle)\n",
    "data['transcription'] = data['transcription'].apply(lemmatize_text)\n",
    "data['transcription'] = data['transcription'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       d mmode     mild mitral and tricuspid regurgit...\n",
       "4         there is a color doppler suggestive of a pat...\n",
       "7       d echocardiogram  multiple view of the heart a...\n",
       "9             description    normal lv systolic function \n",
       "11                d study  moderate biatrial enlargement \n",
       "                              ...                        \n",
       "4967    exam   left heart cath  selective coronary ang...\n",
       "4968    indication   acute coronary syndrome  consent ...\n",
       "4971    angina  is chest pain due to a lack of oxygen ...\n",
       "4972    indication   chest pain  type of test   adenos...\n",
       "4975    history of present illness   mr abc is a yearo...\n",
       "Name: transcription, Length: 2947, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize text and create sparse matrix\n",
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words='english',ngram_range=(1,3), max_df=0.75, use_idf=True, smooth_idf=True, max_features=1000)\n",
    "tfIdfMat  = vectorizer.fit_transform(data['transcription'].tolist())\n",
    "tfIdfMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Cardiovascular / Pulmonary', ' Urology', ' General Medicine',\n",
       "       ' Surgery', ' SOAP / Chart / Progress Notes', ' Radiology',\n",
       "       ' Orthopedic', ' Obstetrics / Gynecology', ' Neurology',\n",
       "       ' Gastroenterology', ' Consult - History and Phy.'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X and y and apply PCA to reduce dimensionality of features\n",
    "pca = PCA(n_components=0.95)\n",
    "tfIdfMat_reduced = pca.fit_transform(tfIdfMat.toarray())\n",
    "labels = data['medical_specialty'].tolist()\n",
    "category_list = data.medical_specialty.unique()\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05420611,  0.01511574,  0.10898833, ...,  0.00325415,\n",
       "         0.00301091, -0.01435424],\n",
       "       [ 0.0316351 ,  0.01493548,  0.08139049, ..., -0.02015478,\n",
       "        -0.01930347,  0.00995442],\n",
       "       [ 0.05076146,  0.00193637,  0.17429783, ...,  0.01664893,\n",
       "         0.01834395,  0.02163482],\n",
       "       ...,\n",
       "       [ 0.0862155 ,  0.01382344,  0.12266943, ...,  0.00074459,\n",
       "         0.01424753, -0.0073192 ],\n",
       "       [ 0.06285067, -0.00218799,  0.15498886, ..., -0.01984566,\n",
       "        -0.02771554,  0.01695366],\n",
       "       [ 0.27695904,  0.06378962, -0.04942733, ..., -0.01779754,\n",
       "        -0.00940408,  0.00705204]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdfMat_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include all data cleaning steps in pipeline (?)\n",
    "#cat_attribs = tfIdfMat_reduced\n",
    "\n",
    "#cat_pipeline = Pipeline([\n",
    "#        ('step1', DataFrameSelector(cat_attribs)),\n",
    "#        ('step2', StandardScaler()),\n",
    "#        ('selector', DataFrameSelector(cat_attribs)),\n",
    "#        ('cat_encoder', OneHotEncoder(sparse=False)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mt_features = cat_pipeline.fit_transform(mtsamples_df)\n",
    "#mt_features.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfIdfMat_reduced, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and train model\n",
    "# default solver would be lbfgs, but it does not support l1_ratio which combines l1 and l2 regularization\n",
    "clf = LogisticRegression(random_state=0, penalty= 'elasticnet', solver= 'saga', l1_ratio=0.5, multi_class='multinomial')\n",
    "lr = Pipeline(steps=[('classifier', clf)]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very poor performance of model with an accuracy of only 0.45 and very low f1-scores\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.32      0.22      0.26        50\n",
      "                       Urology       0.42      0.51      0.46        47\n",
      "              General Medicine       0.33      0.08      0.12        39\n",
      "                       Surgery       0.33      0.21      0.26        33\n",
      " SOAP / Chart / Progress Notes       0.35      0.36      0.35        25\n",
      "                     Radiology       0.00      0.00      0.00        27\n",
      "                    Orthopedic       0.24      0.12      0.16        52\n",
      "       Obstetrics / Gynecology       0.48      0.43      0.45        54\n",
      "                     Neurology       0.29      0.34      0.32        29\n",
      "              Gastroenterology       0.55      0.87      0.68       207\n",
      "    Consult - History and Phy.       1.00      0.11      0.20        27\n",
      "\n",
      "                      accuracy                           0.47       590\n",
      "                     macro avg       0.39      0.30      0.30       590\n",
      "                  weighted avg       0.44      0.47      0.41       590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Very poor performance of model with an accuracy of only 0.45 and very low f1-scores')\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m param_grid \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mclassifier__C\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.001\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m1000\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mclassifier__solver\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mclassifier__penalty\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39melasticnet\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m      3\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(lr, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      5\u001b[0m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1233\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1231\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1233\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[1;32m   1234\u001b[0m     path_func(\n\u001b[1;32m   1235\u001b[0m         X,\n\u001b[1;32m   1236\u001b[0m         y,\n\u001b[1;32m   1237\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1238\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1239\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1240\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1241\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1242\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1243\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1244\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1245\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1246\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1247\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1248\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1249\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1250\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1251\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1252\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1253\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[1;32m   1254\u001b[0m     )\n\u001b[1;32m   1255\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1256\u001b[0m )\n\u001b[1;32m   1258\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:495\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    492\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[1;32m    493\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[0;32m--> 495\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[1;32m    496\u001b[0m         X,\n\u001b[1;32m    497\u001b[0m         target,\n\u001b[1;32m    498\u001b[0m         sample_weight,\n\u001b[1;32m    499\u001b[0m         loss,\n\u001b[1;32m    500\u001b[0m         alpha,\n\u001b[1;32m    501\u001b[0m         beta,\n\u001b[1;32m    502\u001b[0m         max_iter,\n\u001b[1;32m    503\u001b[0m         tol,\n\u001b[1;32m    504\u001b[0m         verbose,\n\u001b[1;32m    505\u001b[0m         random_state,\n\u001b[1;32m    506\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    507\u001b[0m         max_squared_sum,\n\u001b[1;32m    508\u001b[0m         warm_start_sag,\n\u001b[1;32m    509\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    510\u001b[0m     )\n\u001b[1;32m    512\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    514\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[1;32m    516\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[0;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[1;32m    326\u001b[0m     dataset,\n\u001b[1;32m    327\u001b[0m     coef_init,\n\u001b[1;32m    328\u001b[0m     intercept_init,\n\u001b[1;32m    329\u001b[0m     n_samples,\n\u001b[1;32m    330\u001b[0m     n_features,\n\u001b[1;32m    331\u001b[0m     n_classes,\n\u001b[1;32m    332\u001b[0m     tol,\n\u001b[1;32m    333\u001b[0m     max_iter,\n\u001b[1;32m    334\u001b[0m     loss,\n\u001b[1;32m    335\u001b[0m     step_size,\n\u001b[1;32m    336\u001b[0m     alpha_scaled,\n\u001b[1;32m    337\u001b[0m     beta_scaled,\n\u001b[1;32m    338\u001b[0m     sum_gradient_init,\n\u001b[1;32m    339\u001b[0m     gradient_memory_init,\n\u001b[1;32m    340\u001b[0m     seen_init,\n\u001b[1;32m    341\u001b[0m     num_seen_init,\n\u001b[1;32m    342\u001b[0m     fit_intercept,\n\u001b[1;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[1;32m    344\u001b[0m     intercept_decay,\n\u001b[1;32m    345\u001b[0m     is_saga,\n\u001b[1;32m    346\u001b[0m     verbose,\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[1;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    353\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# finetune model and choosing best C, solver, penalty with grid search\n",
    "param_grid = {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'classifier__solver': ['saga', 'lbfgs', 'liblinear'], 'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet']}\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance only improves slightly in weighted average after finetuning\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.32      0.20      0.25        50\n",
      "                       Urology       0.35      0.47      0.40        47\n",
      "              General Medicine       0.45      0.13      0.20        39\n",
      "                       Surgery       0.32      0.24      0.28        33\n",
      " SOAP / Chart / Progress Notes       0.35      0.32      0.33        25\n",
      "                     Radiology       0.00      0.00      0.00        27\n",
      "                    Orthopedic       0.28      0.17      0.21        52\n",
      "       Obstetrics / Gynecology       0.44      0.41      0.42        54\n",
      "                     Neurology       0.32      0.34      0.33        29\n",
      "              Gastroenterology       0.56      0.86      0.68       207\n",
      "    Consult - History and Phy.       1.00      0.11      0.20        27\n",
      "\n",
      "                      accuracy                           0.46       590\n",
      "                     macro avg       0.40      0.30      0.30       590\n",
      "                  weighted avg       0.44      0.46      0.42       590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, penalty= 'l1', solver= 'saga', multi_class='multinomial', C=1)\n",
    "lr = Pipeline(steps=[('classifier', clf)]).fit(X_train, y_train)\n",
    "# predict and evaluate\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Model performance only improves slightly in weighted average after finetuning')\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))\n",
    "\n",
    "# classfifcation report function\n",
    "def classification_report_with_accuracy_score(y_test, y_pred):\n",
    "    category_list = data.medical_specialty.unique()\n",
    "    return classification_report(y_test, y_pred, target_names=category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are certain generic categories like surgery, SOAP, or Consult which are not very specific and the dataset is very unbalanced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_specialty</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                transcription\n",
       "medical_specialty                            \n",
       " Cardiovascular / Pulmonary               276\n",
       " Consult - History and Phy.               220\n",
       " Gastroenterology                         193\n",
       " General Medicine                         137\n",
       " Neurology                                162\n",
       " Obstetrics / Gynecology                  128\n",
       " Orthopedic                               296\n",
       " Radiology                                248\n",
       " SOAP / Chart / Progress Notes            140\n",
       " Surgery                                 1008\n",
       " Urology                                  139"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying some domain knowlegde to improve model performance\n",
    "# show categories with count of samples\n",
    "data_categories = data.groupby(data['medical_specialty'])\n",
    "print('There are certain generic categories like surgery, SOAP, or Consult which are not very specific and the dataset is very unbalanced')\n",
    "data_categories.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance improves significantly after balancing dataset with SMOTE\n",
      "However some categories like Gastrientology or Obstetrics / Gynecology are still not predicted well\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.67      0.71      0.69       189\n",
      "                       Urology       0.65      0.60      0.63       207\n",
      "              General Medicine       0.74      0.79      0.76       198\n",
      "                       Surgery       0.64      0.75      0.69       218\n",
      " SOAP / Chart / Progress Notes       0.59      0.70      0.64       177\n",
      "                     Radiology       0.78      0.92      0.84       191\n",
      "                    Orthopedic       0.68      0.64      0.66       206\n",
      "       Obstetrics / Gynecology       0.59      0.49      0.53       218\n",
      "                     Neurology       0.67      0.65      0.66       214\n",
      "              Gastroenterology       0.36      0.23      0.28       197\n",
      "    Consult - History and Phy.       0.79      0.82      0.80       203\n",
      "\n",
      "                      accuracy                           0.66      2218\n",
      "                     macro avg       0.65      0.67      0.65      2218\n",
      "                  weighted avg       0.65      0.66      0.65      2218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# balance out dataset with SMOTE, creates synthetic samples of the minority classes\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(tfIdfMat_reduced, labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Model performance improves significantly after balancing dataset with SMOTE')\n",
    "print('However some categories like Gastrientology or Obstetrics / Gynecology are still not predicted well')\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUROC score of 0.9552\n"
     ]
    }
   ],
   "source": [
    "# ROC curve\n",
    "# Generate class membership probabilities\n",
    "y_preb_probs = lr.predict_proba(X_test)\n",
    "score = roc_auc_score(y_test, y_preb_probs, average=\"weighted\", multi_class=\"ovr\")\n",
    "print('Average AUROC score of', round(score,4))\n",
    "\n",
    "# ROC score function\n",
    "def roc_auc_score_multiclass():\n",
    "    y_preb_probs = lr.predict_proba(X_test)\n",
    "    score = roc_auc_score(y_test, y_preb_probs, average=\"weighted\", multi_class=\"ovr\")\n",
    "    return('Average AUROC score of', round(score,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6294970150158223"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version of accuracy that also integrates measurements of chance and class imbalance\n",
    "# Generally, a score above 0.8 is considered excellent\n",
    "cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for each category\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <th>Urology</th>\n",
       "      <th>General Medicine</th>\n",
       "      <th>Surgery</th>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <th>Radiology</th>\n",
       "      <th>Orthopedic</th>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <th>Neurology</th>\n",
       "      <th>Gastroenterology</th>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>167</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Cardiovascular / Pulmonary   Urology  \\\n",
       "Actual                                                                  \n",
       " Cardiovascular / Pulmonary                             135         7   \n",
       " Urology                                                  0       125   \n",
       " General Medicine                                         3         3   \n",
       " Surgery                                                  1        19   \n",
       " SOAP / Chart / Progress Notes                            1         8   \n",
       " Radiology                                                3         1   \n",
       " Orthopedic                                               0         4   \n",
       " Obstetrics / Gynecology                                 35         1   \n",
       " Neurology                                                2        17   \n",
       " Gastroenterology                                        21         0   \n",
       " Consult - History and Phy.                               1         6   \n",
       "\n",
       "                                 General Medicine   Surgery  \\\n",
       "Actual                                                        \n",
       " Cardiovascular / Pulmonary                     2         4   \n",
       " Urology                                        2        40   \n",
       " General Medicine                             157         1   \n",
       " Surgery                                        0       164   \n",
       " SOAP / Chart / Progress Notes                  1         3   \n",
       " Radiology                                      4         0   \n",
       " Orthopedic                                     1         4   \n",
       " Obstetrics / Gynecology                        8         0   \n",
       " Neurology                                      1        36   \n",
       " Gastroenterology                              37         1   \n",
       " Consult - History and Phy.                     0         2   \n",
       "\n",
       "                                 SOAP / Chart / Progress Notes   Radiology  \\\n",
       "Actual                                                                       \n",
       " Cardiovascular / Pulmonary                                  0           3   \n",
       " Urology                                                    13           3   \n",
       " General Medicine                                            0           3   \n",
       " Surgery                                                     3           0   \n",
       " SOAP / Chart / Progress Notes                             124           2   \n",
       " Radiology                                                   0         175   \n",
       " Orthopedic                                                 13           4   \n",
       " Obstetrics / Gynecology                                    48          10   \n",
       " Neurology                                                   4           0   \n",
       " Gastroenterology                                            4          22   \n",
       " Consult - History and Phy.                                  0           3   \n",
       "\n",
       "                                 Orthopedic   Obstetrics / Gynecology  \\\n",
       "Actual                                                                  \n",
       " Cardiovascular / Pulmonary               1                        14   \n",
       " Urology                                  5                         0   \n",
       " General Medicine                         1                        13   \n",
       " Surgery                                  0                         0   \n",
       " SOAP / Chart / Progress Notes            6                        18   \n",
       " Radiology                                0                         2   \n",
       " Orthopedic                             132                        19   \n",
       " Obstetrics / Gynecology                  4                       106   \n",
       " Neurology                                8                         0   \n",
       " Gastroenterology                        34                         4   \n",
       " Consult - History and Phy.               2                         5   \n",
       "\n",
       "                                 Neurology   Gastroenterology  \\\n",
       "Actual                                                          \n",
       " Cardiovascular / Pulmonary              6                 17   \n",
       " Urology                                13                  0   \n",
       " General Medicine                        1                 14   \n",
       " Surgery                                31                  0   \n",
       " SOAP / Chart / Progress Notes           2                 11   \n",
       " Radiology                               2                  2   \n",
       " Orthopedic                              2                 25   \n",
       " Obstetrics / Gynecology                 0                  5   \n",
       " Neurology                             140                  0   \n",
       " Gastroenterology                        3                 46   \n",
       " Consult - History and Phy.              9                  8   \n",
       "\n",
       "                                 Consult - History and Phy.  Total  \n",
       "Actual                                                              \n",
       " Cardiovascular / Pulmonary                               0    189  \n",
       " Urology                                                  6    207  \n",
       " General Medicine                                         2    198  \n",
       " Surgery                                                  0    218  \n",
       " SOAP / Chart / Progress Notes                            1    177  \n",
       " Radiology                                                2    191  \n",
       " Orthopedic                                               2    206  \n",
       " Obstetrics / Gynecology                                  1    218  \n",
       " Neurology                                                6    214  \n",
       " Gastroenterology                                        25    197  \n",
       " Consult - History and Phy.                             167    203  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table with predictions\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=category_list, columns=category_list)\n",
    "index = cm_df.index\n",
    "index.name = 'Actual'\n",
    "cm_df['Total'] = cm_df.apply(lambda x: x.sum(), axis=1)\n",
    "print('Predictions for each category')\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.566344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.266607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.066584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.023439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.018870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.017109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.015937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.012332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.006744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.005774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " Surgery                           0.566344\n",
       " Urology                           0.266607\n",
       " Neurology                         0.066584\n",
       " Consult - History and Phy.        0.023439\n",
       " Orthopedic                        0.018870\n",
       " SOAP / Chart / Progress Notes     0.017109\n",
       " General Medicine                  0.015937\n",
       " Cardiovascular / Pulmonary        0.012332\n",
       " Radiology                         0.006744\n",
       " Gastroenterology                  0.005774\n",
       " Obstetrics / Gynecology           0.000260"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities for a sample from test set\n",
    "prob_array = lr.predict_proba(X_test)[0,:]\n",
    "prob_df = pd.DataFrame(prob_array, index=category_list, columns=['Probability']).sort_values(by='Probability', ascending=False)\n",
    "prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict category for a given text\n",
    "def predict_category(sample):\n",
    "    sample = lemmatize_text(sample)\n",
    "    sample = clean_text(sample)\n",
    "    sample = vectorizer.transform([sample])\n",
    "    sample = pca.transform(sample.toarray())\n",
    "    # prob_array = lr.predict_proba(sample)\n",
    "    prob_df = pd.DataFrame(sample, index=['Probability'], columns=category_list).T\n",
    "    prob_df = prob_df.sort_values(by='Probability', ascending=False)\n",
    "    return prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my heart is beating fast and i have pain in my chest'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'My heart is beating fast and I have pain in my chest'\n",
    "sample = lemmatize_text(sample)\n",
    "sample = clean_text(sample)\n",
    "sample = vectorizer.transform([sample])\n",
    "sample = pca.transform(sample.toarray())\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 540), indices imply (1, 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Predict probabilities for a new sample\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMy heart is beating fast and I have pain in my chest\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m predict_category(sample)\n",
      "Cell \u001b[0;32mIn [23], line 8\u001b[0m, in \u001b[0;36mpredict_category\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m      6\u001b[0m sample \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(sample\u001b[39m.\u001b[39mtoarray())\n\u001b[1;32m      7\u001b[0m \u001b[39m# prob_array = lr.predict_proba(sample)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m prob_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(sample, index\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mProbability\u001b[39;49m\u001b[39m'\u001b[39;49m], columns\u001b[39m=\u001b[39;49mcategory_list)\u001b[39m.\u001b[39mT\n\u001b[1;32m      9\u001b[0m prob_df \u001b[39m=\u001b[39m prob_df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProbability\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[39mreturn\u001b[39;00m prob_df\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    711\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    712\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    713\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    722\u001b[0m             data,\n\u001b[1;32m    723\u001b[0m             index,\n\u001b[1;32m    724\u001b[0m             columns,\n\u001b[1;32m    725\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    726\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    727\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    728\u001b[0m         )\n\u001b[1;32m    730\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/pandas/core/internals/construction.py:350\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    346\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    347\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 350\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/pandas/core/internals/construction.py:421\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    419\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    420\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 421\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1, 540), indices imply (1, 11)"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for a new sample\n",
    "sample = 'My heart is beating fast and I have pain in my chest'\n",
    "predict_category(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.646012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.138018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.096524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.036741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.021423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.019092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.017372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.009357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.006584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.004471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.004404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " Obstetrics / Gynecology           0.646012\n",
       " Cardiovascular / Pulmonary        0.138018\n",
       " Surgery                           0.096524\n",
       " Gastroenterology                  0.036741\n",
       " Urology                           0.021423\n",
       " SOAP / Chart / Progress Notes     0.019092\n",
       " Orthopedic                        0.017372\n",
       " General Medicine                  0.009357\n",
       " Neurology                         0.006584\n",
       " Radiology                         0.004471\n",
       " Consult - History and Phy.        0.004404"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_2 = \"Multiple views of the heart and great vessels reveal normal intracardiac and great vessel relationships.\"\n",
    "predict_category(sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "pickle.dump(lr, open('model_lr.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
