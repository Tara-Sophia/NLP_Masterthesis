{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import imblearn\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from traitlets import List\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/processed/mtsamples_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline() -> imblearn.pipeline.Pipeline:\n",
    "    \"\"\"\n",
    "    Build pipeline for model\n",
    "    \"\"\"\n",
    "    model_pipeline = imbPipeline(\n",
    "        [\n",
    "            (\"preprocessing\", CountVectorizer()),\n",
    "            (\"smote\", SMOTE(random_state=42)),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    random_state=42,\n",
    "                ),\n",
    "            ),  # remainder=\"passthrough\"\n",
    "        ]\n",
    "    )\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = build_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline.fit(training_data.transcription_f, training_data.medical_specialty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(model: imblearn.pipeline.Pipeline, value: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get probabilities for sample\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : imblearn.pipeline.Pipeline\n",
    "        best model from train.py\n",
    "    value : str\n",
    "        sample\n",
    "    category_list: list[str]\n",
    "        list of unique labels\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Probabilities for labels\n",
    "    \"\"\"\n",
    "\n",
    "    prob_array = model.predict_proba(value)\n",
    "    prob_df = (\n",
    "        pd.DataFrame(prob_array, index=[\"Probability\"], columns=model.classes_)\n",
    "        .transpose()\n",
    "        .sort_values(by=\"Probability\", ascending=False)\n",
    "    )\n",
    "    return prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Probability\n",
      " Cardiovascular / Pulmonary        0.725316\n",
      " Radiology                         0.153696\n",
      " General Medicine                  0.088011\n",
      " Obstetrics / Gynecology           0.016509\n",
      " Consult - History and Phy.        0.011008\n",
      " Surgery                           0.004094\n",
      " Neurology                         0.000660\n",
      " Gastroenterology                  0.000326\n",
      " SOAP / Chart / Progress Notes     0.000313\n",
      " Urology                           0.000049\n",
      " Orthopedic                        0.000018\n"
     ]
    }
   ],
   "source": [
    "# Predict probability\n",
    "to_pred = \"coronary nitroglycerin muscle heart breast oxygen valve artery\"\n",
    "res_df = predict_probability(model, [to_pred])\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_explainer(model: imblearn.pipeline.Pipeline, value: str):\n",
    "    \"\"\"\n",
    "    Get features the model used for top predicted classes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : imblearn.pipeline.Pipeline\n",
    "        best model from train.py\n",
    "    value : str\n",
    "        sample\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Features from sample the model used to predict classes\n",
    "    \"\"\"\n",
    "    explainer = LimeTextExplainer(class_names=model.classes_)\n",
    "    num_features = len(value.split())\n",
    "    exp = explainer.explain_instance(\n",
    "        value, model.predict_proba, num_features=num_features, top_labels=3\n",
    "    )\n",
    "    feat_importance = exp.as_map()\n",
    "    feat_importance = {model.classes_[k]: v for k, v in feat_importance.items()}\n",
    "    feat_importance = {\n",
    "        k: [(value.split()[i], v) for i, v in v] for k, v in feat_importance.items()\n",
    "    }\n",
    "    feat_importance_pos = {\n",
    "        k: [v for v in v if v[1] > 0] for k, v in feat_importance.items()\n",
    "    }\n",
    "    return feat_importance_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' General Medicine': [('breast', 0.08721571703500162), ('muscle', 0.07988169304133039), ('heart', 0.03135017615158257), ('oxygen', 0.030225364661143464)], ' Radiology': [('artery', 0.14760497121135482), ('nitroglycerin', 0.07510531220124371), ('muscle', 0.043301535530355345)], ' Cardiovascular / Pulmonary': [('oxygen', 0.25242070018155083), ('artery', 0.22901780568996302), ('heart', 0.21310866418142863), ('coronary', 0.19967080647956545), ('valve', 0.13323602638065268)]}\n"
     ]
    }
   ],
   "source": [
    "# features the model used for top predicted classes\n",
    "feat_importance = lime_explainer(model, to_pred)\n",
    "print(feat_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ' General Medicine'\n",
    "\n",
    "# if key is in dict return value (first value in list)\n",
    "def get_value(x):\n",
    "    if x in feat_importance:\n",
    "        return feat_importance[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = get_value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breast', 'muscle', 'heart', 'oxygen']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only access words in list\n",
    "words = [v[0] for v in value]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine get_value and words into one function\n",
    "def get_words(x):\n",
    "    if x in feat_importance:\n",
    "        value = feat_importance[x]\n",
    "        words = [v[0] for v in value]\n",
    "        return words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breast', 'muscle', 'heart', 'oxygen']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=model.classes_)\n",
    "num_features = len(to_pred.split())\n",
    "exp = explainer.explain_instance(\n",
    "    to_pred, model.predict_proba, num_features=num_features, top_labels=3\n",
    ")\n",
    "feat_importance = exp.as_map()\n",
    "feat_importance = {model.classes_[k]: v for k, v in feat_importance.items()}\n",
    "feat_importance = {\n",
    "    k: [(to_pred.split()[i], v) for i, v in v] for k, v in feat_importance.items()\n",
    "}\n",
    "feat_importance_pos = {\n",
    "    k: [v for v in v if v[1] > 0] for k, v in feat_importance.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' General Medicine': [('artery', -0.1869880324487356),\n",
       "  ('breast', 0.0880783857407666),\n",
       "  ('muscle', 0.07814815334554133),\n",
       "  ('valve', -0.060311035364575015),\n",
       "  ('heart', 0.03292414708991069),\n",
       "  ('oxygen', 0.026857580194068784),\n",
       "  ('nitroglycerin', -0.021849195996523633),\n",
       "  ('coronary', -0.006822275744941747)],\n",
       " ' Radiology': [('oxygen', -0.19120402466101397),\n",
       "  ('artery', 0.14181291398386572),\n",
       "  ('nitroglycerin', 0.07048150048241235),\n",
       "  ('muscle', 0.04382698549680477),\n",
       "  ('coronary', -0.023307206099310092),\n",
       "  ('heart', -0.022521716599489632),\n",
       "  ('breast', -0.019836767093437305),\n",
       "  ('valve', -0.008045373440971927)],\n",
       " ' Cardiovascular / Pulmonary': [('oxygen', 0.256451435035843),\n",
       "  ('artery', 0.23452081596977184),\n",
       "  ('heart', 0.21094362769758024),\n",
       "  ('coronary', 0.1995309298470315),\n",
       "  ('breast', -0.19744731236806046),\n",
       "  ('muscle', -0.13769584310116986),\n",
       "  ('valve', 0.1374394013956226),\n",
       "  ('nitroglycerin', -0.065400545820238)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.725316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.153696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.088011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.016509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.011008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.004094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " Cardiovascular / Pulmonary        0.725316\n",
       " Radiology                         0.153696\n",
       " General Medicine                  0.088011\n",
       " Obstetrics / Gynecology           0.016509\n",
       " Consult - History and Phy.        0.011008\n",
       " Surgery                           0.004094\n",
       " Neurology                         0.000660\n",
       " Gastroenterology                  0.000326\n",
       " SOAP / Chart / Progress Notes     0.000313\n",
       " Urology                           0.000049\n",
       " Orthopedic                        0.000018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_probability(model, [to_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to explain lime output\n",
    "# https://stackoverflow.com/questions/53895007/how-to-interpret-lime-output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_masterthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
