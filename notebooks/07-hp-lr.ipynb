{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import imblearn\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from traitlets import List\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/processed/mtsamples_nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline() -> imblearn.pipeline.Pipeline:\n",
    "    \"\"\"\n",
    "    Build pipeline for model\n",
    "    \"\"\"\n",
    "    model_pipeline = imbPipeline(\n",
    "        [\n",
    "            (\"preprocessing\", CountVectorizer()),\n",
    "            (\"smote\", SMOTE(random_state=42)),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    random_state=42, penalty=\"l1\", multi_class=\"multinomial\", solver='saga', C=1\n",
    "                ),\n",
    "            ),  # remainder=\"passthrough\"\n",
    "        ]\n",
    "    )\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = build_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline.fit(training_data.transcription_f, training_data.medical_specialty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456375838926175"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy @k\n",
    "y_preb_probs = model.predict_proba(testing_data.transcription_f)\n",
    "top = np.argsort(y_preb_probs, axis=1)[:, -3:]\n",
    "top = np.apply_along_axis(lambda x: model.classes_[x], 1, top)\n",
    "actual = np.array(testing_data.medical_specialty).reshape(-1, 1)\n",
    "np.any(top == actual, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456375838926175"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preb_probs = model.predict_proba(testing_data.transcription_f)\n",
    "top = np.argsort(y_preb_probs, axis=1)[:, -3:]\n",
    "top = np.apply_along_axis(lambda x: model.classes_[x], 1, top)\n",
    "actual = np.array(testing_data.medical_specialty).reshape(-1, 1)\n",
    "np.any(top == actual, axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(\n",
    "    X_train: pd.core.series.Series,\n",
    "    y_train: list,\n",
    "    model_pipeline: imblearn.pipeline.Pipeline,\n",
    "    param_grid: list,\n",
    ") -> imblearn.pipeline.Pipeline:\n",
    "    \"\"\"\n",
    "    Grid search for best model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.core.series.Series\n",
    "        train data\n",
    "    y_train : list\n",
    "        train labels\n",
    "    model_pipeline : imblearn.pipeline.Pipeline\n",
    "        pipeline for model\n",
    "    param_grid : list\n",
    "        list of parameters for grid search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    imblearn.pipeline.Pipeline\n",
    "        best model\n",
    "    \"\"\"\n",
    "    search = GridSearchCV(model_pipeline, param_grid, cv=5)\n",
    "    search.fit(X_train, y_train)\n",
    "    print(\"Best parameters:\", search.best_params_)\n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy_function(model, X_test, y_test, k):\n",
    "    \"\"\"\n",
    "    Custom scorer with accuracy @k\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : imblearn.pipeline.Pipeline\n",
    "        pipeline for model\n",
    "    X_test: pd.core.series.Series\n",
    "        train data\n",
    "    y_test: list\n",
    "        train labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        accuracy @k\n",
    "    \"\"\"\n",
    "    y_preb_probs = model.predict_proba(X_test)\n",
    "    top = np.argsort(y_preb_probs, axis=1)[:, -k:]\n",
    "    top = np.apply_along_axis(lambda x: model.classes_[x], 1, top)\n",
    "    actual = np.array(y_test).reshape(-1, 1)\n",
    "    return np.any(top == actual, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "        {\n",
    "            \"classifier__C\": [0.01, 0.1, 1, 10],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "best_model = grid_search(\n",
    "    training_data.transcription_f,\n",
    "    training_data.medical_specialty,\n",
    "    model_pipeline,\n",
    "    param_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835570469798657"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preb_probs = best_model.predict_proba(testing_data.transcription_f)\n",
    "top = np.argsort(y_preb_probs, axis=1)[:, -3:]\n",
    "top = np.apply_along_axis(lambda x: model.classes_[x], 1, top)\n",
    "actual = np.array(testing_data.medical_specialty).reshape(-1, 1)\n",
    "np.any(top == actual, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(model: imblearn.pipeline.Pipeline, value: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get probabilities for sample\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : imblearn.pipeline.Pipeline\n",
    "        best model from train.py\n",
    "    value : str\n",
    "        sample\n",
    "    category_list: list[str]\n",
    "        list of unique labels\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Probabilities for labels\n",
    "    \"\"\"\n",
    "\n",
    "    prob_array = model.predict_proba(value)\n",
    "    prob_df = (\n",
    "        pd.DataFrame(prob_array, index=[\"Probability\"], columns=model.classes_)\n",
    "        .transpose()\n",
    "        .sort_values(by=\"Probability\", ascending=False)\n",
    "    )\n",
    "    return prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Probability\n",
      " Cardiovascular / Pulmonary        0.725316\n",
      " Radiology                         0.153696\n",
      " General Medicine                  0.088011\n",
      " Obstetrics / Gynecology           0.016509\n",
      " Consult - History and Phy.        0.011008\n",
      " Surgery                           0.004094\n",
      " Neurology                         0.000660\n",
      " Gastroenterology                  0.000326\n",
      " SOAP / Chart / Progress Notes     0.000313\n",
      " Urology                           0.000049\n",
      " Orthopedic                        0.000018\n"
     ]
    }
   ],
   "source": [
    "# Predict probability\n",
    "to_pred = \"coronary nitroglycerin muscle heart breast oxygen valve artery\"\n",
    "res_df = predict_probability(model, [to_pred])\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_explainer(model: imblearn.pipeline.Pipeline, value: str):\n",
    "    \"\"\"\n",
    "    Get features the model used for top predicted classes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : imblearn.pipeline.Pipeline\n",
    "        best model from train.py\n",
    "    value : str\n",
    "        sample\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Features from sample the model used to predict classes\n",
    "    \"\"\"\n",
    "    explainer = LimeTextExplainer(class_names=model.classes_)\n",
    "    num_features = len(value.split())\n",
    "    exp = explainer.explain_instance(\n",
    "        value, model.predict_proba, num_features=num_features, top_labels=3\n",
    "    )\n",
    "    feat_importance = exp.as_map()\n",
    "    feat_importance = {model.classes_[k]: v for k, v in feat_importance.items()}\n",
    "    feat_importance = {\n",
    "        k: [(value.split()[i], v) for i, v in v] for k, v in feat_importance.items()\n",
    "    }\n",
    "    feat_importance_pos = {\n",
    "        k: [v for v in v if v[1] > 0] for k, v in feat_importance.items()\n",
    "    }\n",
    "    return feat_importance_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' General Medicine': [('breast', 0.08721571703500162), ('muscle', 0.07988169304133039), ('heart', 0.03135017615158257), ('oxygen', 0.030225364661143464)], ' Radiology': [('artery', 0.14760497121135482), ('nitroglycerin', 0.07510531220124371), ('muscle', 0.043301535530355345)], ' Cardiovascular / Pulmonary': [('oxygen', 0.25242070018155083), ('artery', 0.22901780568996302), ('heart', 0.21310866418142863), ('coronary', 0.19967080647956545), ('valve', 0.13323602638065268)]}\n"
     ]
    }
   ],
   "source": [
    "# features the model used for top predicted classes\n",
    "feat_importance = lime_explainer(model, to_pred)\n",
    "print(feat_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ' General Medicine'\n",
    "\n",
    "# if key is in dict return value (first value in list)\n",
    "def get_value(x):\n",
    "    if x in feat_importance:\n",
    "        return feat_importance[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = get_value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breast', 'muscle', 'heart', 'oxygen']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only access words in list\n",
    "words = [v[0] for v in value]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine get_value and words into one function\n",
    "def get_words(x):\n",
    "    if x in feat_importance:\n",
    "        value = feat_importance[x]\n",
    "        words = [v[0] for v in value]\n",
    "        return words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breast', 'muscle', 'heart', 'oxygen']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=model.classes_)\n",
    "num_features = len(to_pred.split())\n",
    "exp = explainer.explain_instance(\n",
    "    to_pred, model.predict_proba, num_features=num_features, top_labels=3\n",
    ")\n",
    "feat_importance = exp.as_map()\n",
    "feat_importance = {model.classes_[k]: v for k, v in feat_importance.items()}\n",
    "feat_importance = {\n",
    "    k: [(to_pred.split()[i], v) for i, v in v] for k, v in feat_importance.items()\n",
    "}\n",
    "feat_importance_pos = {\n",
    "    k: [v for v in v if v[1] > 0] for k, v in feat_importance.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' General Medicine': [('artery', -0.1869880324487356),\n",
       "  ('breast', 0.0880783857407666),\n",
       "  ('muscle', 0.07814815334554133),\n",
       "  ('valve', -0.060311035364575015),\n",
       "  ('heart', 0.03292414708991069),\n",
       "  ('oxygen', 0.026857580194068784),\n",
       "  ('nitroglycerin', -0.021849195996523633),\n",
       "  ('coronary', -0.006822275744941747)],\n",
       " ' Radiology': [('oxygen', -0.19120402466101397),\n",
       "  ('artery', 0.14181291398386572),\n",
       "  ('nitroglycerin', 0.07048150048241235),\n",
       "  ('muscle', 0.04382698549680477),\n",
       "  ('coronary', -0.023307206099310092),\n",
       "  ('heart', -0.022521716599489632),\n",
       "  ('breast', -0.019836767093437305),\n",
       "  ('valve', -0.008045373440971927)],\n",
       " ' Cardiovascular / Pulmonary': [('oxygen', 0.256451435035843),\n",
       "  ('artery', 0.23452081596977184),\n",
       "  ('heart', 0.21094362769758024),\n",
       "  ('coronary', 0.1995309298470315),\n",
       "  ('breast', -0.19744731236806046),\n",
       "  ('muscle', -0.13769584310116986),\n",
       "  ('valve', 0.1374394013956226),\n",
       "  ('nitroglycerin', -0.065400545820238)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cardiovascular / Pulmonary</th>\n",
       "      <td>0.725316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>0.153696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Medicine</th>\n",
       "      <td>0.088011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obstetrics / Gynecology</th>\n",
       "      <td>0.016509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult - History and Phy.</th>\n",
       "      <td>0.011008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery</th>\n",
       "      <td>0.004094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neurology</th>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gastroenterology</th>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOAP / Chart / Progress Notes</th>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedic</th>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Probability\n",
       " Cardiovascular / Pulmonary        0.725316\n",
       " Radiology                         0.153696\n",
       " General Medicine                  0.088011\n",
       " Obstetrics / Gynecology           0.016509\n",
       " Consult - History and Phy.        0.011008\n",
       " Surgery                           0.004094\n",
       " Neurology                         0.000660\n",
       " Gastroenterology                  0.000326\n",
       " SOAP / Chart / Progress Notes     0.000313\n",
       " Urology                           0.000049\n",
       " Orthopedic                        0.000018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_probability(model, [to_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to explain lime output\n",
    "# https://stackoverflow.com/questions/53895007/how-to-interpret-lime-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new data \n",
    "df_new = pd.read_csv('../data/processed/nlp/mtsamples/mtsamples_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keywords_list</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>mmode leave atrial enlargement leave atrial di...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "      <td>['cardiovascular / pulmonary', ' 2-d m-mode', ...</td>\n",
       "      <td>dict_values([[221, 233], [11, 29], [163, 181],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>leave ventricular cavity size wall thickness a...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "      <td>['cardiovascular / pulmonary', ' 2-d', ' doppl...</td>\n",
       "      <td>dict_values([[409, 416], [680, 687], [506, 517...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 3</td>\n",
       "      <td>echocardiogrammultiple view heart great vessel...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d echocardiogram...</td>\n",
       "      <td>['cardiovascular / pulmonary', ' 2-d echocardi...</td>\n",
       "      <td>dict_values([[101, 117], [206, 213], [453, 465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Echocardiogram and Doppler</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 4</td>\n",
       "      <td>description normal cardiac chamber size normal...</td>\n",
       "      <td>cardiovascular / pulmonary, ejection fraction,...</td>\n",
       "      <td>['cardiovascular / pulmonary', ' ejection frac...</td>\n",
       "      <td>dict_values([[97, 114], [76, 96], [282, 295], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Normal left ventricle, moderate biatrial enla...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Doppler</td>\n",
       "      <td>study mild aortic stenosis widely calcify mini...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d study, doppler...</td>\n",
       "      <td>['cardiovascular / pulmonary', ' 2-d study', '...</td>\n",
       "      <td>dict_values([[334, 357], [17, 25], [71, 82], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           3                             2-D M-Mode. Doppler.     \n",
       "1           4                                 2-D Echocardiogram   \n",
       "2           7                                 2-D Echocardiogram   \n",
       "3           9                         Echocardiogram and Doppler   \n",
       "4          11   Normal left ventricle, moderate biatrial enla...   \n",
       "\n",
       "             medical_specialty               sample_name  \\\n",
       "0   Cardiovascular / Pulmonary   2-D Echocardiogram - 1    \n",
       "1   Cardiovascular / Pulmonary   2-D Echocardiogram - 2    \n",
       "2   Cardiovascular / Pulmonary   2-D Echocardiogram - 3    \n",
       "3   Cardiovascular / Pulmonary   2-D Echocardiogram - 4    \n",
       "4   Cardiovascular / Pulmonary              2-D Doppler    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  mmode leave atrial enlargement leave atrial di...   \n",
       "1  leave ventricular cavity size wall thickness a...   \n",
       "2  echocardiogrammultiple view heart great vessel...   \n",
       "3  description normal cardiac chamber size normal...   \n",
       "4  study mild aortic stenosis widely calcify mini...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  cardiovascular / pulmonary, 2-d m-mode, dopple...   \n",
       "1  cardiovascular / pulmonary, 2-d, doppler, echo...   \n",
       "2  cardiovascular / pulmonary, 2-d echocardiogram...   \n",
       "3  cardiovascular / pulmonary, ejection fraction,...   \n",
       "4  cardiovascular / pulmonary, 2-d study, doppler...   \n",
       "\n",
       "                                       keywords_list  \\\n",
       "0  ['cardiovascular / pulmonary', ' 2-d m-mode', ...   \n",
       "1  ['cardiovascular / pulmonary', ' 2-d', ' doppl...   \n",
       "2  ['cardiovascular / pulmonary', ' 2-d echocardi...   \n",
       "3  ['cardiovascular / pulmonary', ' ejection frac...   \n",
       "4  ['cardiovascular / pulmonary', ' 2-d study', '...   \n",
       "\n",
       "                                            location  \n",
       "0  dict_values([[221, 233], [11, 29], [163, 181],...  \n",
       "1  dict_values([[409, 416], [680, 687], [506, 517...  \n",
       "2  dict_values([[101, 117], [206, 213], [453, 465...  \n",
       "3  dict_values([[97, 114], [76, 96], [282, 295], ...  \n",
       "4  dict_values([[334, 357], [17, 25], [71, 82], [...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove medical specialties that appear less than 10 times in dataset\n",
    "#df_new = df_new.groupby('medical_specialty').filter(lambda x: len(x) > 10)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 8)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['cardiovascular / pulmonary', ' 2-d m-mode', ' doppler', ' aortic valve', ' atrial enlargement', ' diastolic function', ' ejection fraction', ' mitral', ' mitral valve', ' pericardial effusion', ' pulmonary valve', ' regurgitation', ' systolic function', ' tricuspid', ' tricuspid valve', ' normal lv ']\""
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.keywords_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['cardiovascular / pulmonary', ' 2-d m-mode', ' doppler', ' aortic valve', ' atrial enlargement', ' diastolic function', ' ejection fraction', ' mitral', ' mitral valve', ' pericardial effusion', ' pulmonary valve', ' regurgitation', ' systolic function', ' tricuspid', ' tricuspid valve', ' normal lv ']\""
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.keywords_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tab(x):\n",
    "    return [i.replace(\" \", \"_\") for i in x]\n",
    "\n",
    "\n",
    "def transform_column(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform column to list\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with labels and NLP features\n",
    "    column_name : str\n",
    "        column name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        dataframe with transformed column\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].apply(lambda x: ast.literal_eval(x))\n",
    "    df[column_name] = df[column_name].apply(lambda x: replace_tab(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = transform_column(df_new, 'keywords_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2947x9891 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42091 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer=lambda x: x)\n",
    "transcription = cv.fit_transform(df_new.keywords_list)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply smote to new data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(transcription, df_new.medical_specialty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.medical_specialty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 9891)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          1008\n",
       " Orthopedic                        296\n",
       " Cardiovascular / Pulmonary        276\n",
       " Radiology                         248\n",
       " Consult - History and Phy.        220\n",
       " Gastroenterology                  193\n",
       " Neurology                         162\n",
       " SOAP / Chart / Progress Notes     140\n",
       " Urology                           139\n",
       " General Medicine                  137\n",
       " Obstetrics / Gynecology           128\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_masterthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
