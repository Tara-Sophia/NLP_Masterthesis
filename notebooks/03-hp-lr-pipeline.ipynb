{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline as skPipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE    \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/raw/mtsamples.csv')\n",
    "df.transcription=df.transcription.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 100 samples: 2976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, mmode, 1, left, atrial, enlargement, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[1, left, ventricular, cavity, size, wall, thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \n",
       "3  [2d, mmode, 1, left, atrial, enlargement, left...  \n",
       "4  [1, left, ventricular, cavity, size, wall, thi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 100 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "    print(\"Number of rows after removing medical specialties with less than 100 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription_c\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    data[\"transcription_c\"] = data[\"transcription_c\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "\n",
    "\n",
    "#apply on dataset\n",
    "df_m = clean_df(df)\n",
    "df_test = remove_punct_lower(df_m)\n",
    "df_test = lemmatize_words(df_test)\n",
    "\n",
    "\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "      <th>transcription_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>{valve, ventricular, mitral, left, pulmonary}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>{wall, ventricle, valve, leaflet, artery, root...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>{arch, venous, valve, septum, artery, vessel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>{valve, cardiac, ventricular, mitral, left}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>{ventricle, heart, ventricular, mitral, left}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                      transcription_c  \\\n",
       "3   2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "4   1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "7   2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "9   description1,normal,cardiac,chamber,size2,norm...   \n",
       "11  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "                                      transcription_f  \n",
       "3       {valve, ventricular, mitral, left, pulmonary}  \n",
       "4   {wall, ventricle, valve, leaflet, artery, root...  \n",
       "7   {arch, venous, valve, septum, artery, vessel, ...  \n",
       "9         {valve, cardiac, ventricular, mitral, left}  \n",
       "11      {ventricle, heart, ventricular, mitral, left}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP with Spacy\n",
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "def medical_entities( text):\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "df_test['transcription_c'] = [','.join(map(str, l)) for l in df_test['transcription_c']]\n",
    "df_test['transcription_f'] = df_test['transcription_c'].apply(medical_entities)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve labels as function\n",
    "def get_labels(data):\n",
    "    return data['medical_specialty'].tolist()\n",
    "\n",
    "df_test_label = get_labels(df_test)\n",
    "\n",
    "df_test_X = df_test['transcription_f'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set as function\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_test_X, df_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for dimensionality reduction\n",
    "def pca(data):\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_reduced = pca.fit_transform(data.toarray())\n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = imbPipeline([\n",
    "        ('preprocessing',CountVectorizer()),\n",
    "        ('svd', TruncatedSVD(n_components=100)),\n",
    "        #('pca', FunctionTransformer(pca)),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', LogisticRegression(random_state=42, multi_class='multinomial')), # remainder=\"passthrough\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.43      0.52      0.47        52\n",
      "                       Urology       0.21      0.17      0.19        40\n",
      "              General Medicine       0.41      0.45      0.43        42\n",
      "                       Surgery       0.09      0.12      0.11        25\n",
      " SOAP / Chart / Progress Notes       0.20      0.35      0.25        23\n",
      "                     Radiology       0.31      0.57      0.40        30\n",
      "                    Orthopedic       0.38      0.53      0.44        57\n",
      "       Obstetrics / Gynecology       0.13      0.16      0.14        51\n",
      "                     Neurology       0.21      0.26      0.23        35\n",
      "              Gastroenterology       0.59      0.29      0.39       212\n",
      "    Consult - History and Phy.       0.35      0.48      0.41        29\n",
      "\n",
      "                      accuracy                           0.34       596\n",
      "                     macro avg       0.30      0.35      0.31       596\n",
      "                  weighted avg       0.40      0.34      0.34       596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "category_list = df_test.medical_specialty.unique()\n",
    "# predict and evaluate\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "245 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1149, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 97, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/hannahpetry/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.33907563 0.33193277        nan 0.07478992        nan        nan\n",
      " 0.39201681 0.39537815        nan        nan        nan        nan\n",
      " 0.33403361 0.32521008        nan 0.34243697        nan        nan\n",
      " 0.41470588 0.41512605        nan        nan        nan        nan\n",
      " 0.34033613 0.33487395        nan 0.40210084        nan        nan\n",
      " 0.39411765 0.39243697        nan        nan        nan        nan\n",
      " 0.33445378 0.32352941        nan 0.35840336        nan        nan\n",
      " 0.3605042  0.35840336        nan        nan        nan        nan\n",
      " 0.33991597 0.3302521         nan 0.34159664        nan        nan\n",
      " 0.33823529 0.33739496        nan        nan        nan        nan\n",
      " 0.33151261 0.33823529        nan 0.32857143        nan        nan\n",
      " 0.33613445 0.3302521         nan        nan        nan        nan\n",
      " 0.33907563 0.32773109        nan 0.34369748        nan        nan\n",
      " 0.34243697 0.33487395        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(C=0.01, multi_class='multinomial', random_state=42),\n",
       " 'classifier__C': 0.01,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    { 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "      'classifier': [LogisticRegression(multi_class='multinomial', random_state=42)],\n",
    "      'classifier__solver': ['saga', 'lbfgs', 'liblinear'],\n",
    "      'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(model_pipeline, param_grid, cv=5)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cardiovascular / Pulmonary       0.47      0.63      0.54        52\n",
      "                       Urology       0.22      0.15      0.18        40\n",
      "              General Medicine       0.44      0.57      0.50        42\n",
      "                       Surgery       0.19      0.28      0.23        25\n",
      " SOAP / Chart / Progress Notes       0.36      0.57      0.44        23\n",
      "                     Radiology       0.37      0.60      0.46        30\n",
      "                    Orthopedic       0.40      0.65      0.49        57\n",
      "       Obstetrics / Gynecology       0.22      0.22      0.22        51\n",
      "                     Neurology       0.19      0.26      0.22        35\n",
      "              Gastroenterology       0.66      0.28      0.39       212\n",
      "    Consult - History and Phy.       0.42      0.66      0.51        29\n",
      "\n",
      "                      accuracy                           0.40       596\n",
      "                     macro avg       0.36      0.44      0.38       596\n",
      "                  weighted avg       0.45      0.40      0.39       596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take best model from grid search and perform evaluation\n",
    "# grid search as function and return best model\n",
    "def grid_search(X_train, y_train, model_pipeline, param_grid):\n",
    "    search = GridSearchCV(model_pipeline, param_grid, cv=5)\n",
    "    search.fit(X_train, y_train)\n",
    "    return search.best_estimator_\n",
    "    \n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "category_list = df_test.medical_specialty.unique()\n",
    "# predict and evaluate\n",
    "print(classification_report(y_test, y_pred, target_names=category_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2976x2702 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 50796 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize transcription to receive sparse matrix\n",
    "def vectorize(data):\n",
    "    vectorizer = CountVectorizer().fit_transform(data)\n",
    "    return vectorizer\n",
    "df_test_X_vectorized = vectorize(df_test_X)\n",
    "df_test_X_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<11253x2702 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 205251 stored elements in Compressed Sparse Row format>,\n",
       " [' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Urology',\n",
       "  ' General Medicine',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ...])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance out dataset with SMOTE, creates synthetic samples of the minority classes as function\n",
    "def smote(X, y):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "X_res, y_res = smote(df_test_X_vectorized, df_test_label)\n",
    "X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for dimensionality reduction\n",
    "def pca(data):\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_reduced = pca.fit_transform(data.toarray())\n",
    "    return X_reduced\n",
    "\n",
    "df_test_X_pca = pca(df_test_X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2380x2574 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 40649 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_preprocessing_pipeline(data):\n",
    "    return Pipeline([\n",
    "        ('vectorize', FunctionTransformer(vectorize, validate=False))\n",
    "    ])\n",
    "\n",
    "X_train_prepared = build_preprocessing_pipeline(X_train)\n",
    "\n",
    "def build_preprocessing_pipeline_2():\n",
    "    return Pipeline([\n",
    "        ('vectorize', CountVectorizer())\n",
    "    ])\n",
    "X_train_prepared_2 = build_preprocessing_pipeline_2().fit_transform(X_train)\n",
    "X_train_prepared_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:43:44) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
