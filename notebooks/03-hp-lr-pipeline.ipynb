{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/hannahpetry/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.manifold import TSNE    \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/raw/mtsamples.csv')\n",
    "df.transcription=df.transcription.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 100 samples: 2976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, mmode, 1, left, atrial, enlargement, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[1, left, ventricular, cavity, size, wall, thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \n",
       "3  [2d, mmode, 1, left, atrial, enlargement, left...  \n",
       "4  [1, left, ventricular, cavity, size, wall, thi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 100 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "    print(\"Number of rows after removing medical specialties with less than 100 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription_c\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    data[\"transcription_c\"] = data[\"transcription_c\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "\n",
    "\n",
    "#apply on dataset\n",
    "df_m = clean_df(df)\n",
    "df_test = remove_punct_lower(df_m)\n",
    "df_test = lemmatize_words(df_test)\n",
    "\n",
    "\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "      <th>transcription_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>{mitral, valve, ventricular, pulmonary, left}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>{lipomatous, mitral, leaflet, wall, root, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>{aorta, mitral, interatrial, heart, vessel, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>{mitral, valve, ventricular, cardiac, left}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>{mitral, heart, ventricle, ventricular, left}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                      transcription_c  \\\n",
       "3   2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "4   1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "7   2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "9   description1,normal,cardiac,chamber,size2,norm...   \n",
       "11  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "                                      transcription_f  \n",
       "3       {mitral, valve, ventricular, pulmonary, left}  \n",
       "4   {lipomatous, mitral, leaflet, wall, root, inte...  \n",
       "7   {aorta, mitral, interatrial, heart, vessel, ve...  \n",
       "9         {mitral, valve, ventricular, cardiac, left}  \n",
       "11      {mitral, heart, ventricle, ventricular, left}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP with Spacy\n",
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "def medical_entities( text):\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "df_test['transcription_c'] = [','.join(map(str, l)) for l in df_test['transcription_c']]\n",
    "df_test['transcription_f'] = df_test['transcription_c'].apply(medical_entities)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve labels as function\n",
    "def get_labels(data):\n",
    "    return data['medical_specialty'].tolist()\n",
    "\n",
    "df_test_label = get_labels(df_test)\n",
    "\n",
    "df_test_X = df_test['transcription_f'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set as function\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_test_X, df_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2976x2702 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 50796 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize transcription to receive sparse matrix\n",
    "def vectorize(data):\n",
    "    vectorizer = CountVectorizer().fit_transform(data)\n",
    "    return vectorizer\n",
    "df_test_X_vectorized = vectorize(df_test_X)\n",
    "df_test_X_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<11253x2702 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 205251 stored elements in Compressed Sparse Row format>,\n",
       " [' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Cardiovascular / Pulmonary',\n",
       "  ' Urology',\n",
       "  ' General Medicine',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Urology',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Urology',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ' Surgery',\n",
       "  ...])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance out dataset with SMOTE, creates synthetic samples of the minority classes as function\n",
    "def smote(X, y):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "X_res, y_res = smote(df_test_X_vectorized, df_test_label)\n",
    "X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca for dimensionality reduction\n",
    "def pca(data):\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_reduced = pca.fit_transform(data.toarray())\n",
    "    return X_reduced\n",
    "\n",
    "df_test_X_pca = pca(df_test_X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2380x2574 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 40649 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_preprocessing_pipeline(data):\n",
    "    return Pipeline([\n",
    "        ('vectorize', FunctionTransformer(vectorize, validate=False))\n",
    "    ])\n",
    "\n",
    "X_train_prepared = build_preprocessing_pipeline(X_train)\n",
    "\n",
    "def build_preprocessing_pipeline_2():\n",
    "    return Pipeline([\n",
    "        ('vectorize', CountVectorizer())\n",
    "    ])\n",
    "X_train_prepared_2 = build_preprocessing_pipeline_2().fit_transform(X_train)\n",
    "X_train_prepared_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(data):\n",
    "    lr = LogisticRegression(random_state=42, multi_class='multinomial')\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(x_train, y_train):\n",
    "    preprocessing_pipeline = build_preprocessing_pipeline()\n",
    "    return Pipeline([\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('smote', FunctionTransformer(smote, validate=False)),\n",
    "        ('pca', FunctionTransformer(pca, validate=False)),\n",
    "        ('classifier', FunctionTransformer(lr_model, validate=False)) \n",
    "    ])\n",
    "\n",
    "def build_pipeline_2():\n",
    "    preprocessing_pipeline = build_preprocessing_pipeline_2()\n",
    "    return Pipeline([\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('pca', PCA(n_components=0.95)),\n",
    "        ('classifier', LogisticRegression(random_state=42, multi_class='multinomial')) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__C\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m],\n\u001b[1;32m      3\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: [LogisticRegression(multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     }\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 9\u001b[0m pipe \u001b[38;5;241m=\u001b[39m build_pipeline_2()\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:414\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 414\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    416\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:316\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps):\n\u001b[1;32m    314\u001b[0m     \u001b[39m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps)\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Setup the memory\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     memory \u001b[39m=\u001b[39m check_memory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:207\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[1;32m    205\u001b[0m         t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     ):\n\u001b[0;32m--> 207\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAll intermediate steps should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtransformers and implement fit and transform \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor be the string \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t))\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    214\u001b[0m \u001b[39m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    216\u001b[0m     estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39mand\u001b[39;00m estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m ):\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    { 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "      'classifier': [LogisticRegression(multi_class='multinomial', random_state=42)],\n",
    "      'classifier__solver': ['saga', 'lbfgs', 'liblinear'],\n",
    "      'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    }\n",
    "]\n",
    "\n",
    "pipe = build_pipeline_2().fit_transform(X_train)\n",
    "# pipe.fit(X_train, y_train)\n",
    "\n",
    "#search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "#search.fit(X_train, y_train)\n",
    "#search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1167c26af54c6340f890887cef801dce27ac37ff6fc6a99bb1eb896d088a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
