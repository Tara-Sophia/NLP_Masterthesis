{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get information on Wav2vec 2.0 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wav2vec 2.0 architecture is a convolutional neural network that takes in raw audio and outputs a sequence of feature vectors. The architecture is based on the convolutional encoder-decoder architecture used in the original wav2vec paper. The encoder is composed of a stack of convolutional layers, while the decoder is composed of a stack of fully connected layers. The encoder and decoder are connected by a sequence of residual connections. The encoder and decoder are trained separately, and the encoder is used to extract features from the raw audio. The decoder is used to predict the target sequence of feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the wav2vec 2.0 architecture uses a self-attention layer to model long-range dependencies between the feature vectors. The self-attention layer is used to compute a context vector for each feature vector. The context vector is then concatenated with the feature vector and passed to the decoder. The self-attention layer is trained jointly with the encoder and decoder.\n",
    "\n",
    "The following diagram shows the architecture of the wav2vec 2.0 model.\n",
    "\n",
    "The wav2vec 2.0 models contain two types of layers: convolutional layers and self-attention layers. The convolutional layers are used to extract features from the raw audio. The self-attention layers are used to model long-range dependencies between the feature vectors.\n",
    "\n",
    "The convolutional layers are used to extract features from the raw audio. The convolutional layers are composed of a stack of convolutional blocks. Each convolutional block contains a stack of convolutional layers. The convolutional layers are composed of a stack of convolutional sublayers. Each convolutional sublayer contains a convolutional layer, a layer normalization layer, and a GELU activation function.\n",
    "\n",
    "The self-attention layers are used to model long-range dependencies between the feature vectors. The self-attention layers are composed of a stack of self-attention blocks. Each self-attention block contains a self-attention layer, a layer normalization layer, and a residual connection. The self-attention layer is composed of a stack of self-attention sublayers. Each self-attention sublayer contains a self-attention layer, a layer normalization layer, and a residual connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the convolutional layers and the self-attention layers is that the convolutional layers are used to extract features from the raw audio, while the self-attention layers are used to model long-range dependencies between the feature vectors.\n",
    "\n",
    "The wav2vec 2.0 model uses a convolutional encoder-decoder architecture to extract features from the raw audio and to predict the target sequence of feature vectors. The encoder is composed of a stack of convolutional layers, while the decoder is composed of a stack of fully connected layers. The encoder and decoder are connected by a sequence of residual connections. The encoder and decoder are trained separately, and the encoder is used to extract features from the raw audio. The decoder is used to predict the target sequence of feature vectors.\n",
    "\n",
    "The raw audio are waveforms sampled at 16 kHz. The raw audio are passed to the encoder, which is composed of a stack of convolutional layers. The convolutional layers are composed of a stack of convolutional sublayers. Each convolutional sublayer contains a convolutional layer, a layer normalization layer, and a GELU activation function. The convolutional layers are connected by a sequence of residual connections. The encoder is trained separately from the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical convolutional model consists of a stack of convolutional layers. Each convolutional layer contains a stack of convolutional sublayers. Each convolutional sublayer contains a convolutional layer, a layer normalization layer, and a GELU activation function. The convolutional layers are connected by a sequence of residual connections. These residual connections are used to pass the output of the previous convolutional layer to the next convolutional layer. The convolutional layers are trained separately from the decoder. The input of the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40268d9a6ead8a84520c08d0b901e046bd2176336d854cc732bdbdbf7245879e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
