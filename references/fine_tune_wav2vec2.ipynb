{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune wav2vec 2.0 on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune wav2vec 2.0 on a custom dataset, you can use the ðŸ¤— Datasets library. Here are the example steps to follow:\n",
    "1. Load the dataset and select the columns you want to use for training\n",
    "2. Preprocess the dataset to add the speech files' absolute path\n",
    "3. Preprocess the dataset to tokenize the targets\n",
    "4. Upload the dataset to the Hub\n",
    "5. Fine-tune the model on the Hub dataset\n",
    "6. Evaluate the fine-tuned model\n",
    "7. Upload the fine-tuned model to the Hub\n",
    "8. Inference\n",
    "9. (Optional) Fine-tune the model on another dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the dataset we extract the .tar.gz file and load the csv file in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune wav2vec 2.0 the hyperparamters should be the following:\n",
    "1. `model.w2v_path = \"facebook/wav2vec2-base-960h\"`: the checkpoint ID of the model to load\n",
    "2. `model.freeze_feature_extractor = True`: freeze the feature extractor\n",
    "3. Batch size should be 16 or 32\n",
    "4. `model.gradient_checkpointing = True`: use gradient checkpointing to save memory and allow bigger batch sizes\n",
    "5. `model.do_stable_layer_norm = True`: use a stable layer norm\n",
    "6. `model.layerdrop = 0.05`: randomly drop out entire layers during training\n",
    "7. `model.gradient_accumulation_steps = 2`: accumulate gradients on several steps\n",
    "8. `model.lr_scheduler_type = \"polynomial\"`: use a polynomial decay of the learning rate because the dataset is small\n",
    "9. `model.total_train_epochs = 30`: finetune for 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you fine-tune the wav2vec2.0 on a dataset with 100 hours of audio the best hyperparameters are:\n",
    "1. `model.w2v_path = \"facebook/wav2vec2-base-960h\"`: the checkpoint ID of the model to load\n",
    "2. `model.freeze_feature_extractor = True`: freeze the feature extractor\n",
    "3. Batch size should be 16 or 32\n",
    "4. `model.gradient_checkpointing = True`: use gradient checkpointing to save memory and allow bigger batch sizes\n",
    "5. `model.do_stable_layer_norm = True`: use a stable layer norm\n",
    "6. `model.layerdrop = 0.1`: randomly drop out entire layers during training\n",
    "7. `model.gradient_accumulation_steps = 2`: accumulate gradients on several steps\n",
    "8. `model.lr_scheduler_type = \"polynomial\"`: use a polynomial decay of the learning rate because the dataset is small\n",
    "9. `model.total_train_epochs = 30`: finetune for 30 epochs\n",
    "10. `model.per_device_train_batch_size = 16`: use a batch size of 16\n",
    "11. `model.val_check_interval = 0.25`: validate every 0.25 steps\n",
    "12. Warmup steps: 500\n",
    "13. Optimizer: AdamW\n",
    "14. Learning rate: 3e-4\n",
    "15. Weight decay: 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40268d9a6ead8a84520c08d0b901e046bd2176336d854cc732bdbdbf7245879e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
