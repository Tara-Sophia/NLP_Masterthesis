{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer#, ColumnTransformer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Morbid obesity.  Laparoscopic antecolic anteg...</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Morbid obesity.,POST...</td>\n",
       "      <td>bariatrics, gastric bypass, eea anastomosis, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Liposuction of the supraumbilical abdomen, re...</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Liposuction</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES:,1.  Deformity, right b...</td>\n",
       "      <td>bariatrics, breast reconstruction, excess, lma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 3</td>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d echocardiogram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Suction-assisted lipectomy - lipodystrophy of...</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Lipectomy - Abdomen/Thighs</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Lipodystrophy of the...</td>\n",
       "      <td>bariatrics, lipodystrophy, abd pads, suction-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Echocardiogram and Doppler</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 4</td>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>cardiovascular / pulmonary, ejection fraction,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Morbid obesity.  Laparoscopic Roux-en-Y gastr...</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass - 1</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Morbid obesity. ,POS...</td>\n",
       "      <td>bariatrics, morbid obesity, roux-en-y, gastric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Normal left ventricle, moderate biatrial enla...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Doppler</td>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d study, doppler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Cerebral Angiogram - moyamoya disease.</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>Moyamoya Disease</td>\n",
       "      <td>CC:, Confusion and slurred speech.,HX , (prima...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Patient presented to the bariatric surgery se...</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Gastric Bypass Discussion - 3</td>\n",
       "      <td>PAST MEDICAL HISTORY:,  Significant for hypert...</td>\n",
       "      <td>bariatrics, weight watchers, roux en y, atkins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Surgical removal of completely bony impacted...</td>\n",
       "      <td>Dentistry</td>\n",
       "      <td>Bony Impacted Teeth Removal</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Completely bony impa...</td>\n",
       "      <td>dentistry, intraoral, bony impacted teeth, thr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                        description  \\\n",
       "0            0   A 23-year-old white female presents with comp...   \n",
       "1            1           Consult for laparoscopic gastric bypass.   \n",
       "2            2           Consult for laparoscopic gastric bypass.   \n",
       "3            3                             2-D M-Mode. Doppler.     \n",
       "4            4                                 2-D Echocardiogram   \n",
       "5            5   Morbid obesity.  Laparoscopic antecolic anteg...   \n",
       "6            6   Liposuction of the supraumbilical abdomen, re...   \n",
       "7            7                                 2-D Echocardiogram   \n",
       "8            8   Suction-assisted lipectomy - lipodystrophy of...   \n",
       "9            9                         Echocardiogram and Doppler   \n",
       "10          10   Morbid obesity.  Laparoscopic Roux-en-Y gastr...   \n",
       "11          11   Normal left ventricle, moderate biatrial enla...   \n",
       "12          12             Cerebral Angiogram - moyamoya disease.   \n",
       "13          13   Patient presented to the bariatric surgery se...   \n",
       "14          14    Surgical removal of completely bony impacted...   \n",
       "\n",
       "              medical_specialty                                sample_name  \\\n",
       "0          Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                    Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                    Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3    Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4    Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "5                    Bariatrics               Laparoscopic Gastric Bypass    \n",
       "6                    Bariatrics                               Liposuction    \n",
       "7    Cardiovascular / Pulmonary                    2-D Echocardiogram - 3    \n",
       "8                    Bariatrics                Lipectomy - Abdomen/Thighs    \n",
       "9    Cardiovascular / Pulmonary                    2-D Echocardiogram - 4    \n",
       "10                   Bariatrics           Laparoscopic Gastric Bypass - 1    \n",
       "11   Cardiovascular / Pulmonary                               2-D Doppler    \n",
       "12                    Neurology                          Moyamoya Disease    \n",
       "13                   Bariatrics             Gastric Bypass Discussion - 3    \n",
       "14                    Dentistry               Bony Impacted Teeth Removal    \n",
       "\n",
       "                                        transcription  \\\n",
       "0   SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1   PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2   HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "5   PREOPERATIVE DIAGNOSIS: , Morbid obesity.,POST...   \n",
       "6   PREOPERATIVE DIAGNOSES:,1.  Deformity, right b...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "8   PREOPERATIVE DIAGNOSIS: , Lipodystrophy of the...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "10  PREOPERATIVE DIAGNOSIS: , Morbid obesity. ,POS...   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "12  CC:, Confusion and slurred speech.,HX , (prima...   \n",
       "13  PAST MEDICAL HISTORY:,  Significant for hypert...   \n",
       "14  PREOPERATIVE DIAGNOSIS:,  Completely bony impa...   \n",
       "\n",
       "                                             keywords  \n",
       "0   allergy / immunology, allergic rhinitis, aller...  \n",
       "1   bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2   bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3   cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4   cardiovascular / pulmonary, 2-d, doppler, echo...  \n",
       "5   bariatrics, gastric bypass, eea anastomosis, r...  \n",
       "6   bariatrics, breast reconstruction, excess, lma...  \n",
       "7   cardiovascular / pulmonary, 2-d echocardiogram...  \n",
       "8   bariatrics, lipodystrophy, abd pads, suction-a...  \n",
       "9   cardiovascular / pulmonary, ejection fraction,...  \n",
       "10  bariatrics, morbid obesity, roux-en-y, gastric...  \n",
       "11  cardiovascular / pulmonary, 2-d study, doppler...  \n",
       "12                                                NaN  \n",
       "13  bariatrics, weight watchers, roux en y, atkins...  \n",
       "14  dentistry, intraoral, bony impacted teeth, thr...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/raw/mtsamples.csv')\n",
    "df.transcription=df.transcription.astype(str)\n",
    "#print(df.columns)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 3546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, mmode, 1, left, atrial, enlargement, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[1, left, ventricular, cavity, size, wall, thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \n",
       "3  [2d, mmode, 1, left, atrial, enlargement, left...  \n",
       "4  [1, left, ventricular, cavity, size, wall, thi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 50]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription_c\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    data[\"transcription_c\"] = data[\"transcription_c\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "\n",
    "\n",
    "#apply on dataset\n",
    "df_m = clean_df(df)\n",
    "df_test = remove_punct_lower(df_m)\n",
    "df_cleaned = lemmatize_words(df_test)\n",
    "\n",
    "\n",
    "df_cleaned.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "#!python -m spacy download en_ner_bionlp13cg_md\n",
    "# !pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
    "\n",
    "#!pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
    "#!pip3 install ../data/en_ner_bionlp13cg_md-0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with complaint of allergies.</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, allergies, asthma, nasal sprays, rhinitis, nasal, erythematous, allegra, sprays, allergic,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climbing stairs, difficulty with airline seats, tying shoes, used to public seating, and lifting objects off the floor.  He exercises three times a week at home and does cardio.  He has difficulty walking two blocks or five flights of stairs.  Difficulty with snoring.  He has muscle and joint pains including knee pain, back pain, foot and ankle pain, and swelling.  He has gastroesophageal reflux disease.,PAST SURGICAL HISTORY:, Includes reconstructive surgery on his right hand 13 years ago.  ,SOCIAL HISTORY:, He is currently single.  He has about ten drinks a year.  He had smoked significantly up until several months ago.  He now smokes less than three cigarettes a day.,FAMILY HISTORY:, Heart disease in both grandfathers, grandmother with stroke, and a grandmother with diabetes.  Denies obesity and hypertension in other family members.,CURRENT MEDICATIONS:, None.,ALLERGIES:,  He is allergic to Penicillin.,MISCELLANEOUS/EATING HISTORY:, He has been going to support groups for seven months with Lynn Holmberg in Greenwich and he is from Eastchester, New York and he feels that we are the appropriate program.  He had a poor experience with the Greenwich program.  Eating history, he is not an emotional eater.  Does not like sweets.  He likes big portions and carbohydrates.  He likes chicken and not steak.  He currently weighs 312 pounds.  Ideal body weight would be 170 pounds.  He is 142 pounds overweight.  If ,he lost 60% of his excess body weight that would be 84 pounds and he should weigh about 228.,REVIEW OF SYSTEMS: ,Negative for head, neck, heart, lungs, GI, GU, orthopedic, and skin.  Specifically denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, high cholesterol, pulmonary embolism, high blood pressure, CVA, venous insufficiency, thrombophlebitis, asthma, shortness of breath, COPD, emphysema, sleep apnea, diabetes, leg and foot swelling, osteoarthritis, rheumatoid arthritis, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, hemorrhoids, rectal bleeding, polyps, incontinence of stool, urinary stress incontinence, or cancer.  Denies cellulitis, pseudotumor cerebri, meningitis, or encephalitis.,PHYSICAL EXAMINATION:, He is alert and oriented x 3.  Cranial nerves II-XII are intact.  Afebrile.  Vital Signs are stable.</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weight loss programs, gastric bypass, atkin's diet, weight watcher's, body weight, laparoscopic gastric, weight loss, pounds, months, weight, laparoscopic, band, loss, diets, overweight, lost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "\n",
       "                                                         description  \\\n",
       "0   A 23-year-old white female presents with complaint of allergies.   \n",
       "1                           Consult for laparoscopic gastric bypass.   \n",
       "\n",
       "       medical_specialty                                sample_name  \\\n",
       "0   Allergy / Immunology                         Allergic Rhinitis    \n",
       "1             Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     transcription  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climbing stairs, difficulty with airline seats, tying shoes, used to public seating, and lifting objects off the floor.  He exercises three times a week at home and does cardio.  He has difficulty walking two blocks or five flights of stairs.  Difficulty with snoring.  He has muscle and joint pains including knee pain, back pain, foot and ankle pain, and swelling.  He has gastroesophageal reflux disease.,PAST SURGICAL HISTORY:, Includes reconstructive surgery on his right hand 13 years ago.  ,SOCIAL HISTORY:, He is currently single.  He has about ten drinks a year.  He had smoked significantly up until several months ago.  He now smokes less than three cigarettes a day.,FAMILY HISTORY:, Heart disease in both grandfathers, grandmother with stroke, and a grandmother with diabetes.  Denies obesity and hypertension in other family members.,CURRENT MEDICATIONS:, None.,ALLERGIES:,  He is allergic to Penicillin.,MISCELLANEOUS/EATING HISTORY:, He has been going to support groups for seven months with Lynn Holmberg in Greenwich and he is from Eastchester, New York and he feels that we are the appropriate program.  He had a poor experience with the Greenwich program.  Eating history, he is not an emotional eater.  Does not like sweets.  He likes big portions and carbohydrates.  He likes chicken and not steak.  He currently weighs 312 pounds.  Ideal body weight would be 170 pounds.  He is 142 pounds overweight.  If ,he lost 60% of his excess body weight that would be 84 pounds and he should weigh about 228.,REVIEW OF SYSTEMS: ,Negative for head, neck, heart, lungs, GI, GU, orthopedic, and skin.  Specifically denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, high cholesterol, pulmonary embolism, high blood pressure, CVA, venous insufficiency, thrombophlebitis, asthma, shortness of breath, COPD, emphysema, sleep apnea, diabetes, leg and foot swelling, osteoarthritis, rheumatoid arthritis, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, hemorrhoids, rectal bleeding, polyps, incontinence of stool, urinary stress incontinence, or cancer.  Denies cellulitis, pseudotumor cerebri, meningitis, or encephalitis.,PHYSICAL EXAMINATION:, He is alert and oriented x 3.  Cranial nerves II-XII are intact.  Afebrile.  Vital Signs are stable.   \n",
       "\n",
       "                                                                                                                                                                                                                                   keywords  \n",
       "0                                                                                                       allergy / immunology, allergic rhinitis, allergies, asthma, nasal sprays, rhinitis, nasal, erythematous, allegra, sprays, allergic,  \n",
       "1  bariatrics, laparoscopic gastric bypass, weight loss programs, gastric bypass, atkin's diet, weight watcher's, body weight, laparoscopic gastric, weight loss, pounds, months, weight, laparoscopic, band, loss, diets, overweight, lost  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df.head(100)\n",
    "pd.set_option('max_colwidth', None)  # Remove any limitation on length \n",
    "                                     # of text displayed in a cell\n",
    "#pd.set_option('max_rows', 300)  # Display up to 300 rows in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         entities\u001b[39m.\u001b[39mappend(ent\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mset\u001b[39m(entities)\u001b[39m#' ,'.join(entities)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m df_small[\u001b[39m'\u001b[39m\u001b[39mtranscription_c\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m, l)) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m df_small[\u001b[39m'\u001b[39m\u001b[39mtranscription_c\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m df_small[\u001b[39m'\u001b[39m\u001b[39mtranscription_f\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_small[\u001b[39m'\u001b[39m\u001b[39mtranscription_c\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(medical_entities)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m df_small\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_small' is not defined"
     ]
    }
   ],
   "source": [
    "# NLP with Spacy\n",
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "def medical_entities( text):\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "df_small['transcription_c'] = [','.join(map(str, l)) for l in df_small['transcription_c']]\n",
    "df_small['transcription_f'] = df_small['transcription_c'].apply(medical_entities)\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "              medical_specialty  \n",
       "3    Cardiovascular / Pulmonary  \n",
       "4    Cardiovascular / Pulmonary  \n",
       "7    Cardiovascular / Pulmonary  \n",
       "9    Cardiovascular / Pulmonary  \n",
       "11   Cardiovascular / Pulmonary  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "df = df[['transcription', 'medical_specialty']]\n",
    "df_small = df.head(100)\n",
    "user_input = [' hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe']\n",
    "\n",
    "#create new df \n",
    "df_user = pd.DataFrame({'transcription':user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/lw9128713_9433llvvhnlv680000gn/T/ipykernel_2855/2661872834.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"transcription\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
      "/var/folders/7p/lw9128713_9433llvvhnlv680000gn/T/ipykernel_2855/2661872834.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"transcription\"] = data[\"transcription\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
      "/var/folders/7p/lw9128713_9433llvvhnlv680000gn/T/ipykernel_2855/2661872834.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"transcription\"] = [','.join(map(str, l)) for l in data['transcription']]\n",
      "/var/folders/7p/lw9128713_9433llvvhnlv680000gn/T/ipykernel_2855/2661872834.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['transcription_final'] = data['transcription'].apply(medical_entities)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{left, ventricular, pulmonary, valve, mitral}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "3  2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "\n",
       "             medical_specialty                            transcription_final  \n",
       "3   Cardiovascular / Pulmonary  {left, ventricular, pulmonary, valve, mitral}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "# remove rows with missing values\n",
    "\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    # remove punctuation and lowercase and lemmatizer\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "def list_to_string_f(data):\n",
    "    data[\"transcription\"] = [','.join(map(str, l)) for l in data['transcription']]\n",
    "    return data\n",
    "\n",
    "    #str1 = \" \" \n",
    "    #return (str1.join(s))\n",
    "\n",
    "def nlp_model(data):\n",
    "    #data[\"transcription_text\"] = [','.join(map(str, l)) for l in data['transcription']]\n",
    "\n",
    "# NLP with Spacy\n",
    "\n",
    "    def medical_entities( text):\n",
    "        nlp = en_ner_bionlp13cg_md.load()\n",
    "        entities = []\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            entities.append(ent.text)\n",
    "        return set(entities)\n",
    "    data['transcription_final'] = data['transcription'].apply(medical_entities)\n",
    "    return data\n",
    "    \n",
    "    #return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "#df_small['transcription_c'] = [','.join(map(str, l)) for l in df_small['transcription_c']]\n",
    "#df_small['transcription_f'] = df_small['transcription_c'].apply(medical_entities)\n",
    "#df_small.head()\n",
    "df_rpl = remove_punct_lower(df_small)\n",
    "lem_df = lemmatize_words(df_rpl)\n",
    "ls = list_to_string_f(lem_df)\n",
    "nl =nlp_model(ls)\n",
    "nl.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{left, ventricular, pulmonary, valve, mitral}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{ventricular, left, ventricle, lipomatous, val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{heart, venous, aorta, inflow, coronary, left,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{left, ventricular, cardiac, valve, mitral}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{heart, left, ventricular, ventricle, mitral}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "4   1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "7   2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "9   description1,normal,cardiac,chamber,size2,norm...   \n",
       "11  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                  transcription_final  \n",
       "3       {left, ventricular, pulmonary, valve, mitral}  \n",
       "4   {ventricular, left, ventricle, lipomatous, val...  \n",
       "7   {heart, venous, aorta, inflow, coronary, left,...  \n",
       "9         {left, ventricular, cardiac, valve, mitral}  \n",
       "11      {heart, left, ventricular, ventricle, mitral}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial,diameter,47,cm2,normal,size,right,left,ventricle3,normal,lv,systolic,function,left,ventricular,ejection,fraction,514,normal,lv,diastolic,function5,pericardial,effusion6,normal,morphology,aortic,valve,mitral,valve,tricuspid,valve,pulmonary,valve7,pa,systolic,pressure,36,mmhgdoppler,1,mild,mitral,tricuspid,regurgitation2,trace,aortic,pulmonary,regurgitation</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{left, mitral, ventricular, pulmonary, valve}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,appear,normal,wall,motion,left,ventricular,systolic,function,appears,hyperdynamic,estimated,ejection,fraction,70,75,nearcavity,obliteration,seen,also,appears,increased,left,ventricular,outflow,tract,gradient,mid,cavity,level,consistent,hyperdynamic,left,ventricular,systolic,function,abnormal,left,ventricular,relaxation,pattern,seen,well,elevated,left,atrial,pressure,seen,doppler,examination2,left,atrium,appears,mildly,dilated3,right,atrium,right,ventricle,appear,normal4,aortic,root,appears,normal5,aortic,valve,appears,calcified,mild,aortic,valve,stenosis,calculated,aortic,valve,area,13,cm,square,maximum,instantaneous,gradient,34,mean,gradient,19,mm6,mitral,annular,calcification,extending,leaflet,supportive,structure,thickening,mitral,valve,leaflet,mild,mitral,regurgitation7,tricuspid,valve,appears,normal,trace,tricuspid,regurgitation,moderate,pulmonary,artery,hypertension,estimated,pulmonary,artery,systolic,pressure,49,mmhg,estimated,right,atrial,pressure,10,mmhg8,pulmonary,valve,appears,normal,trace,pulmonary,insufficiency9,pericardial,effusion,intracardiac,mass,seen10,color,doppler,suggestive,patent,foramen,ovale,lipomatous,hypertrophy,interatrial,septum11,study,somewhat,technically,limited,hence,subtle,abnormality,could,missed,study</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{leaflet, left, mitral, lipomatous, ventricular, pulmonary, interatrial, root, ventricle, atrium, valve, artery, wall}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,vessel,reveal,normal,intracardiac,great,vessel,relationship,cardiac,function,normal,significant,chamber,enlargement,hypertrophy,pericardial,effusion,vegetation,seen,doppler,interrogation,including,color,flow,imaging,reveals,systemic,venous,return,right,atrium,normal,tricuspid,inflow,pulmonary,outflow,normal,valve,pulmonary,venous,return,left,atrium,interatrial,septum,intact,mitral,inflow,ascending,aorta,flow,normal,aortic,valve,trileaflet,coronary,artery,appear,normal,origin,aortic,arch,leftsided,patent,normal,descending,aorta,pulsatility</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{inflow, left, mitral, arch, pulmonary, interatrial, septum, venous, heart, vessel, atrium, valve, coronary, aorta, artery, cardiac}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>description1,normal,cardiac,chamber,size2,normal,left,ventricular,size3,normal,lv,systolic,function,ejection,fraction,estimated,around,604,aortic,valve,seen,good,motion5,mitral,valve,seen,good,motion6,tricuspid,valve,seen,good,motion7,pericardial,effusion,intracardiac,massesdoppler1,trace,mitral,regurgitation2,trace,tricuspid,regurgitationimpression1,normal,lv,systolic,function2,ejection,fraction,estimated,around,60</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{left, mitral, ventricular, valve, cardiac}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcified,minimally,restricted2,mild,left,ventricular,hypertrophy,normal,systolic,function3,moderate,biatrial,enlargement4,normal,right,ventricle5,normal,appearance,tricuspid,mitral,valves6,normal,left,ventricle,left,ventricular,systolic,functiondoppler1,1,2,aortic,regurgitation,easily,seen,aortic,stenosis2,mild,tricuspid,regurgitation,mild,increase,right,heart,pressure,3035,mmhg,maximumsummary1,normal,left,ventricle2,moderate,biatrial,enlargement3,mild,tricuspid,regurgitation,mild,increase,right,heart,pressure</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>{left, mitral, ventricular, heart, ventricle}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   original_transcription  \\\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    2d,mmode,1,left,atrial,enlargement,left,atrial,diameter,47,cm2,normal,size,right,left,ventricle3,normal,lv,systolic,function,left,ventricular,ejection,fraction,514,normal,lv,diastolic,function5,pericardial,effusion6,normal,morphology,aortic,valve,mitral,valve,tricuspid,valve,pulmonary,valve7,pa,systolic,pressure,36,mmhgdoppler,1,mild,mitral,tricuspid,regurgitation2,trace,aortic,pulmonary,regurgitation   \n",
       "4   1,left,ventricular,cavity,size,wall,thickness,appear,normal,wall,motion,left,ventricular,systolic,function,appears,hyperdynamic,estimated,ejection,fraction,70,75,nearcavity,obliteration,seen,also,appears,increased,left,ventricular,outflow,tract,gradient,mid,cavity,level,consistent,hyperdynamic,left,ventricular,systolic,function,abnormal,left,ventricular,relaxation,pattern,seen,well,elevated,left,atrial,pressure,seen,doppler,examination2,left,atrium,appears,mildly,dilated3,right,atrium,right,ventricle,appear,normal4,aortic,root,appears,normal5,aortic,valve,appears,calcified,mild,aortic,valve,stenosis,calculated,aortic,valve,area,13,cm,square,maximum,instantaneous,gradient,34,mean,gradient,19,mm6,mitral,annular,calcification,extending,leaflet,supportive,structure,thickening,mitral,valve,leaflet,mild,mitral,regurgitation7,tricuspid,valve,appears,normal,trace,tricuspid,regurgitation,moderate,pulmonary,artery,hypertension,estimated,pulmonary,artery,systolic,pressure,49,mmhg,estimated,right,atrial,pressure,10,mmhg8,pulmonary,valve,appears,normal,trace,pulmonary,insufficiency9,pericardial,effusion,intracardiac,mass,seen10,color,doppler,suggestive,patent,foramen,ovale,lipomatous,hypertrophy,interatrial,septum11,study,somewhat,technically,limited,hence,subtle,abnormality,could,missed,study   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2d,echocardiogrammultiple,view,heart,great,vessel,reveal,normal,intracardiac,great,vessel,relationship,cardiac,function,normal,significant,chamber,enlargement,hypertrophy,pericardial,effusion,vegetation,seen,doppler,interrogation,including,color,flow,imaging,reveals,systemic,venous,return,right,atrium,normal,tricuspid,inflow,pulmonary,outflow,normal,valve,pulmonary,venous,return,left,atrium,interatrial,septum,intact,mitral,inflow,ascending,aorta,flow,normal,aortic,valve,trileaflet,coronary,artery,appear,normal,origin,aortic,arch,leftsided,patent,normal,descending,aorta,pulsatility   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     description1,normal,cardiac,chamber,size2,normal,left,ventricular,size3,normal,lv,systolic,function,ejection,fraction,estimated,around,604,aortic,valve,seen,good,motion5,mitral,valve,seen,good,motion6,tricuspid,valve,seen,good,motion7,pericardial,effusion,intracardiac,massesdoppler1,trace,mitral,regurgitation2,trace,tricuspid,regurgitationimpression1,normal,lv,systolic,function2,ejection,fraction,estimated,around,60   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             2d,study1,mild,aortic,stenosis,widely,calcified,minimally,restricted2,mild,left,ventricular,hypertrophy,normal,systolic,function3,moderate,biatrial,enlargement4,normal,right,ventricle5,normal,appearance,tricuspid,mitral,valves6,normal,left,ventricle,left,ventricular,systolic,functiondoppler1,1,2,aortic,regurgitation,easily,seen,aortic,stenosis2,mild,tricuspid,regurgitation,mild,increase,right,heart,pressure,3035,mmhg,maximumsummary1,normal,left,ventricle2,moderate,biatrial,enlargement3,mild,tricuspid,regurgitation,mild,increase,right,heart,pressure   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                                                                                                           transcription  \n",
       "3                                                                                          {left, mitral, ventricular, pulmonary, valve}  \n",
       "4                 {leaflet, left, mitral, lipomatous, ventricular, pulmonary, interatrial, root, ventricle, atrium, valve, artery, wall}  \n",
       "7   {inflow, left, mitral, arch, pulmonary, interatrial, septum, venous, heart, vessel, atrium, valve, coronary, aorta, artery, cardiac}  \n",
       "9                                                                                            {left, mitral, ventricular, valve, cardiac}  \n",
       "11                                                                                         {left, mitral, ventricular, heart, ventricle}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl = nl.rename(columns={'transcription': 'original_transcription', 'transcription_final': 'transcription'})\n",
    "nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.to_csv('../data/processed/mtsamples_nlp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transcription', 'medicalspecialty']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m nlp \u001b[39m=\u001b[39m en_ner_bionlp13cg_md\u001b[39m.\u001b[39mload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pl \u001b[39m=\u001b[39m Pipeline(memory\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     steps\u001b[39m=\u001b[39m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m        \u001b[39m# ('cleandata', clean_data),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m       \u001b[39m# ('modelf', nlp_model_final_function)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     ], verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mfit_transform(df_small)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#pd.set_option('max_colwidth', None)  # Remove any limitation on length \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                                      \u001b[39m# of text displayed in a cell\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#pd.set_option('max_rows', 300)  # Display up to 300 rows in a dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:422\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    420\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    423\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/preprocessing/_function_transformer.py:212\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/preprocessing/_function_transformer.py:292\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[0;32m--> 292\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n",
      "\u001b[1;32m/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb Cell 15\u001b[0m in \u001b[0;36mlemmatize_words\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m stop \u001b[39m=\u001b[39m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m lemmatizer \u001b[39m=\u001b[39m WordNetLemmatizer()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtranscription\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39;49m\u001b[39mtranscription\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [lemmatizer\u001b[39m.\u001b[39mlemmatize(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m word_tokenize(x) \u001b[39mif\u001b[39;00m x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (stop)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#clean_data = FunctionTransformer(clean_df, validate=False)\n",
    "remove_punctation = FunctionTransformer(remove_punct_lower, validate=False)\n",
    "lemmatize_thewords = FunctionTransformer(lemmatize_words, validate=False)\n",
    "liststring = FunctionTransformer(list_to_string_f, validate=False)\n",
    "nlp_model_final_function = FunctionTransformer(nlp_model, validate=False)\n",
    "\n",
    "\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "pl = Pipeline(memory=None,\n",
    "    steps=[\n",
    "       # ('cleandata', clean_data),\n",
    "        ('removepunct', remove_punctation),\n",
    "        ('lemmatize', lemmatize_thewords )#,\n",
    "       ('list_to_stringf', list_to_string_f),\n",
    "       ('modelf', nlp_model_final_function)\n",
    "    ], verbose=False)\n",
    "\n",
    "\n",
    "x = pl.fit_transform(df_small)\n",
    "#pd.set_option('max_colwidth', None)  # Remove any limitation on length \n",
    "                                     # of text displayed in a cell\n",
    "#pd.set_option('max_rows', 300)  # Display up to 300 rows in a dataset\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP with YAKE\n",
    "https://towardsdatascience.com/keyword-extraction-methods-the-overview-35557350f8bb\n",
    "https://medium.com/@galeopsi/getting-started-nlp-9955b2cdba8c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 142\n"
     ]
    }
   ],
   "source": [
    "y = pl.transform(df_small)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplication_threshold variable is limit the duplication of words in different keywords. You can set the deduplication_threshold value to 0.1 to avoid the repetition of words in keywords. If you set the deduplication_threshold value to 0.9, then repetition of words is allowed in keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>procedure elective male sterilization via bila...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>indication prostate cancertechnique 35 hour fo...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>description patient placed supine position pre...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>preoperative diagnosis voluntary sterilitypost...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>diagnosis desire vasectomyname operation vasec...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription medical_specialty\n",
       "18  procedure elective male sterilization via bila...           Urology\n",
       "20  indication prostate cancertechnique 35 hour fo...           Urology\n",
       "22  description patient placed supine position pre...           Urology\n",
       "23  preoperative diagnosis voluntary sterilitypost...           Urology\n",
       "25  diagnosis desire vasectomyname operation vasec...           Urology"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 50]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    # remove punctuation and lowercase and lemmatizer\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "def list_to_string_f(data):\n",
    "    data[\"transcription\"] = [' '.join(map(str, l)) for l in data['transcription']]\n",
    "    return data\n",
    "\n",
    "# NLP with Spacy\n",
    "\n",
    "def medical_entities( text):\n",
    "    nlp = en_ner_bionlp13cg_md.load()\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)\n",
    "\n",
    "def nlp_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(medical_entities)\n",
    "    return data\n",
    "    \n",
    "    #return set(entities)#' ,'.join(entities)\n",
    "\n",
    "df_small = df.head(200)\n",
    "\n",
    "clean_data = FunctionTransformer(clean_df, validate=False)\n",
    "remove_punctation = FunctionTransformer(remove_punct_lower, validate=False)\n",
    "lemmatize_thewords = FunctionTransformer(lemmatize_words, validate=False)\n",
    "list_to_string_words = FunctionTransformer(list_to_string_f, validate=False)\n",
    "nlp_model_final_function = FunctionTransformer(nlp_model, validate=False)\n",
    "\n",
    "\n",
    "pl = Pipeline(memory=None,\n",
    "    steps=[\n",
    "        ('cleandata', clean_data),\n",
    "        ('removepunct', remove_punctation),\n",
    "        ('lemmatize', lemmatize_thewords ),\n",
    "       ('list_to_stringf', list_to_string_words)#,\n",
    "      #  ('modelf', nlp_model_final_function)\n",
    "    ], verbose=False)\n",
    "\n",
    "\n",
    "x = pl.fit_transform(df_small)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>procedure elective male sterilization via bila...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{segment removed free, removed free end, sutur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>indication prostate cancertechnique 35 hour fo...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{normal limit kidney, indication prostate canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>description patient placed supine position pre...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{anesthetized local anesthesia, chromic catgut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>preoperative diagnosis voluntary sterilitypost...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{fulgurated meticulous hemostasis, deferens sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>diagnosis desire vasectomyname operation vasec...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{vasectomyanesthesia generalhistory patient, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription medical_specialty  \\\n",
       "18  procedure elective male sterilization via bila...           Urology   \n",
       "20  indication prostate cancertechnique 35 hour fo...           Urology   \n",
       "22  description patient placed supine position pre...           Urology   \n",
       "23  preoperative diagnosis voluntary sterilitypost...           Urology   \n",
       "25  diagnosis desire vasectomyname operation vasec...           Urology   \n",
       "\n",
       "                                  transcription_final  \n",
       "18  {segment removed free, removed free end, sutur...  \n",
       "20  {normal limit kidney, indication prostate canc...  \n",
       "22  {anesthetized local anesthesia, chromic catgut...  \n",
       "23  {fulgurated meticulous hemostasis, deferens sk...  \n",
       "25  {vasectomyanesthesia generalhistory patient, c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yake\n",
    "def yake_function(text):\n",
    "    entities = []\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 3\n",
    "    deduplication_threshold = 0.9\n",
    "    numOfKeywords = 20\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    for kw in keywords:\n",
    "        entities.append(kw[0])\n",
    "        #print(kw)    \n",
    "    return set(entities)\n",
    "\n",
    "def yake_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(yake_function)\n",
    "    return data\n",
    "\n",
    "#y = FunctionTransformer(yake_model, validate=False)\n",
    "y = yake_model(x)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "Pattern matched multiple keys",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mmax_colwidth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# Remove any limitation on length \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                      \u001b[39m# of text displayed in a cell\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m pd\u001b[39m.\u001b[39;49mset_option(\u001b[39m'\u001b[39;49m\u001b[39mmax_rows\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m300\u001b[39;49m)  \u001b[39m# Display up to 300 rows in a dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m t\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/pandas/_config/config.py:256\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/pandas/_config/config.py:149\u001b[0m, in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_set_option() got an unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkwarg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args[::\u001b[39m2\u001b[39m], args[\u001b[39m1\u001b[39m::\u001b[39m2\u001b[39m]):\n\u001b[0;32m--> 149\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(k, silent)\n\u001b[1;32m    151\u001b[0m     o \u001b[39m=\u001b[39m _get_registered_option(key)\n\u001b[1;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m o \u001b[39mand\u001b[39;00m o\u001b[39m.\u001b[39mvalidator:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/pandas/_config/config.py:116\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such keys(s): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(pat)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keys) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39m\"\u001b[39m\u001b[39mPattern matched multiple keys\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m key \u001b[39m=\u001b[39m keys[\u001b[39m0\u001b[39m]\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m silent:\n",
      "\u001b[0;31mOptionError\u001b[0m: Pattern matched multiple keys"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "def rake_nltk_function(text):\n",
    "    rake_nltk_var = Rake()\n",
    "    entities = []\n",
    "    rake_nltk_var.extract_keywords_from_text(text)\n",
    "    keywords_scored = rake_nltk_var.get_word_degrees()\n",
    "    #keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "    for key in keywords_scored:\n",
    "        entities.append(key)\n",
    "    return set(entities)\n",
    "\n",
    "def rake_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(rake_nltk_function)\n",
    "    return data\n",
    "\n",
    "t = rake_model(x)\n",
    "pd.set_option('max_colwidth', None)  # Remove any limitation on length \n",
    "                                     # of text displayed in a cell\n",
    "pd.set_option('max_rows', 300)  # Display up to 300 rows in a dataset\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline with custom input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  transcription\n",
       "0   hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = [' hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe']\n",
    "\n",
    "#create new df \n",
    "df_user = pd.DataFrame({'transcription':user_input})\n",
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "df_small = df.head(100)\n",
    "\n",
    "def remove_punct_lower(series_input):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    print(series_input.apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation))))\n",
    "    return series_input.apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' hello i am a patent and i am sick nasal issues also headach and my mum and dad huhu hehe']\n"
     ]
    }
   ],
   "source": [
    "def remove_punct_lower(series_input):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    print(list(map(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)),series_input )))\n",
    "    #return series_input.apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "inp = [' hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe']\n",
    "remove_punct_lower(inp)\n",
    "\n",
    "\n",
    "#l = [int(x) for x in l]\n",
    "\n",
    "#l = list(map(int,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip() argument after * must be an iterable, not function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X33sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m inp \u001b[39m=\u001b[39m [[\u001b[39m'\u001b[39m\u001b[39m hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X33sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m#inp = inp.reshape(-1, 1)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X33sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m x \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mfit_transform(df\u001b[39m.\u001b[39;49mtranscription)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tara-sophiatumbraegel/UNI/masterthesis/NLP_Masterthesis/src/mtsamples_data.ipynb#X33sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m x\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:414\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 414\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    416\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    334\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    335\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    337\u001b[0m     cloned_transformer,\n\u001b[1;32m    338\u001b[0m     X,\n\u001b[1;32m    339\u001b[0m     y,\n\u001b[1;32m    340\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    341\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    342\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    343\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    344\u001b[0m )\n\u001b[1;32m    345\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    869\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    871\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:669\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39m# set n_features_in_ attribute\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 669\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_transformers()\n\u001b[1;32m    670\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    671\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp_masterthesis/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:329\u001b[0m, in \u001b[0;36mColumnTransformer._validate_transformers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers:\n\u001b[1;32m    327\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m names, transformers, _ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformers)\n\u001b[1;32m    331\u001b[0m \u001b[39m# validate names\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_names(names)\n",
      "\u001b[0;31mTypeError\u001b[0m: zip() argument after * must be an iterable, not function"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "\n",
    "def remove_punct_lower(series_input):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    print(series_input.apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation))))\n",
    "    return series_input.apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "\n",
    "def lemmatize_words(series_input):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    # remove punctuation and lowercase and lemmatizer\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return series_input.apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    " \n",
    "def list_to_string_f(series_input):\n",
    "    return [' '.join(map(str, l)) for l in series_input]\n",
    "\n",
    "\n",
    "def medical_entities( series_input):\n",
    "    nlp = en_ner_bionlp13cg_md.load()\n",
    "    entities = []\n",
    "    doc = nlp(series_input)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.series_input)\n",
    "    return set(entities)\n",
    "\n",
    "def nlp_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(medical_entities)\n",
    "    return data\n",
    "    \n",
    "    #return set(entities)#' ,'.join(entities)\n",
    "\n",
    "#df_small = df.head(200)\n",
    "\n",
    "#clean_data = FunctionTransformer(clean_df, validate=False)\n",
    "remove_punctation = ColumnTransformer(remove_punct_lower)\n",
    "lemmatize_thewords = ColumnTransformer(lemmatize_words)#, validate=False)\n",
    "list_to_string_words = ColumnTransformer(list_to_string_f)#, validate=False)\n",
    "nlp_model_final_function = ColumnTransformer(medical_entities)#, validate=False)\n",
    "\n",
    "\n",
    "pl = Pipeline(memory=None,\n",
    "    steps=[\n",
    "        #(\n",
    "            #'cleandata', clean_data),\n",
    "        ('removepunct', remove_punctation),\n",
    "        ('lemmatize', lemmatize_thewords ),\n",
    "       ('list_to_stringf', list_to_string_words),\n",
    "       ('modelf', nlp_model_final_function)\n",
    "    ], verbose=False)\n",
    "\n",
    "inp = [[' hello I am a patent, and I am sick, nasal issues, also headach and my mum and dad huhu hehe']]\n",
    "#inp = inp.reshape(-1, 1)\n",
    "x = pl.fit_transform(df.transcription)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e008ba518fc94ce1407a9eb93057d27eeafd2dad53a3852a13fd11c85bd39236"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
