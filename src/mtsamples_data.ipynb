{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imports and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tara-\n",
      "[nltk_data]     sophiatumbraegel/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/raw/mtsamples.csv')\n",
    "df.transcription=df.transcription.astype(str)\n",
    "#print(df.columns)\n",
    "#df =df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0   A 23-year-old white female presents with comp...   \n",
       "1           1           Consult for laparoscopic gastric bypass.   \n",
       "2           2           Consult for laparoscopic gastric bypass.   \n",
       "3           3                             2-D M-Mode. Doppler.     \n",
       "4           4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 3546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, mmode, 1, left, atrial, enlargement, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[1, left, ventricular, cavity, size, wall, thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "             medical_specialty  \\\n",
       "3   Cardiovascular / Pulmonary   \n",
       "4   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                     transcription_c  \n",
       "3  [2d, mmode, 1, left, atrial, enlargement, left...  \n",
       "4  [1, left, ventricular, cavity, size, wall, thi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 50]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription_c\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    data[\"transcription_c\"] = data[\"transcription_c\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "\n",
    "\n",
    "#apply on dataset\n",
    "df_m = clean_df(df)\n",
    "df_test = remove_punct_lower(df_m)\n",
    "df_test = lemmatize_words(df_test)\n",
    "\n",
    "\n",
    "df_test.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Spacy\n",
    "things to do:\n",
    "- currently only single word extraction instead of multi keywords\n",
    "- group by sickness\n",
    "- pipeline\n",
    "- valuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "#!python -m spacy download en_ner_bionlp13cg_md\n",
    "# !pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
    "\n",
    "#!pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
    "#!pip3 install ../data/en_ner_bionlp13cg_md-0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, mmode, 1, left, atrial, enlargement, left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[1, left, ventricular, cavity, size, wall, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, echocardiogrammultiple, view, heart, grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[description1, normal, cardiac, chamber, size2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[2d, study1, mild, aortic, stenosis, widely, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PREOPERATIVE DIAGNOSES,Airway obstruction seco...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>[preoperative, diagnosesairway, obstruction, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PROCEDURE: , Elective male sterilization via b...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>[procedure, elective, male, sterilization, via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HISTORY OF PRESENT ILLNESS:,  The patient is a...</td>\n",
       "      <td>General Medicine</td>\n",
       "      <td>[history, present, illness, patient, 17yearold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>INDICATION:,  Prostate Cancer.,TECHNIQUE:,  3....</td>\n",
       "      <td>Urology</td>\n",
       "      <td>[indication, prostate, cancertechnique, 35, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DESCRIPTION:,  The patient was placed in the s...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>[description, patient, placed, supine, positio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "16  PREOPERATIVE DIAGNOSES,Airway obstruction seco...   \n",
       "18  PROCEDURE: , Elective male sterilization via b...   \n",
       "19  HISTORY OF PRESENT ILLNESS:,  The patient is a...   \n",
       "20  INDICATION:,  Prostate Cancer.,TECHNIQUE:,  3....   \n",
       "22  DESCRIPTION:,  The patient was placed in the s...   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "16   Cardiovascular / Pulmonary   \n",
       "18                      Urology   \n",
       "19             General Medicine   \n",
       "20                      Urology   \n",
       "22                      Urology   \n",
       "\n",
       "                                      transcription_c  \n",
       "3   [2d, mmode, 1, left, atrial, enlargement, left...  \n",
       "4   [1, left, ventricular, cavity, size, wall, thi...  \n",
       "7   [2d, echocardiogrammultiple, view, heart, grea...  \n",
       "9   [description1, normal, cardiac, chamber, size2...  \n",
       "11  [2d, study1, mild, aortic, stenosis, widely, c...  \n",
       "16  [preoperative, diagnosesairway, obstruction, s...  \n",
       "18  [procedure, elective, male, sterilization, via...  \n",
       "19  [history, present, illness, patient, 17yearold...  \n",
       "20  [indication, prostate, cancertechnique, 35, ho...  \n",
       "22  [description, patient, placed, supine, positio...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df_test.head(10)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/lw9128713_9433llvvhnlv680000gn/T/ipykernel_3064/1039835220.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['transcription_c'] = [','.join(map(str, l)) for l in df_small['transcription_c']]\n",
      "/var/folders/7p/lw9128713_9433llvvhnlv680000gn/T/ipykernel_3064/1039835220.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['transcription_f'] = df_small['transcription_c'].apply(medical_entities)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_c</th>\n",
       "      <th>transcription_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,mmode,1,left,atrial,enlargement,left,atrial...</td>\n",
       "      <td>{left, pulmonary, ventricular, valve, mitral}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1,left,ventricular,cavity,size,wall,thickness,...</td>\n",
       "      <td>{root, left, ventricle, atrium, wall, pulmonar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,echocardiogrammultiple,view,heart,great,ves...</td>\n",
       "      <td>{cardiac, left, atrium, venous, heart, pulmona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>description1,normal,cardiac,chamber,size2,norm...</td>\n",
       "      <td>{cardiac, left, ventricular, valve, mitral}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2d,study1,mild,aortic,stenosis,widely,calcifie...</td>\n",
       "      <td>{left, ventricle, heart, ventricular, mitral}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "              medical_specialty  \\\n",
       "3    Cardiovascular / Pulmonary   \n",
       "4    Cardiovascular / Pulmonary   \n",
       "7    Cardiovascular / Pulmonary   \n",
       "9    Cardiovascular / Pulmonary   \n",
       "11   Cardiovascular / Pulmonary   \n",
       "\n",
       "                                      transcription_c  \\\n",
       "3   2d,mmode,1,left,atrial,enlargement,left,atrial...   \n",
       "4   1,left,ventricular,cavity,size,wall,thickness,...   \n",
       "7   2d,echocardiogrammultiple,view,heart,great,ves...   \n",
       "9   description1,normal,cardiac,chamber,size2,norm...   \n",
       "11  2d,study1,mild,aortic,stenosis,widely,calcifie...   \n",
       "\n",
       "                                      transcription_f  \n",
       "3       {left, pulmonary, ventricular, valve, mitral}  \n",
       "4   {root, left, ventricle, atrium, wall, pulmonar...  \n",
       "7   {cardiac, left, atrium, venous, heart, pulmona...  \n",
       "9         {cardiac, left, ventricular, valve, mitral}  \n",
       "11      {left, ventricle, heart, ventricular, mitral}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP with Spacy\n",
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "def medical_entities( text):\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "df_small['transcription_c'] = [','.join(map(str, l)) for l in df_small['transcription_c']]\n",
    "df_small['transcription_f'] = df_small['transcription_c'].apply(medical_entities)\n",
    "df_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "# remove rows with missing values\n",
    "\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 100]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    # remove punctuation and lowercase and lemmatizer\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "def list_to_string_f(data):\n",
    "    data[\"transcription\"] = [','.join(map(str, l)) for l in data['transcription']]\n",
    "    return data\n",
    "\n",
    "    #str1 = \" \" \n",
    "    #return (str1.join(s))\n",
    "    \n",
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "\n",
    "def nlp_model(data):\n",
    "    data[\"transcription_text\"] = [','.join(map(str, l)) for l in data['transcription']]\n",
    "\n",
    "# NLP with Spacy\n",
    "\n",
    "    def medical_entities( text):\n",
    "        nlp = en_ner_bionlp13cg_md.load()\n",
    "        entities = []\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            entities.append(ent.text)\n",
    "        return set(entities)\n",
    "    data['transcription_final'] = data['transcription_text'].apply(medical_entities)\n",
    "    return data\n",
    "    \n",
    "    #return set(entities)#' ,'.join(entities)\n",
    "\n",
    "\n",
    "#df_small['transcription_c'] = [','.join(map(str, l)) for l in df_small['transcription_c']]\n",
    "#df_small['transcription_f'] = df_small['transcription_c'].apply(medical_entities)\n",
    "#df_small.head()\n",
    "df_small = df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleandata&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function clean_df at 0x7fcaf7176b90&gt;)),\n",
       "                (&#x27;removepunct&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function remove_punct_lower at 0x7fcaf7176c20&gt;)),\n",
       "                (&#x27;lemmatize&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function lemmatize_words at 0x7fcaf7176cb0&gt;)),\n",
       "                (&#x27;modelf&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function nlp_model at 0x7fcaf7176dd0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleandata&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function clean_df at 0x7fcaf7176b90&gt;)),\n",
       "                (&#x27;removepunct&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function remove_punct_lower at 0x7fcaf7176c20&gt;)),\n",
       "                (&#x27;lemmatize&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function lemmatize_words at 0x7fcaf7176cb0&gt;)),\n",
       "                (&#x27;modelf&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function nlp_model at 0x7fcaf7176dd0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function clean_df at 0x7fcaf7176b90&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function remove_punct_lower at 0x7fcaf7176c20&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function lemmatize_words at 0x7fcaf7176cb0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function nlp_model at 0x7fcaf7176dd0&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cleandata',\n",
       "                 FunctionTransformer(func=<function clean_df at 0x7fcaf7176b90>)),\n",
       "                ('removepunct',\n",
       "                 FunctionTransformer(func=<function remove_punct_lower at 0x7fcaf7176c20>)),\n",
       "                ('lemmatize',\n",
       "                 FunctionTransformer(func=<function lemmatize_words at 0x7fcaf7176cb0>)),\n",
       "                ('modelf',\n",
       "                 FunctionTransformer(func=<function nlp_model at 0x7fcaf7176dd0>))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "clean_data = FunctionTransformer(clean_df, validate=False)\n",
    "remove_punctation = FunctionTransformer(remove_punct_lower, validate=False)\n",
    "lemmatize_thewords = FunctionTransformer(lemmatize_words, validate=False)\n",
    "nlp_model_final_function = FunctionTransformer(nlp_model, validate=False)\n",
    "\n",
    "\n",
    "nlp = en_ner_bionlp13cg_md.load()\n",
    "pl = Pipeline(memory=None,\n",
    "    steps=[\n",
    "        ('cleandata', clean_data),\n",
    "        ('removepunct', remove_punctation),\n",
    "        ('lemmatize', lemmatize_thewords ),\n",
    "      # ('list_to_stringf', list_to_string_f)#,\n",
    "       # ('selector', get_numeric_data),\n",
    "       ('modelf', nlp_model_final_function)\n",
    "    ], verbose=False)\n",
    "\n",
    "\n",
    "pl.fit(df_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP with YAKE\n",
    "https://towardsdatascience.com/keyword-extraction-methods-the-overview-35557350f8bb\n",
    "https://medium.com/@galeopsi/getting-started-nlp-9955b2cdba8c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 142\n"
     ]
    }
   ],
   "source": [
    "x = pl.transform(df_small)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplication_threshold variable is limit the duplication of words in different keywords. You can set the deduplication_threshold value to 0.1 to avoid the repetition of words in keywords. If you set the deduplication_threshold value to 0.9, then repetition of words is allowed in keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing medical specialties with less than 50 samples: 142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>procedure elective male sterilization via bila...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>indication prostate cancertechnique 35 hour fo...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>description patient placed supine position pre...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>preoperative diagnosis voluntary sterilitypost...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>diagnosis desire vasectomyname operation vasec...</td>\n",
       "      <td>Urology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription medical_specialty\n",
       "18  procedure elective male sterilization via bila...           Urology\n",
       "20  indication prostate cancertechnique 35 hour fo...           Urology\n",
       "22  description patient placed supine position pre...           Urology\n",
       "23  preoperative diagnosis voluntary sterilitypost...           Urology\n",
       "25  diagnosis desire vasectomyname operation vasec...           Urology"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import en_ner_bionlp13cg_md\n",
    "# remove rows with missing values\n",
    "def clean_df(data):\n",
    "    df = data.dropna().drop_duplicates() \n",
    "    # drop rows where medical specialty appears less than 50 times\n",
    "    df = df[df.groupby(\"medical_specialty\")[\"medical_specialty\"].transform('size') > 50]\n",
    "    print(\"Number of rows after removing medical specialties with less than 50 samples:\", len(df.index))\n",
    "    # remove unnecessary columns, only keep transcriptions and medical_specialty columns\n",
    "    return df[['transcription', 'medical_specialty']]\n",
    "\n",
    "\n",
    "# remove punctuation and lowercase and lemmatizer\n",
    "\n",
    "def remove_punct_lower(data):\n",
    "    '''remove punctuation and lowercase'''\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: x.lower().translate(str.maketrans('','', string.punctuation)))\n",
    "    return data\n",
    "\n",
    "def lemmatize_words(data):\n",
    "    '''lemmatize words, remove stopwords'''\n",
    "    # remove punctuation and lowercase and lemmatizer\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    data[\"transcription\"] = data[\"transcription\"].apply(lambda x: [lemmatizer.lemmatize(x) for x in word_tokenize(x) if x not in (stop)])\n",
    "    return data\n",
    " \n",
    "def list_to_string_f(data):\n",
    "    data[\"transcription\"] = [' '.join(map(str, l)) for l in data['transcription']]\n",
    "    return data\n",
    "\n",
    "# NLP with Spacy\n",
    "\n",
    "def medical_entities( text):\n",
    "    nlp = en_ner_bionlp13cg_md.load()\n",
    "    entities = []\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text)\n",
    "    return set(entities)\n",
    "\n",
    "def nlp_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(medical_entities)\n",
    "    return data\n",
    "    \n",
    "    #return set(entities)#' ,'.join(entities)\n",
    "\n",
    "df_small = df.head(200)\n",
    "\n",
    "clean_data = FunctionTransformer(clean_df, validate=False)\n",
    "remove_punctation = FunctionTransformer(remove_punct_lower, validate=False)\n",
    "lemmatize_thewords = FunctionTransformer(lemmatize_words, validate=False)\n",
    "list_to_string_words = FunctionTransformer(list_to_string_f, validate=False)\n",
    "nlp_model_final_function = FunctionTransformer(nlp_model, validate=False)\n",
    "\n",
    "\n",
    "pl = Pipeline(memory=None,\n",
    "    steps=[\n",
    "        ('cleandata', clean_data),\n",
    "        ('removepunct', remove_punctation),\n",
    "        ('lemmatize', lemmatize_thewords ),\n",
    "       ('list_to_stringf', list_to_string_words)#,\n",
    "      #  ('modelf', nlp_model_final_function)\n",
    "    ], verbose=False)\n",
    "\n",
    "\n",
    "x = pl.fit_transform(df_small)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>procedure elective male sterilization via bila...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{hemostasis cautery end, double back securing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>indication prostate cancertechnique 35 hour fo...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{indication prostate cancertechnique, skull up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>description patient placed supine position pre...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{sheath incised scalpel, position prepped drap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>preoperative diagnosis voluntary sterilitypost...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{clipped proximally distally, supine position ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>diagnosis desire vasectomyname operation vasec...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{chromic bleeding identifiedthrough, tied drop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription medical_specialty  \\\n",
       "18  procedure elective male sterilization via bila...           Urology   \n",
       "20  indication prostate cancertechnique 35 hour fo...           Urology   \n",
       "22  description patient placed supine position pre...           Urology   \n",
       "23  preoperative diagnosis voluntary sterilitypost...           Urology   \n",
       "25  diagnosis desire vasectomyname operation vasec...           Urology   \n",
       "\n",
       "                                  transcription_final  \n",
       "18  {hemostasis cautery end, double back securing,...  \n",
       "20  {indication prostate cancertechnique, skull up...  \n",
       "22  {sheath incised scalpel, position prepped drap...  \n",
       "23  {clipped proximally distally, supine position ...  \n",
       "25  {chromic bleeding identifiedthrough, tied drop...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yake\n",
    "def yake_function(text):\n",
    "    entities = []\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 3\n",
    "    deduplication_threshold = 0.9\n",
    "    numOfKeywords = 20\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    for kw in keywords:\n",
    "        entities.append(kw[0])\n",
    "        #print(kw)    \n",
    "    return set(entities)\n",
    "\n",
    "def yake_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(yake_function)\n",
    "    return data\n",
    "\n",
    "#y = FunctionTransformer(yake_model, validate=False)\n",
    "y = yake_model(x)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>procedure elective male sterilization via bila...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{carefully, discussed, 1inch, tied, via, level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>indication prostate cancertechnique 35 hour fo...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{activity, clinically, administration, mci, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>description patient placed supine position pre...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{catgut, incision, va, procedure, clamp, hemoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>preoperative diagnosis voluntary sterilitypost...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{room, discussed, clamp, chromic, hemiscrotum,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>diagnosis desire vasectomyname operation vasec...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>{incision, va, surrounding, room, procedure, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transcription medical_specialty  \\\n",
       "18  procedure elective male sterilization via bila...           Urology   \n",
       "20  indication prostate cancertechnique 35 hour fo...           Urology   \n",
       "22  description patient placed supine position pre...           Urology   \n",
       "23  preoperative diagnosis voluntary sterilitypost...           Urology   \n",
       "25  diagnosis desire vasectomyname operation vasec...           Urology   \n",
       "\n",
       "                                  transcription_final  \n",
       "18  {carefully, discussed, 1inch, tied, via, level...  \n",
       "20  {activity, clinically, administration, mci, re...  \n",
       "22  {catgut, incision, va, procedure, clamp, hemoc...  \n",
       "23  {room, discussed, clamp, chromic, hemiscrotum,...  \n",
       "25  {incision, va, surrounding, room, procedure, t...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "def rake_nltk_function(text):\n",
    "    rake_nltk_var = Rake()\n",
    "    entities = []\n",
    "    rake_nltk_var.extract_keywords_from_text(text)\n",
    "    keywords_scored = rake_nltk_var.get_word_degrees()\n",
    "    #keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "    for key in keywords_scored:\n",
    "        entities.append(key)\n",
    "    return set(entities)\n",
    "\n",
    "def rake_model(data):\n",
    "    data['transcription_final'] = data['transcription'].apply(rake_nltk_function)\n",
    "    return data\n",
    "\n",
    "t = rake_model(x)\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)  # Remove any limitation on length \n",
    "                                     # of text displayed in a cell\n",
    "pd.set_option('max_rows', 300)  # Display up to 300 rows in a dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp_masterthesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e008ba518fc94ce1407a9eb93057d27eeafd2dad53a3852a13fd11c85bd39236"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
